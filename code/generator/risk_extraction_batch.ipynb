{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "import json\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "# from docx import Document\n",
    "\n",
    "\n",
    "import json\n",
    "import os\n",
    "from copy import deepcopy\n",
    "import time\n",
    "import ast\n",
    "import re\n",
    "import requests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from openai import OpenAI\n",
    "\n",
    "# Get the first key from the uploaded dictionary\n",
    "env_file_key = \"openai.env\"\n",
    "\n",
    "# Open the file and read its content\n",
    "with open(env_file_key, 'r', encoding='utf-8') as file:\n",
    "    env_content = file.read()\n",
    "\n",
    "# # Load the content into a variable\n",
    "# env_variables = dotenv_values(stream=io.StringIO(env_content))\n",
    "\n",
    "api_key = env_content\n",
    "# openai.api_key = api_key\n",
    "\n",
    "client = OpenAI(\n",
    "    # # This is the default and can be omitted\n",
    "    api_key=api_key,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def chat_gpt(prompt):\n",
    "    response = client.chat.completions.create(\n",
    "        model=\"gpt-4o\",\n",
    "        messages=prompt\n",
    "    )\n",
    "    return response.choices[0].message.content.strip()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prepare data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_file = \"data/new_data/unique_risks_model_cards_v3.json\"\n",
    "data = pd.read_json(data_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>modelId</th>\n",
       "      <th>author</th>\n",
       "      <th>creation_time</th>\n",
       "      <th>last_modified</th>\n",
       "      <th>downloads</th>\n",
       "      <th>likes</th>\n",
       "      <th>library_name</th>\n",
       "      <th>tags</th>\n",
       "      <th>pipeline_tag</th>\n",
       "      <th>card_data_language</th>\n",
       "      <th>card_data_license</th>\n",
       "      <th>card_data_library_name</th>\n",
       "      <th>card_data_tags</th>\n",
       "      <th>card_data_base_model</th>\n",
       "      <th>card_data_datasets</th>\n",
       "      <th>model_card_metadata</th>\n",
       "      <th>model_card</th>\n",
       "      <th>risks_limitations_bias</th>\n",
       "      <th>risk_section_len</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>facebook/fasttext-language-identification</td>\n",
       "      <td>facebook</td>\n",
       "      <td>2023-03-06 12:52:50</td>\n",
       "      <td>2023-06-09T12:39:43+00:00</td>\n",
       "      <td>53352708</td>\n",
       "      <td>135</td>\n",
       "      <td>fasttext</td>\n",
       "      <td>[fasttext, text-classification, language-ident...</td>\n",
       "      <td>text-classification</td>\n",
       "      <td>None</td>\n",
       "      <td>cc-by-nc-4.0</td>\n",
       "      <td>fasttext</td>\n",
       "      <td>[text-classification, language-identification]</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>{'base_model': None, 'datasets': None, 'eval_r...</td>\n",
       "      <td>\\n# fastText (Language Identification)\\n\\nfast...</td>\n",
       "      <td>### Limitations and bias\\n\\nEven if the traini...</td>\n",
       "      <td>786</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>google-bert/bert-base-uncased</td>\n",
       "      <td>google-bert</td>\n",
       "      <td>2022-03-02 23:29:04</td>\n",
       "      <td>2024-02-19T11:06:12+00:00</td>\n",
       "      <td>44931654</td>\n",
       "      <td>1678</td>\n",
       "      <td>transformers</td>\n",
       "      <td>[transformers, pytorch, tf, jax, rust, coreml,...</td>\n",
       "      <td>fill-mask</td>\n",
       "      <td>en</td>\n",
       "      <td>apache-2.0</td>\n",
       "      <td>None</td>\n",
       "      <td>[exbert]</td>\n",
       "      <td>None</td>\n",
       "      <td>[bookcorpus, wikipedia]</td>\n",
       "      <td>{'base_model': None, 'datasets': ['bookcorpus'...</td>\n",
       "      <td>\\n# BERT base model (uncased)\\n\\nPretrained mo...</td>\n",
       "      <td>### Limitations and bias\\n\\nEven if the traini...</td>\n",
       "      <td>1783</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                     modelId       author       creation_time  \\\n",
       "2  facebook/fasttext-language-identification     facebook 2023-03-06 12:52:50   \n",
       "4              google-bert/bert-base-uncased  google-bert 2022-03-02 23:29:04   \n",
       "\n",
       "               last_modified  downloads  likes  library_name  \\\n",
       "2  2023-06-09T12:39:43+00:00   53352708    135      fasttext   \n",
       "4  2024-02-19T11:06:12+00:00   44931654   1678  transformers   \n",
       "\n",
       "                                                tags         pipeline_tag  \\\n",
       "2  [fasttext, text-classification, language-ident...  text-classification   \n",
       "4  [transformers, pytorch, tf, jax, rust, coreml,...            fill-mask   \n",
       "\n",
       "  card_data_language card_data_license card_data_library_name  \\\n",
       "2               None      cc-by-nc-4.0               fasttext   \n",
       "4                 en        apache-2.0                   None   \n",
       "\n",
       "                                   card_data_tags card_data_base_model  \\\n",
       "2  [text-classification, language-identification]                 None   \n",
       "4                                        [exbert]                 None   \n",
       "\n",
       "        card_data_datasets                                model_card_metadata  \\\n",
       "2                     None  {'base_model': None, 'datasets': None, 'eval_r...   \n",
       "4  [bookcorpus, wikipedia]  {'base_model': None, 'datasets': ['bookcorpus'...   \n",
       "\n",
       "                                          model_card  \\\n",
       "2  \\n# fastText (Language Identification)\\n\\nfast...   \n",
       "4  \\n# BERT base model (uncased)\\n\\nPretrained mo...   \n",
       "\n",
       "                              risks_limitations_bias  risk_section_len  \n",
       "2  ### Limitations and bias\\n\\nEven if the traini...               786  \n",
       "4  ### Limitations and bias\\n\\nEven if the traini...              1783  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2672, 19)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2672, 19)\n"
     ]
    }
   ],
   "source": [
    "unique_risks = data.drop_duplicates(subset=\"risks_limitations_bias\")\n",
    "print (unique_risks.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>modelId</th>\n",
       "      <th>author</th>\n",
       "      <th>creation_time</th>\n",
       "      <th>last_modified</th>\n",
       "      <th>downloads</th>\n",
       "      <th>likes</th>\n",
       "      <th>library_name</th>\n",
       "      <th>tags</th>\n",
       "      <th>pipeline_tag</th>\n",
       "      <th>card_data_language</th>\n",
       "      <th>card_data_license</th>\n",
       "      <th>card_data_library_name</th>\n",
       "      <th>card_data_tags</th>\n",
       "      <th>card_data_base_model</th>\n",
       "      <th>card_data_datasets</th>\n",
       "      <th>model_card_metadata</th>\n",
       "      <th>model_card</th>\n",
       "      <th>risks_limitations_bias</th>\n",
       "      <th>risk_section_len</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>facebook/fasttext-language-identification</td>\n",
       "      <td>facebook</td>\n",
       "      <td>2023-03-06 12:52:50</td>\n",
       "      <td>2023-06-09T12:39:43+00:00</td>\n",
       "      <td>53352708</td>\n",
       "      <td>135</td>\n",
       "      <td>fasttext</td>\n",
       "      <td>[fasttext, text-classification, language-ident...</td>\n",
       "      <td>text-classification</td>\n",
       "      <td>None</td>\n",
       "      <td>cc-by-nc-4.0</td>\n",
       "      <td>fasttext</td>\n",
       "      <td>[text-classification, language-identification]</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>{'base_model': None, 'datasets': None, 'eval_r...</td>\n",
       "      <td>\\n# fastText (Language Identification)\\n\\nfast...</td>\n",
       "      <td>### Limitations and bias\\n\\nEven if the traini...</td>\n",
       "      <td>786</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>google-bert/bert-base-uncased</td>\n",
       "      <td>google-bert</td>\n",
       "      <td>2022-03-02 23:29:04</td>\n",
       "      <td>2024-02-19T11:06:12+00:00</td>\n",
       "      <td>44931654</td>\n",
       "      <td>1678</td>\n",
       "      <td>transformers</td>\n",
       "      <td>[transformers, pytorch, tf, jax, rust, coreml,...</td>\n",
       "      <td>fill-mask</td>\n",
       "      <td>en</td>\n",
       "      <td>apache-2.0</td>\n",
       "      <td>None</td>\n",
       "      <td>[exbert]</td>\n",
       "      <td>None</td>\n",
       "      <td>[bookcorpus, wikipedia]</td>\n",
       "      <td>{'base_model': None, 'datasets': ['bookcorpus'...</td>\n",
       "      <td>\\n# BERT base model (uncased)\\n\\nPretrained mo...</td>\n",
       "      <td>### Limitations and bias\\n\\nEven if the traini...</td>\n",
       "      <td>1783</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                     modelId       author       creation_time  \\\n",
       "2  facebook/fasttext-language-identification     facebook 2023-03-06 12:52:50   \n",
       "4              google-bert/bert-base-uncased  google-bert 2022-03-02 23:29:04   \n",
       "\n",
       "               last_modified  downloads  likes  library_name  \\\n",
       "2  2023-06-09T12:39:43+00:00   53352708    135      fasttext   \n",
       "4  2024-02-19T11:06:12+00:00   44931654   1678  transformers   \n",
       "\n",
       "                                                tags         pipeline_tag  \\\n",
       "2  [fasttext, text-classification, language-ident...  text-classification   \n",
       "4  [transformers, pytorch, tf, jax, rust, coreml,...            fill-mask   \n",
       "\n",
       "  card_data_language card_data_license card_data_library_name  \\\n",
       "2               None      cc-by-nc-4.0               fasttext   \n",
       "4                 en        apache-2.0                   None   \n",
       "\n",
       "                                   card_data_tags card_data_base_model  \\\n",
       "2  [text-classification, language-identification]                 None   \n",
       "4                                        [exbert]                 None   \n",
       "\n",
       "        card_data_datasets                                model_card_metadata  \\\n",
       "2                     None  {'base_model': None, 'datasets': None, 'eval_r...   \n",
       "4  [bookcorpus, wikipedia]  {'base_model': None, 'datasets': ['bookcorpus'...   \n",
       "\n",
       "                                          model_card  \\\n",
       "2  \\n# fastText (Language Identification)\\n\\nfast...   \n",
       "4  \\n# BERT base model (uncased)\\n\\nPretrained mo...   \n",
       "\n",
       "                              risks_limitations_bias  risk_section_len  \n",
       "2  ### Limitations and bias\\n\\nEven if the traini...               786  \n",
       "4  ### Limitations and bias\\n\\nEven if the traini...              1783  "
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "unique_risks.head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "MESSAGES = [ { 'role': 'system', 'content': \"\"\"\n",
    "Consider the following definitions: \n",
    "    1) An AI incident is an event, circumstance or series of events where the development, use or malfunction of one or more AI systems directly or indirectly leads to any of the following harms: (a) injury or harm to the health of a person or groups of people; (b) disruption of the management and operation of critical infrastructure; (c) violations to human rights or a breach of obligations under the applicable law intended to protect fundamental, labour and intellectual property rights; (d) harm to property, communities or the environment.' The harm can be physical, psychological, reputational, economic/financial (including harm to property), environmental, public interest (e.g., protection of critical infrastructure and democratic institutions), human rights and fundamental rights. \n",
    "    2) An AI risk is expressed as likelihood that harm or damage will occur. Risk is a function of both the probability of an event occurring and the severity of the consequences that would result. Risk is usually expressed in terms of risk sources, potential events, their consequences and their likelihood. \n",
    "\"\"\" },\n",
    "\n",
    "{ 'role': 'user', 'content': \"\"\"You are provided in input with cardID and a section written by an AI developer from Risks, Bias and Limitations section of an AI model card:\n",
    "cardID: \"{}\", section: \"{}\".\n",
    "\n",
    "Tasks:\n",
    "\n",
    "1) Identify Relevance: Determine for each section whether it discusses the AI risks and potential solutions to mitigate them. Provide a response as Yes, No, or Unclear. If the answer is Yes, continue with the next steps; else, you will output empty \"Risks and Mitigations\" in the output JSON.\n",
    "\n",
    "2) Analyze: Identify  all the subtexts in the section that can be categorized into - \"RISKS\",  \"MITIGATIONS\", or \"MIX OF BOTH\". Classify each such subtext into one of the provided three types. This subtext must match the exact sentences in the input section and is used as a reference.\n",
    "\n",
    "3) Split: For the each reference, identify unique risks and mitigations. Classify each into one of the two types \"RISKS\" or \"MITIGATIONS\".\n",
    "It is very important that each risk or mitigation identified be formatted like this: Verb + Object + [Explanation], and describes one unique risk/mitigation, is concise, consisting of one clear, to-the-point sentence, with up to maximum of 20 words. Specifically, start a risk with an action verb in active present tense (e.g., undermines, discriminates, infringes, reduces, increases etc., but NOT potentially) followed by the object and the reason in case it is not obvious and requires an explanation. Start a mitigation with verb in present tense, base form (e.g., perform, inform, investigate). Also, we want these descriptions to be read by broad public who does not have a deep knowledge about AI technology. Do not change the meaning of the concrete risk. For example, if it says the model does not works in a particular setting then you say it underperforms and not discriminates.\n",
    "This would NOT be a good output: \"Potentially undermines the right to privacy if the facial recognition data is not properly secured.\" while this is good: \"Undermines the right to privacy if the facial recognition data is not properly secured.\". This would NOT be a good output: \"Affects all fined tuned versions of the model.\" as it does not specify what the risk is; instead \"Transfers all the <specific risks from reference like bias, unrepresentative data> to the inherited models\" is better. \"Evaluations surface potential risks in use cases.\" is a bad output, instead specify the potential risks from the reference.\n",
    "Other examples of well-formatted risks:\n",
    "    * Underperforms on non-English languages \n",
    "    * Discriminates against certain players, such as women or those from certain ethnic backgrounds.\n",
    "    * Undermines the safety and security when model is deployed without thorough in-domain testing.\n",
    "Examples of well-formatted mitigations:\n",
    "    * Perform thorough in-domain testing\n",
    "    * Update model card for models using pretrained models\n",
    "    * Inform indirect users when the content they're working with is created by the LLM.\n",
    "\n",
    "Output Format: Ensure your output strictly follows this JSON structure.\n",
    "\n",
    "{{\n",
    "    \"cardID\": \"<Card ID>\",\n",
    "    \"section\": {{\n",
    "        \"about risks, bias or mitigations\": [\"Yes\"/\"No\"/\"Unclear\"],\n",
    "        \"risks_and_mitigations\": \n",
    "    [\n",
    "        {{\n",
    "            \"reference_text\": \"Reference subtext 1 from <section>\",\n",
    "            \"type\": [\"RISKS\", \"MITIGATIONS\", \"MIX OF BOTH\"],\n",
    "            \"splits\": [\n",
    "                {{\n",
    "                \"unique_risk_mitigation\": \"Unique risk/mitigation 1 in identified reference\",\n",
    "                \"type\": [\"RISKS\", \"MITIGATIONS\"]\n",
    "                }},\n",
    "                ...\n",
    "                {{\n",
    "                \"unique_risk_mitigation\": \"Unique risk/mitigation N in identified reference\",\n",
    "                \"Type\": [\"RISKS\", \"MITIGATIONS\"]\n",
    "                }},\n",
    "            ]\n",
    "        }},\n",
    "        ...\n",
    "        {{\n",
    "            \"reference_text\": \"Reference subtext N from <section>\",\n",
    "            \"type\": [\"RISKS\", \"MITIGATIONS\", \"MIX OF BOTH\"],\n",
    "            \"splits\": [\n",
    "                {{\n",
    "                \"unique_risk_mitigation\": \"Unique risk/mitigation 1 in identified reference\",\n",
    "                \"type\": [\"RISKS\", \"MITIGATIONS\"]\n",
    "                }},\n",
    "                ...\n",
    "                {{\n",
    "                \"unique_risk_mitigation\": \"Unique risk/mitigation N in identified reference\",\n",
    "                \"type\": [\"RISKS\", \"MITIGATIONS\"]\n",
    "                }},\n",
    "            ]\n",
    "        }},\n",
    "        ...\n",
    "    ]\n",
    "    }}\n",
    "}}\n",
    "\n",
    "\n",
    "Important Notes: Do not report your reasoning steps or any preamble like 'Here is the output', ONLY the JSON result. In scenarios where there are no sentences mentioned, provide an empty JSON array for those sections.\n",
    "\n",
    "*** Double Check your output that it contains only the requested JSON and nothing else. *** \"\"\"\n",
    "\n",
    "} ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "def format_prompt(MESSAGES, cardID, section): \n",
    "    messages = deepcopy(MESSAGES) \n",
    "    messages[1]['content'] = messages[1]['content'].format(cardID, section) \n",
    "    return messages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>modelId</th>\n",
       "      <th>author</th>\n",
       "      <th>creation_time</th>\n",
       "      <th>last_modified</th>\n",
       "      <th>downloads</th>\n",
       "      <th>likes</th>\n",
       "      <th>library_name</th>\n",
       "      <th>tags</th>\n",
       "      <th>pipeline_tag</th>\n",
       "      <th>card_data_language</th>\n",
       "      <th>card_data_license</th>\n",
       "      <th>card_data_library_name</th>\n",
       "      <th>card_data_tags</th>\n",
       "      <th>card_data_base_model</th>\n",
       "      <th>card_data_datasets</th>\n",
       "      <th>model_card_metadata</th>\n",
       "      <th>model_card</th>\n",
       "      <th>risks_limitations_bias</th>\n",
       "      <th>risk_section_len</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>15688</th>\n",
       "      <td>M4-ai/Hercules-Mini-1.8B</td>\n",
       "      <td>M4-ai</td>\n",
       "      <td>2024-03-29 00:06:01</td>\n",
       "      <td>2024-03-30T15:18:49+00:00</td>\n",
       "      <td>504</td>\n",
       "      <td>6</td>\n",
       "      <td>transformers</td>\n",
       "      <td>[transformers, safetensors, qwen2, text-genera...</td>\n",
       "      <td>text-generation</td>\n",
       "      <td>[en]</td>\n",
       "      <td>other</td>\n",
       "      <td>transformers</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>[Locutusque/hercules-v4.0]</td>\n",
       "      <td>{'base_model': None, 'datasets': ['Locutusque/...</td>\n",
       "      <td>\\n# Hercules-Mini-1.8B \\n\\n&lt;!-- Provide a quic...</td>\n",
       "      <td>## Bias, Risks, and Limitations\\n\\n&lt;!-- This s...</td>\n",
       "      <td>583</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                        modelId author       creation_time  \\\n",
       "15688  M4-ai/Hercules-Mini-1.8B  M4-ai 2024-03-29 00:06:01   \n",
       "\n",
       "                   last_modified  downloads  likes  library_name  \\\n",
       "15688  2024-03-30T15:18:49+00:00        504      6  transformers   \n",
       "\n",
       "                                                    tags     pipeline_tag  \\\n",
       "15688  [transformers, safetensors, qwen2, text-genera...  text-generation   \n",
       "\n",
       "      card_data_language card_data_license card_data_library_name  \\\n",
       "15688               [en]             other           transformers   \n",
       "\n",
       "      card_data_tags card_data_base_model          card_data_datasets  \\\n",
       "15688           None                 None  [Locutusque/hercules-v4.0]   \n",
       "\n",
       "                                     model_card_metadata  \\\n",
       "15688  {'base_model': None, 'datasets': ['Locutusque/...   \n",
       "\n",
       "                                              model_card  \\\n",
       "15688  \\n# Hercules-Mini-1.8B \\n\\n<!-- Provide a quic...   \n",
       "\n",
       "                                  risks_limitations_bias  risk_section_len  \n",
       "15688  ## Bias, Risks, and Limitations\\n\\n<!-- This s...               583  "
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "unique_risks.iloc[785:786]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "messages = format_prompt(MESSAGES, \"15688\", unique_risks[\"risks_limitations_bias\"].iloc[785])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'role': 'system',\n",
       "  'content': \"\\nConsider the following definitions: \\n    1) An AI incident is an event, circumstance or series of events where the development, use or malfunction of one or more AI systems directly or indirectly leads to any of the following harms: (a) injury or harm to the health of a person or groups of people; (b) disruption of the management and operation of critical infrastructure; (c) violations to human rights or a breach of obligations under the applicable law intended to protect fundamental, labour and intellectual property rights; (d) harm to property, communities or the environment.' The harm can be physical, psychological, reputational, economic/financial (including harm to property), environmental, public interest (e.g., protection of critical infrastructure and democratic institutions), human rights and fundamental rights. \\n    2) An AI risk is expressed as likelihood that harm or damage will occur. Risk is a function of both the probability of an event occurring and the severity of the consequences that would result. Risk is usually expressed in terms of risk sources, potential events, their consequences and their likelihood. \\n\"},\n",
       " {'role': 'user',\n",
       "  'content': 'You are provided in input with cardID and a section written by an AI developer from Risks, Bias and Limitations section of an AI model card:\\ncardID: \"15688\", section: \"## Bias, Risks, and Limitations\\n\\n<!-- This section is meant to convey both technical and sociotechnical limitations. -->\\n\\nThe eos token was not setup properly, so to prevent infinite generation you\\'ll need to implement a stopping criteria when the model generates the <|im_end|> token. ### Recommendations\\n\\n<!-- This section is meant to convey recommendations with respect to the bias, risk, and technical limitations. -->\\n\\nUsers (both direct and downstream) should be made aware of the risks, biases and limitations of the model. More information needed for further recommendations.\".\\n\\nTasks:\\n\\n1) Identify Relevance: Determine for each section whether it discusses the AI risks and potential solutions to mitigate them. Provide a response as Yes, No, or Unclear. If the answer is Yes, continue with the next steps; else, you will output empty \"Risks and Mitigations\" in the output JSON.\\n\\n2) Analyze: Identify  all the subtexts in the section that can be categorized into - \"RISKS\",  \"MITIGATIONS\", or \"MIX OF BOTH\". Classify each such subtext into one of the provided three types. This subtext must match the exact sentences in the input section and is used as a reference.\\n\\n3) Split: For the each reference, identify unique risks and mitigations. Classify each into one of the two types \"RISKS\" or \"MITIGATIONS\".\\nIt is very important that each risk or mitigation identified be formatted like this: Verb + Object + [Explanation], and describes one unique risk/mitigation, is concise, consisting of one clear, to-the-point sentence, with up to maximum of 20 words. Specifically, start a risk with an action verb in active present tense (e.g., undermines, discriminates, infringes, reduces, increases etc., but NOT potentially) followed by the object and the reason in case it is not obvious and requires an explanation. Start a mitigation with verb in present tense, base form (e.g., perform, inform, investigate). Also, we want these descriptions to be read by broad public who does not have a deep knowledge about AI technology. Do not change the meaning of the concrete risk. For example, if it says the model does not works in a particular setting then you say it underperforms and not discriminates.\\nThis would NOT be a good output: \"Potentially undermines the right to privacy if the facial recognition data is not properly secured.\" while this is good: \"Undermines the right to privacy if the facial recognition data is not properly secured.\". This would NOT be a good output: \"Affects all fined tuned versions of the model.\" as it does not specify what the risk is; instead \"Transfers all the <specific risks from reference like bias, unrepresentative data> to the inherited models\" is better. \"Evaluations surface potential risks in use cases.\" is a bad output, instead specify the potential risks from the reference.\\nOther examples of well-formatted risks:\\n    * Underperforms on non-English languages \\n    * Discriminates against certain players, such as women or those from certain ethnic backgrounds.\\n    * Undermines the safety and security when model is deployed without thorough in-domain testing.\\nExamples of well-formatted mitigations:\\n    * Perform thorough in-domain testing\\n    * Update model card for models using pretrained models\\n    * Inform indirect users when the content they\\'re working with is created by the LLM.\\n\\nOutput Format: Ensure your output strictly follows this JSON structure.\\n\\n{\\n    \"cardID\": \"<Card ID>\",\\n    \"section\": {\\n        \"about risks, bias or mitigations\": [\"Yes\"/\"No\"/\"Unclear\"],\\n        \"risks_and_mitigations\": \\n    [\\n        {\\n            \"reference_text\": \"Reference subtext 1 from <section>\",\\n            \"type\": [\"RISKS\", \"MITIGATIONS\", \"MIX OF BOTH\"],\\n            \"splits\": [\\n                {\\n                \"unique_risk_mitigation\": \"Unique risk/mitigation 1 in identified reference\",\\n                \"type\": [\"RISKS\", \"MITIGATIONS\"]\\n                },\\n                ...\\n                {\\n                \"unique_risk_mitigation\": \"Unique risk/mitigation N in identified reference\",\\n                \"Type\": [\"RISKS\", \"MITIGATIONS\"]\\n                },\\n            ]\\n        },\\n        ...\\n        {\\n            \"reference_text\": \"Reference subtext N from <section>\",\\n            \"type\": [\"RISKS\", \"MITIGATIONS\", \"MIX OF BOTH\"],\\n            \"splits\": [\\n                {\\n                \"unique_risk_mitigation\": \"Unique risk/mitigation 1 in identified reference\",\\n                \"type\": [\"RISKS\", \"MITIGATIONS\"]\\n                },\\n                ...\\n                {\\n                \"unique_risk_mitigation\": \"Unique risk/mitigation N in identified reference\",\\n                \"type\": [\"RISKS\", \"MITIGATIONS\"]\\n                },\\n            ]\\n        },\\n        ...\\n    ]\\n    }\\n}\\n\\n\\nImportant Notes: Do not report your reasoning steps or any preamble like \\'Here is the output\\', ONLY the JSON result. In scenarios where there are no sentences mentioned, provide an empty JSON array for those sections.\\n\\n*** Double Check your output that it contains only the requested JSON and nothing else. *** '}]"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "messages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "response = chat_gpt(messages)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'{\\n    \"cardID\": \"15688\",\\n    \"section\": {\\n        \"about risks, bias or mitigations\": [\"Yes\"],\\n        \"risks_and_mitigations\": [\\n            {\\n                \"reference_text\": \"The eos token was not setup properly, so to prevent infinite generation you\\'ll need to implement a stopping criteria when the model generates the'"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'{\\n    \"cardID\": \"2\",\\n    \"section\": {\\n        \"about risks, bias or mitigations\": [\"Yes\"],\\n        \"risks_and_mitigations\": [\\n            {\\n                \"reference_text\": \"Any deployed use case of the model - whether commercial or not - is currently out of scope. Non-deployed use cases such as image search in a constrained environment, are also not recommended unless there is thorough in-domain testing of the model with a specific, fixed class taxonomy. This is because our safety assessment demonstrated a high need for task specific testing especially given the variability of CLIP’s performance with different class taxonomies. This makes untested and unconstrained deployment of the model in any use case currently potentially harmful.\",\\n                \"type\": [\"MIX OF BOTH\"],\\n                \"splits\": [\\n                    {\\n                        \"unique_risk_mitigation\": \"Undermines the safety and security when model is deployed without thorough in-domain testing.\",\\n                        \"type\": [\"RISKS\"]\\n                    },\\n                    {\\n                        \"unique_risk_mitigation\": \"Perform thorough in-domain testing of the model with a specific, fixed class taxonomy.\",\\n                        \"type\": [\"MITIGATIONS\"]\\n                    }\\n                ]\\n            },\\n            {\\n                \"reference_text\": \"Certain use cases which would fall under the domain of surveillance and facial recognition are always out-of-scope regardless of performance of the model. This is because the use of artificial intelligence for tasks such as these can be premature currently given the lack of testing norms and checks to ensure its fair use.\",\\n                \"type\": [\"RISKS\"],\\n                \"splits\": [\\n                    {\\n                        \"unique_risk_mitigation\": \"Undermines ethical standards when applied in surveillance and facial recognition without proper checks.\",\\n                        \"type\": [\"RISKS\"]\\n                    }\\n                ]\\n            },\\n            {\\n                \"reference_text\": \"Since the model has not been purposefully trained in or evaluated on any languages other than English, its use should be limited to English language use cases.\",\\n                \"type\": [\"RISKS\"],\\n                \"splits\": [\\n                    {\\n                        \"unique_risk_mitigation\": \"Underperforms on non-English languages.\",\\n                        \"type\": [\"RISKS\"]\\n                    }\\n                ]\\n            },\\n            {\\n                \"reference_text\": \"CLIP currently struggles with respect to certain tasks such as fine grained classification and counting objects.\",\\n                \"type\": [\"RISKS\"],\\n                \"splits\": [\\n                    {\\n                        \"unique_risk_mitigation\": \"Struggles with fine grained classification.\",\\n                        \"type\": [\"RISKS\"]\\n                    },\\n                    {\\n                        \"unique_risk_mitigation\": \"Underperforms in counting objects.\",\\n                        \"type\": [\"RISKS\"]\\n                    }\\n                ]\\n            },\\n            {\\n                \"reference_text\": \"CLIP also poses issues with regards to fairness and bias which we discuss in the paper and briefly in the next section.\",\\n                \"type\": [\"RISKS\"],\\n                \"splits\": [\\n                    {\\n                        \"unique_risk_mitigation\": \"Poses issues with regards to fairness and bias.\",\\n                        \"type\": [\"RISKS\"]\\n                    }\\n                ]\\n            },\\n            {\\n                \"reference_text\": \"In many cases we have used linear probes to evaluate the performance of CLIP and there is evidence suggesting that linear probes can underestimate model performance.\",\\n                \"type\": [\"RISKS\"],\\n                \"splits\": [\\n                    {\\n                        \"unique_risk_mitigation\": \"Underestimates model performance when evaluated with linear probes.\",\\n                        \"type\": [\"RISKS\"]\\n                    }\\n                ]\\n            },\\n            {\\n                \"reference_text\": \"We find that the performance of CLIP - and the specific biases it exhibits - can depend significantly on class design and the choices one makes for categories to include and exclude.\",\\n                \"type\": [\"MIX OF BOTH\"],\\n                \"splits\": [\\n                    {\\n                        \"unique_risk_mitigation\": \"Discriminates based on class design and categories chosen.\",\\n                        \"type\": [\"RISKS\"]\\n                    },\\n                    {\\n                        \"unique_risk_mitigation\": \"Design classes carefully and choose categories inclusively.\",\\n                        \"type\": [\"MITIGATIONS\"]\\n                    }\\n                ]\\n            },\\n            {\\n                \"reference_text\": \"We tested the risk of certain kinds of denigration with CLIP by classifying images of people from Fairface into crime-related and non-human animal categories. We found significant disparities with respect to race and gender. Additionally, we found that these disparities could shift based on how the classes were constructed.\",\\n                \"type\": [\"RISKS\"],\\n                \"splits\": [\\n                    {\\n                        \"unique_risk_mitigation\": \"Shows disparities with respect to race and gender when classifying images.\",\\n                        \"type\": [\"RISKS\"]\\n                    },\\n                    {\\n                        \"unique_risk_mitigation\": \"Shifts disparities based on class construction.\",\\n                        \"type\": [\"RISKS\"]\\n                    }\\n                ]\\n            },\\n            {\\n                \"reference_text\": \"We also tested the performance of CLIP on gender, race and age classification using the Fairface dataset (We default to using race categories as they are constructed in the Fairface dataset.) in order to assess quality of performance across different demographics. We found accuracy >96% across all races for gender classification with ‘Middle Eastern’ having the highest accuracy (98.4%) and ‘White’ having the lowest (96.5%). Additionally, CLIP averaged ~93% for racial classification and ~63% for age classification.\",\\n                \"type\": [\"MIX OF BOTH\"],\\n                \"splits\": [\\n                    {\\n                        \"unique_risk_mitigation\": \"Evaluate performance across different demographics to surface potential risks.\",\\n                        \"type\": [\"MITIGATIONS\"]\\n                    },\\n                    {\\n                        \"unique_risk_mitigation\": \"Performs well in gender classification but shows disparity in racial and age classification.\",\\n                        \"type\": [\"RISKS\"]\\n                    }\\n                ]\\n            }\\n        ]\\n    }\\n}'"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'```json\\n{\\n    \"cardID\": \"2\",\\n    \"section\": {\\n        \"about risks, bias or mitigations\": \"Yes\",\\n        \"risks_and_mitigations\": [\\n            {\\n                \"reference_text\": \"Even if the training data used for this model could be characterized as fairly neutral, this model can have biased predictions:\",\\n                \"type\": \"RISKS\",\\n                \"splits\": [\\n                    {\\n                        \"unique_risk_mitigation\": \"Produces biased predictions despite neutral training data\",\\n                        \"type\": \"RISKS\"\\n                    }\\n                ]\\n            },\\n            {\\n                \"reference_text\": \"[Example predictions showing bias]\",\\n                \"type\": \"RISKS\",\\n                \"splits\": [\\n                    {\\n                        \"unique_risk_mitigation\": \"Exhibits gender bias in job roles predictions\",\\n                        \"type\": \"RISKS\"\\n                    },\\n                    {\\n                        \"unique_risk_mitigation\": \"Transfers all the bias to the inherited models\",\\n                        \"type\": \"RISKS\"\\n                    }\\n                ]\\n            }\\n        ]\\n    }\\n}\\n```'"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Batch the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "def batch_data(data=data):\n",
    "\n",
    "    tasks = []\n",
    "\n",
    "    for i, el in data.iterrows():\n",
    "        userID = i \n",
    "        # if (len(chosen_ids) and userID in chosen_ids) or (not len(chosen_ids)):\n",
    "        \n",
    "        section = el[\"risks_limitations_bias\"]\n",
    "\n",
    "        messages = format_prompt(MESSAGES, userID, section)\n",
    "\n",
    "        task = {\n",
    "        \"custom_id\": f\"task-{int(userID)}\",\n",
    "        \"method\": \"POST\",\n",
    "        \"url\": \"/v1/chat/completions\",\n",
    "        \"body\": {\n",
    "            # This is what you would have in your Chat Completions API call\n",
    "            \"model\": \"gpt-4o\",\n",
    "            \"temperature\": 0,\n",
    "            \"response_format\": { \n",
    "                \"type\": \"json_object\"\n",
    "            },\n",
    "            \"messages\": messages,\n",
    "            }\n",
    "        }\n",
    "    \n",
    "        tasks.append(task)\n",
    "\n",
    "    return tasks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating the file\n",
    "\n",
    "file_name = \"batch_risks.jsonl\"\n",
    "\n",
    "tasks = batch_data(data=unique_risks)\n",
    "with open(file_name, 'w') as file:\n",
    "    for obj in tasks:\n",
    "        file.write(json.dumps(obj) + '\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Upload batch file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_file = client.files.create(\n",
    "  file=open(file_name, \"rb\"),\n",
    "  purpose=\"batch\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "FileObject(id='file-pu0CxC6ZYA6H7eU6IE8jjFJt', bytes=18714957, created_at=1721771322, filename='batch_risks.jsonl', object='file', purpose='batch', status='processed', status_details=None)"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch_file"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create batch job"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating the batch job\n",
    "batch_job = client.batches.create(\n",
    "  input_file_id=batch_file.id,\n",
    "  endpoint=\"/v1/chat/completions\",\n",
    "  completion_window=\"24h\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'batch_9AhgAKcRCNJpYZQYBOQUipBe'"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch_job.id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch(id='batch_9AhgAKcRCNJpYZQYBOQUipBe', completion_window='24h', created_at=1721771345, endpoint='/v1/chat/completions', input_file_id='file-pu0CxC6ZYA6H7eU6IE8jjFJt', object='batch', status='completed', cancelled_at=None, cancelling_at=None, completed_at=1721772241, error_file_id=None, errors=None, expired_at=None, expires_at=1721857745, failed_at=None, finalizing_at=1721772102, in_progress_at=1721771347, metadata=None, output_file_id='file-IBKWsO9FrIAdjfs8exfGXwyq', request_counts=BatchRequestCounts(completed=2672, failed=0, total=2672))\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Checking batch status\n",
    "batch_job = client.batches.retrieve(batch_job.id)\n",
    "print(batch_job)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Retrieve results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "result_file_id = batch_job.output_file_id\n",
    "result = client.files.content(result_file_id).content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "result_file_name = \"data/new_data/llm_analysis/LLM_risk_analysis_results_gppt4o.jsonl\"\n",
    "\n",
    "with open(result_file_name, 'wb') as file:\n",
    "    file.write(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import ast"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "result_file_name = \"data/new_data/llm_analysis/LLM_risk_analysis_results_gppt4o.jsonl\"\n",
    "# Loading data from saved file\n",
    "results = []\n",
    "with open(result_file_name, 'r') as file:\n",
    "    for line in file:\n",
    "        # Parsing the JSON string into a dict and appending to the list of results\n",
    "        json_object = json.loads(line.strip())\n",
    "        results.append(json_object)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'id': 'batch_req_5v7sbal5tOW52tLVh7Jryhhv', 'custom_id': 'task-0', 'response': {'status_code': 200, 'request_id': '7f8d8fa761a125ce444669d0e2674e1d', 'body': {'id': 'chatcmpl-9bbHdgi9kfoobiQRoc6cMYUKBLH9b', 'object': 'chat.completion', 'created': 1718748481, 'model': 'gpt-4o-2024-05-13', 'choices': [{'index': 0, 'message': {'role': 'assistant', 'content': '{\\n    \"cardID\": \"0\",\\n    \"section\": {\\n        \"about risks, bias or mitigations\": \"Yes\",\\n        \"risks_and_mitigations\": [\\n            {\\n                \"reference_text\": \"Even if the training data used for this model could be characterized as fairly neutral, this model can have biased predictions:\",\\n                \"type\": \"RISKS\",\\n                \"splits\": [\\n                    {\\n                        \"unique_risk_mitigation\": \"Produces biased predictions despite neutral training data.\",\\n                        \"type\": \"RISKS\"\\n                    }\\n                ]\\n            },\\n            {\\n                \"reference_text\": \"This bias will also affect all fine-tuned versions of this model.\",\\n                \"type\": \"RISKS\",\\n                \"splits\": [\\n                    {\\n                        \"unique_risk_mitigation\": \"Affects all fine-tuned versions of the model.\",\\n                        \"type\": \"RISKS\"\\n                    }\\n                ]\\n            }\\n        ],\\n        \"rating_of_section\": \"4\",\\n        \"reasoning\": \"The section effectively identifies the risk of biased predictions and notes that this bias will affect all fine-tuned versions of the model. However, it lacks specific mitigations to address these risks.\"\\n    }\\n}'}, 'logprobs': None, 'finish_reason': 'stop'}], 'usage': {'prompt_tokens': 1763, 'completion_tokens': 246, 'total_tokens': 2009}, 'system_fingerprint': 'fp_f4e629d0a5'}}, 'error': None}\n"
     ]
    }
   ],
   "source": [
    "for res in results:\n",
    "    print (res)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EOL while scanning string literal (<unknown>, line 7)\n",
      "{\n",
      "    \"cardID\": \"15688\",\n",
      "    \"section\": {\n",
      "        \"about risks, bias or mitigations\": \"Yes\",\n",
      "        \"risks_and_mitigations\": [\n",
      "            {\n",
      "                \"reference_text\": \"The eos token was not setup properly, so to prevent infinite generation you'll need to implement a stopping criteria when the model generates the \n"
     ]
    }
   ],
   "source": [
    "FULL_RES = []\n",
    "cnt_errors = []\n",
    "\n",
    "# Reading only the first results\n",
    "for res in results:\n",
    "    task_id = res['custom_id']\n",
    "    # Getting index from task id\n",
    "    index = task_id.split('-')[-1]\n",
    "    result = res['response']['body']['choices'][0]['message']['content']\n",
    "    try:\n",
    "        res = ast.literal_eval(result)\n",
    "        # print (index)\n",
    "        res[\"Incident ID\"] = int(index)\n",
    "        FULL_RES.append(res)\n",
    "    except Exception as e:\n",
    "        print (e)\n",
    "        print (result)\n",
    "        cnt_errors.append(index)\n",
    "        continue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['15688']"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cnt_errors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "###############################\n",
    "# save result\n",
    "with open(f\"data/new_data/llm_analysis/LLM_risk_analysis_results_gppt4o.json\", \"w\") as json_file:\n",
    "    json.dump(FULL_RES, json_file, indent=4)  # 4 spaces of indentation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Analyse Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "extracted_risks = pd.read_json(\"data/new_data/llm_analysis/LLM_risk_analysis_results_gppt4o.json\")\n",
    "# process them to contain clean strings\n",
    "risk_ref_list = []\n",
    "mit_ref_list = []\n",
    "risk_list = []\n",
    "mit_list = []\n",
    "\n",
    "for i, row in extracted_risks.iterrows():\n",
    "    risk_sentences = []\n",
    "    mit_sentences = []\n",
    "    risks = []\n",
    "    mits = []\n",
    "    if \"risks_and_mitigations\" in row[\"section\"].keys():\n",
    "        for sentence in row[\"section\"]['risks_and_mitigations']:\n",
    "            if sentence[\"type\"] == \"RISKS\" or sentence[\"type\"] == [\"RISKS\"]:\n",
    "                risk_sentences += sentence[\"reference_text\"] + ' ** '\n",
    "            if sentence[\"type\"] == \"MITIGATIONS\" or sentence[\"type\"] == [\"MITIGATIONS\"]:\n",
    "                mit_sentences += sentence[\"reference_text\"] + ' ** '\n",
    "\n",
    "            if \"splits\" in sentence.keys():\n",
    "                for split in sentence[\"splits\"]:\n",
    "                    if split[\"type\"] == \"RISKS\" or split[\"type\"] == [\"RISKS\"]:\n",
    "                        risks.append(split[\"unique_risk_mitigation\"])\n",
    "                    if split[\"type\"] == \"MITIGATIONS\" or split[\"type\"] == [\"MITIGATIONS\"]:\n",
    "                        mits.append(split[\"unique_risk_mitigation\"])\n",
    "\n",
    "    risk_ref_list.append(risk_sentences)\n",
    "    mit_ref_list.append(mit_sentences)\n",
    "    risk_list.append(risks)\n",
    "    mit_list.append(mits)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#  assign it to the dataframe\n",
    "extracted_risks[\"risk_reference\"] = risk_ref_list\n",
    "extracted_risks[\"mitigation_reference\"] = mit_ref_list\n",
    "extracted_risks[\"risks\"] = risk_list\n",
    "extracted_risks[\"mitigations\"] = mit_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>cardID</th>\n",
       "      <th>section</th>\n",
       "      <th>Incident ID</th>\n",
       "      <th>risk_reference</th>\n",
       "      <th>mitigation_reference</th>\n",
       "      <th>risks</th>\n",
       "      <th>mitigations</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2</td>\n",
       "      <td>{'about risks, bias or mitigations': 'Yes', 'r...</td>\n",
       "      <td>2</td>\n",
       "      <td>Even if the training data used for this model ...</td>\n",
       "      <td></td>\n",
       "      <td>Produces biased predictions despite neutral tr...</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4</td>\n",
       "      <td>{'about risks, bias or mitigations': 'Yes', 'r...</td>\n",
       "      <td>4</td>\n",
       "      <td>Even if the training data used for this model ...</td>\n",
       "      <td></td>\n",
       "      <td>Produces biased predictions despite neutral tr...</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5</td>\n",
       "      <td>{'about risks, bias or mitigations': 'Yes', 'r...</td>\n",
       "      <td>5</td>\n",
       "      <td>Certain use cases which would fall under the d...</td>\n",
       "      <td></td>\n",
       "      <td>Undermines safety and security when model is d...</td>\n",
       "      <td>Perform thorough in-domain testing. ** Perform...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>10</td>\n",
       "      <td>{'about risks, bias or mitigations': 'Yes', 'r...</td>\n",
       "      <td>10</td>\n",
       "      <td>Certain use cases which would fall under the d...</td>\n",
       "      <td></td>\n",
       "      <td>Undermines safety when deployed without thorou...</td>\n",
       "      <td>Perform thorough in-domain testing with a spec...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>11</td>\n",
       "      <td>{'about risks, bias or mitigations': 'Yes', 'r...</td>\n",
       "      <td>11</td>\n",
       "      <td>Even if the training data used for this model ...</td>\n",
       "      <td></td>\n",
       "      <td>Produces biased predictions despite neutral tr...</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2666</th>\n",
       "      <td>395164</td>\n",
       "      <td>{'about risks, bias or mitigations': 'Yes', 'r...</td>\n",
       "      <td>395164</td>\n",
       "      <td>The model, while powerful, may have limitation...</td>\n",
       "      <td>Users should verify the model's recommendation...</td>\n",
       "      <td>Underperforms in understanding highly speciali...</td>\n",
       "      <td>Verify the model's recommendations with curren...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2667</th>\n",
       "      <td>397247</td>\n",
       "      <td>{'about risks, bias or mitigations': 'Yes', 'r...</td>\n",
       "      <td>397247</td>\n",
       "      <td>The model was not trained to be factual or tru...</td>\n",
       "      <td></td>\n",
       "      <td>Underperforms in generating factual or true re...</td>\n",
       "      <td>Implement additional safety mechanisms and con...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2668</th>\n",
       "      <td>397368</td>\n",
       "      <td>{'about risks, bias or mitigations': 'No', 'ri...</td>\n",
       "      <td>397368</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2669</th>\n",
       "      <td>397779</td>\n",
       "      <td>{'about risks, bias or mitigations': 'Yes', 'r...</td>\n",
       "      <td>397779</td>\n",
       "      <td></td>\n",
       "      <td>Users should exercise caution and perform addi...</td>\n",
       "      <td>Underperforms in scenarios outside specific ge...</td>\n",
       "      <td>Perform additional testing for specific use ca...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2670</th>\n",
       "      <td>397827</td>\n",
       "      <td>{'about risks, bias or mitigations': 'Yes', 'r...</td>\n",
       "      <td>397827</td>\n",
       "      <td></td>\n",
       "      <td>Researchers should validate HSF's performance ...</td>\n",
       "      <td>Underperforms across different populations not...</td>\n",
       "      <td>Validate HSF's performance on specific dataset...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2671 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      cardID                                            section  Incident ID  \\\n",
       "0          2  {'about risks, bias or mitigations': 'Yes', 'r...            2   \n",
       "1          4  {'about risks, bias or mitigations': 'Yes', 'r...            4   \n",
       "2          5  {'about risks, bias or mitigations': 'Yes', 'r...            5   \n",
       "3         10  {'about risks, bias or mitigations': 'Yes', 'r...           10   \n",
       "4         11  {'about risks, bias or mitigations': 'Yes', 'r...           11   \n",
       "...      ...                                                ...          ...   \n",
       "2666  395164  {'about risks, bias or mitigations': 'Yes', 'r...       395164   \n",
       "2667  397247  {'about risks, bias or mitigations': 'Yes', 'r...       397247   \n",
       "2668  397368  {'about risks, bias or mitigations': 'No', 'ri...       397368   \n",
       "2669  397779  {'about risks, bias or mitigations': 'Yes', 'r...       397779   \n",
       "2670  397827  {'about risks, bias or mitigations': 'Yes', 'r...       397827   \n",
       "\n",
       "                                         risk_reference  \\\n",
       "0     Even if the training data used for this model ...   \n",
       "1     Even if the training data used for this model ...   \n",
       "2     Certain use cases which would fall under the d...   \n",
       "3     Certain use cases which would fall under the d...   \n",
       "4     Even if the training data used for this model ...   \n",
       "...                                                 ...   \n",
       "2666  The model, while powerful, may have limitation...   \n",
       "2667  The model was not trained to be factual or tru...   \n",
       "2668                                                      \n",
       "2669                                                      \n",
       "2670                                                      \n",
       "\n",
       "                                   mitigation_reference  \\\n",
       "0                                                         \n",
       "1                                                         \n",
       "2                                                         \n",
       "3                                                         \n",
       "4                                                         \n",
       "...                                                 ...   \n",
       "2666  Users should verify the model's recommendation...   \n",
       "2667                                                      \n",
       "2668                                                      \n",
       "2669  Users should exercise caution and perform addi...   \n",
       "2670  Researchers should validate HSF's performance ...   \n",
       "\n",
       "                                                  risks  \\\n",
       "0     Produces biased predictions despite neutral tr...   \n",
       "1     Produces biased predictions despite neutral tr...   \n",
       "2     Undermines safety and security when model is d...   \n",
       "3     Undermines safety when deployed without thorou...   \n",
       "4     Produces biased predictions despite neutral tr...   \n",
       "...                                                 ...   \n",
       "2666  Underperforms in understanding highly speciali...   \n",
       "2667  Underperforms in generating factual or true re...   \n",
       "2668                                                      \n",
       "2669  Underperforms in scenarios outside specific ge...   \n",
       "2670  Underperforms across different populations not...   \n",
       "\n",
       "                                            mitigations  \n",
       "0                                                        \n",
       "1                                                        \n",
       "2     Perform thorough in-domain testing. ** Perform...  \n",
       "3     Perform thorough in-domain testing with a spec...  \n",
       "4                                                        \n",
       "...                                                 ...  \n",
       "2666  Verify the model's recommendations with curren...  \n",
       "2667  Implement additional safety mechanisms and con...  \n",
       "2668                                                     \n",
       "2669  Perform additional testing for specific use ca...  \n",
       "2670  Validate HSF's performance on specific dataset...  \n",
       "\n",
       "[2671 rows x 7 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "extracted_risks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "extracted_risks.drop([\"Incident ID\"], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>cardID</th>\n",
       "      <th>section</th>\n",
       "      <th>risk_reference</th>\n",
       "      <th>mitigation_reference</th>\n",
       "      <th>risks</th>\n",
       "      <th>mitigations</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2</td>\n",
       "      <td>{'about risks, bias or mitigations': 'Yes', 'r...</td>\n",
       "      <td>Even if the training data used for this model ...</td>\n",
       "      <td></td>\n",
       "      <td>Produces biased predictions despite neutral tr...</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4</td>\n",
       "      <td>{'about risks, bias or mitigations': 'Yes', 'r...</td>\n",
       "      <td>Even if the training data used for this model ...</td>\n",
       "      <td></td>\n",
       "      <td>Produces biased predictions despite neutral tr...</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   cardID                                            section  \\\n",
       "0       2  {'about risks, bias or mitigations': 'Yes', 'r...   \n",
       "1       4  {'about risks, bias or mitigations': 'Yes', 'r...   \n",
       "\n",
       "                                      risk_reference mitigation_reference  \\\n",
       "0  Even if the training data used for this model ...                        \n",
       "1  Even if the training data used for this model ...                        \n",
       "\n",
       "                                               risks mitigations  \n",
       "0  Produces biased predictions despite neutral tr...              \n",
       "1  Produces biased predictions despite neutral tr...              "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "extracted_risks.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "extracted_risks = pd.read_json(\"data/new_data/llm_analysis/LLM_risk_analysis_results_gppt4o.json\")\n",
    "sentences = []\n",
    "split_sentences = []\n",
    "types = []\n",
    "split_types = []\n",
    "for i,row in extracted_risks.iterrows():\n",
    "    if \"risks_and_mitigations\" in row[\"section\"].keys():\n",
    "        for sentence in row[\"section\"]['risks_and_mitigations']:\n",
    "            sentences.append(sentence[\"reference_text\"])\n",
    "            if type(sentence[\"type\"]) != str : types.append(sentence[\"type\"][0])\n",
    "            else: types.append(sentence[\"type\"])\n",
    "            if \"splits\" in sentence.keys():\n",
    "                for split in sentence[\"splits\"]:\n",
    "                    split_sentences.append(split[\"unique_risk_mitigation\"])\n",
    "                    if type(split[\"type\"]) != str : split_types.append(split[\"type\"][0])\n",
    "                    else: split_types.append(split[\"type\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame({\"sentences\": sentences, \"types\": types})\n",
    "df_split = pd.DataFrame({\"sentences\": split_sentences, \"types\": split_types})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentences</th>\n",
       "      <th>types</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Produces biased predictions despite neutral tr...</td>\n",
       "      <td>RISKS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Produces biased predictions despite neutral tr...</td>\n",
       "      <td>RISKS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Transfers bias to all fine-tuned versions</td>\n",
       "      <td>RISKS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Undermines safety and security when model is d...</td>\n",
       "      <td>RISKS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Perform thorough in-domain testing.</td>\n",
       "      <td>MITIGATIONS</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           sentences        types\n",
       "0  Produces biased predictions despite neutral tr...        RISKS\n",
       "1  Produces biased predictions despite neutral tr...        RISKS\n",
       "2          Transfers bias to all fine-tuned versions        RISKS\n",
       "3  Undermines safety and security when model is d...        RISKS\n",
       "4                Perform thorough in-domain testing.  MITIGATIONS"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_split.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentences</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>types</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>MITIGATIONS</th>\n",
       "      <td>1462</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MIX OF BOTH</th>\n",
       "      <td>1753</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RISKS</th>\n",
       "      <td>4847</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             sentences\n",
       "types                 \n",
       "MITIGATIONS       1462\n",
       "MIX OF BOTH       1753\n",
       "RISKS             4847"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.groupby(['types']).count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentences</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>types</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>MITIGATIONS</th>\n",
       "      <td>3951</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RISKS</th>\n",
       "      <td>8926</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             sentences\n",
       "types                 \n",
       "MITIGATIONS       3951\n",
       "RISKS             8926"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_split.groupby(['types']).count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                    types\n",
      "sentences                                                \n",
      "Users (both direct and downstream) should be ma...    124\n",
      "This bias will also affect all fine-tuned versi...     46\n",
      "The model was not trained to be factual or true...     44\n",
      "Faces and people in general may not be generate...     37\n",
      "Testing conducted to date has been in English, ...     37\n",
      "...                                                   ...\n",
      "Limited Domain: The model's effectiveness may b...      1\n",
      "Limited Domain Expertise: While knowledgeable a...      1\n",
      "Limited Context: The model makes predictions ba...      1\n",
      "Limitations: The model's performance depends on...      1\n",
      "한편, 본 언어모델은 주로 한국어 텍스트로 학습되었으며, 이들의 특성을 전이할 수 있...      1\n",
      "\n",
      "[5356 rows x 1 columns]\n"
     ]
    }
   ],
   "source": [
    "a = df.groupby(['sentences']).count().sort_values(by='types', ascending=False)\n",
    "print (a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                    types\n",
      "sentences                                                \n",
      "Underperforms on non-English languages                 95\n",
      "Carries risks with use                                 49\n",
      "Produces factually incorrect output                    45\n",
      "Inform users about the risks, biases, and limit...     38\n",
      "Underperforms in non-English languages                 36\n",
      "...                                                   ...\n",
      "Consider using additional validation steps to e...      1\n",
      "Consult a licensed medical professional before ...      1\n",
      "Inform end-users about limitations and possible...      1\n",
      "Consult a qualified financial professional for ...      1\n",
      "Überprüfen Sie die Ausgaben.                            1\n",
      "\n",
      "[8153 rows x 1 columns]\n"
     ]
    }
   ],
   "source": [
    "b = df_split.groupby(['sentences']).count().sort_values(by='types', ascending=False)\n",
    "print (b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                    types\n",
      "sentences                                                \n",
      "Underperforms on non-English languages                 95\n",
      "Carries risks with use                                 49\n",
      "Produces factually incorrect output                    45\n",
      "Fails to cover all scenarios                           36\n",
      "Underperforms in non-English languages                 36\n",
      "...                                                   ...\n",
      "Hallucinates on questions about code commands           1\n",
      "Hallucinates on questions about Verus technolog...      1\n",
      "Hallucinates on advanced questions                      1\n",
      "Hallucinates new ships, prices, features not in...      1\n",
      "Yields inaccurate results for unrelated classif...      1\n",
      "\n",
      "[5396 rows x 1 columns]\n"
     ]
    }
   ],
   "source": [
    "risks_df = df_split[df_split['types'] == 'RISKS']\n",
    "c = risks_df.groupby(['sentences']).count().sort_values(by='types', ascending=False)\n",
    "print (c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "c.to_csv(\"data/new_data/unique_risks_count.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(8062, 2)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(12877, 2)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_split.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop_duplicates(subset=\"sentences\", keep=\"first\", inplace=True)\n",
    "df_split.drop_duplicates(subset=\"sentences\", keep=\"first\", inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5356, 2)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(8153, 2)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_split.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv(\"data/new_data/unique_risks_mitigations_gpto.csv\")\n",
    "df_split.to_csv(\"data/new_data/unique_risks_mitigation_splits_gpto.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentences</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>types</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>MITIGATIONS</th>\n",
       "      <td>948</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MIX OF BOTH</th>\n",
       "      <td>1182</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RISKS</th>\n",
       "      <td>3226</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             sentences\n",
       "types                 \n",
       "MITIGATIONS        948\n",
       "MIX OF BOTH       1182\n",
       "RISKS             3226"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.groupby(['types']).count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentences</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>types</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>MITIGATIONS</th>\n",
       "      <td>2759</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RISKS</th>\n",
       "      <td>5394</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             sentences\n",
       "types                 \n",
       "MITIGATIONS       2759\n",
       "RISKS             5394"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_split.groupby(['types']).count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ai-mitigations",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
