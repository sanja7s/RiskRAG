{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Adapt Risks to Uses\n",
    "Adapt the risks and mitigations matched from model cards to the use description."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "import json\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "from copy import deepcopy\n",
    "import time\n",
    "import ast\n",
    "import re\n",
    "import requests\n",
    "from openai import OpenAI"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### OpenAI setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from openai import OpenAI\n",
    "\n",
    "# Get the first key from the uploaded dictionary\n",
    "env_file_key = \"openai.env\"\n",
    "\n",
    "# Open the file and read its content\n",
    "with open(env_file_key, 'r', encoding='utf-8') as file:\n",
    "    env_content = file.read()\n",
    "\n",
    "api_key = env_content\n",
    "\n",
    "client = OpenAI(\n",
    "    # # This is the default and can be omitted\n",
    "    api_key=api_key,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def chat_gpt(prompt):\n",
    "    response = client.chat.completions.create(\n",
    "        model=\"gpt-4o\",\n",
    "        messages=prompt\n",
    "    )\n",
    "    return response.choices[0].message.content.strip()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# MESSAGES = [ { 'role': 'system', 'content': \"\"\"\n",
    "# Consider the following definitions: \n",
    "#     1) An AI incident is an event, circumstance or series of events where the development, use or malfunction of one or more AI systems directly or indirectly leads to any of the following harms: (a) injury or harm to the health of a person or groups of people; (b) disruption of the management and operation of critical infrastructure; (c) violations to human rights or a breach of obligations under the applicable law intended to protect fundamental, labour and intellectual property rights; (d) harm to property, communities or the environment.' The harm can be physical, psychological, reputational, economic/financial (including harm to property), environmental, public interest (e.g., protection of critical infrastructure and democratic institutions), human rights and fundamental rights. \n",
    "#     2) An AI risk is expressed as likelihood that harm or damage will occur. Risk is a function of both the probability of an event occurring and the severity of the consequences that would result. Risk is usually expressed in terms of risk sources, potential events, their consequences and their likelihood.  \"\"\" },\n",
    "\n",
    "# { 'role': 'user', 'content': \"\"\"You are provided in input with cardID, model description, a potential use of the model and a list of risks :\n",
    "# cardID: \"{}\", model_description: \"{}\", model_task: \"{}\", use: \"{}\", ai_user: \"{}\", ai_subject: \"{}\", institution: \"{}\" model_risks: \"{}\", aiid_risks: \"{}\".\n",
    "\n",
    "# Tasks:\n",
    "\n",
    "# (1) The main purpose of this task is to rephrase each unique risk to adapt it to the use provided. Output the risk ONLY AFTER ADAPTING IT TO THE USE. If some risks are redundant and similar to each other, skip the duplicates and rephrase ONLY UNIQUE risks. If some risks do not pertain to the model description or use, skip those. DO NOT INVENT ANY NEW RISKS. \n",
    "#  Guidelines:\n",
    "#  1. Understand Model Description, Model Task and Use: Thoroughly read and understand the specific context of the AI model being described, the task it is intended for and its application described in use.\n",
    "#  2. Identify Relevant Risks: There are two lists of risks. Identify unique risks from both lists that are relevant to the described model and use; skip those that are not. Remember the source of the risk. For the model_risks, check if it is relevant to the model description and model_task. If it is not, skip those. For the aiid_risks, check if it is relevant to the model_task and use. Skip those, if it is not relevant.\n",
    "#  3. Adapt Each Risk: Adapt each identified risk to the context of the model and use, ensuring it aligns with the specifics of the use. If the risk includes specific info which cannot be found in the model/use description, then do not impose the specificity on the adapted risk. Pay attention to the model_task. If the risk could not emanate from this type of model, do not adapt this risk.\n",
    "#  4. Format and Clarity: Verb + Object + [Explanation]. Start with an action verb in active present tense (e.g., undermines, discriminates, infringes, reduces, increases, underperforms, etc.). Be clear, and to-the-point, with a maximum of 20 words.\n",
    "#  5. Identify the subject at risk: For each adapted risk, identify the subject at risk from the list provided in input - ai_user, ai_subject and institution.\n",
    " \n",
    "#  Examples of Good Adaptation: \n",
    "#  1. The use description involves a facial recognition system.\n",
    "#     Reference Risk: Violates privacy rights.\n",
    "#     Adapted Risk: Undermines the right to privacy if the facial recognition data is not properly secured.\n",
    "#     Reasoning: Specifies how the privacy violation pertains to the facial recognition data. \n",
    "#  2. The model description involves a model fine-tuned on Western zodiac signs,\n",
    "#     Reference Risk: Overfits heavily due to training on a very small corpus.\n",
    "#     Adapted Risk: Overfits heavily due to fine-tuning on a small corpus of Western zodiac signs data.\n",
    "#     Reasoning: Specifies the small corpus context of Western zodiac signs.\n",
    "\n",
    "#  Examples of Bad Adaptation:\n",
    "#  1. The model description involves a model fine-tuned on Twitter dataset\n",
    "#     Reference Risk: Produces harmful content such as conspiracist views.\n",
    "#     Bad Adaptation: Generates harmful conspiratorial content.\n",
    "#     Good Adaptation: Produces harmful content such as conspiracist views common in Twitter data.\n",
    "#     Reasoning: The good adaptation specifies the source of the harmful content, aligning it with the Twitter data context.\n",
    "#  2. The use description involves a educational use case and model task is image classification\n",
    "#     Reference Risk: Underperforms due to limited genuine samples for Arabic.\n",
    "#     Bad Adaptation: Underperforms with educational content in Arabic due to limited data.\n",
    "#     Reasoning: This risk needs to be skipped as the model does not have anything to do with Arabic.\n",
    "#  3. The model task is image classification and use description involves a educational use case.\n",
    "#     Reference Risk: Generates offensive content harming reputations.\n",
    "#     Bad Adaptation: Generates offensive educational content impacting reputations.\n",
    "#     Reasoning: This risk needs to be skipped as the model is not about image generation.\n",
    " \n",
    "# Output Format: Ensure your output strictly follows this JSON structure.\n",
    "\n",
    "# {{\n",
    "#     \"cardID\": \"<Card ID>\",\n",
    "#     \"use\": \"<use>\"\n",
    "#     \"risks\": \n",
    "#     {{\n",
    "#         [\n",
    "#             {{\n",
    "#                 \"reference_risk\": \"Reference risk 1 from list\",\n",
    "#                 \"source\": \"model_risks or aiid_risks\",\n",
    "#                 \"adapted_risk\": \"Unique risk 1 adapted\",\n",
    "#                 \"reasoning\": \"reasoning\",\n",
    "#                 \"subject_at_risk\": \"<ai_user> or <ai_subject> or <institution>\"\n",
    "#             }},\n",
    "#             {{\n",
    "#                 \"reference_risk\": \"Reference risk 2 from list\",\n",
    "#                 \"source\": \"model_risks or aiid_risks\",\n",
    "#                 \"adapted_risk\": \"Unique risk 2 adapted\",\n",
    "#                 \"reasoning\": \"reasoning\",\n",
    "#                 \"subject_at_risk\": \"<ai_user> or <ai_subject> or <institution>\"\n",
    "#             }},\n",
    "#             ...\n",
    "#         ]\n",
    "#     }},\n",
    "# }}\n",
    "\n",
    "\n",
    "# Important Notes: Do not report your reasoning steps or any preamble like 'Here is the output', '```json ...```', ONLY the JSON result. In scenarios where there are no sentences mentioned, provide an empty JSON array for those sections.\n",
    "\n",
    "# *** Double Check your output that it contains only the requested JSON and nothing else. *** \"\"\"\n",
    "\n",
    "# } ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "MESSAGES = [ { 'role': 'system', 'content': \"\"\"\n",
    "Consider the following definitions: \n",
    "    1) An AI incident is an event, circumstance or series of events where the development, use or malfunction of one or more AI systems directly or indirectly leads to any of the following harms: (a) injury or harm to the health of a person or groups of people; (b) disruption of the management and operation of critical infrastructure; (c) violations to human rights or a breach of obligations under the applicable law intended to protect fundamental, labour and intellectual property rights; (d) harm to property, communities or the environment.' The harm can be physical, psychological, reputational, economic/financial (including harm to property), environmental, public interest (e.g., protection of critical infrastructure and democratic institutions), human rights and fundamental rights. \n",
    "    2) An AI risk is expressed as likelihood that harm or damage will occur. Risk is a function of both the probability of an event occurring and the severity of the consequences that would result. Risk is usually expressed in terms of risk sources, potential events, their consequences and their likelihood.  \"\"\" },\n",
    "\n",
    "{ 'role': 'user', 'content': \"\"\"You are provided in input with cardID, model description, a potential use of the model and a list of risks :\n",
    "cardID: \"{}\", model_description: \"{}\", model_task: \"{}\", use: \"{}\", ai_user: \"{}\", ai_subject: \"{}\", institution: \"{}\" model_risks: \"{}\", aiid_risks: \"{}\".\n",
    "\n",
    "Tasks:\n",
    "\n",
    "(1) The main purpose of this task is to map each unique risk to the use provided. Output the risk ONLY AFTER MAPPING IT TO THE USE. If some risks are redundant and similar to each other, skip the duplicates and map ONLY UNIQUE risks. If some risks do not pertain to the model description or use, skip those. DO NOT INVENT ANY NEW RISKS. \n",
    " Guidelines:\n",
    " 1. Understand Model Description, Model Task and Use: Thoroughly read and understand the specific context of the AI model being described, the task it is intended for and its application described in use.\n",
    " 2. Identify Relevant Risks: There are two lists of risks. Identify unique risks from both lists that are relevant to the described model and use; skip those that are not. Remember the source of the risk. For the model_risks, check if it is relevant to the model description and model_task. If it is not, skip those. For the aiid_risks, check if it is relevant to the model_task and use. Skip those, if it is not relevant.\n",
    " 3. Identify the subject at risk: For each mapped risk, identify the subject at risk from the list provided in input - ai_user, ai_subject and institution.\n",
    " \n",
    " Examples: \n",
    " 1. The use description involves a facial recognition system.\n",
    "    Reference Risk: Violates privacy rights.\n",
    "    Maps to the use: Yes\n",
    "    Reasoning: Privacy violation pertains to the facial recognition data. \n",
    " 2. The model description involves a model fine-tuned on Western zodiac signs,\n",
    "    Reference Risk: Overfits heavily due to training on a very small corpus.\n",
    "    Maps to the use: Yes\n",
    "    Reasoning: Pertains to the small corpus context of Western zodiac signs.\n",
    " 3. The use description involves a educational use case and model task is image classification\n",
    "    Reference Risk: Underperforms due to limited genuine samples for Arabic.\n",
    "    Maps to the use: No\n",
    "    Reasoning: This risk needs to be skipped as the model does not have anything to do with Arabic.\n",
    " 3. The model task is image classification and use description involves a educational use case.\n",
    "    Reference Risk: Generates offensive content harming reputations.\n",
    "    Maps to the use: No\n",
    "    Reasoning: This risk needs to be skipped as the model task is not about image generation.\n",
    " \n",
    "Output Format: Ensure your output strictly follows this JSON structure. Ouput only relevant risks. No need to output skipped risks.\n",
    "\n",
    "{{\n",
    "    \"cardID\": \"<Card ID>\",\n",
    "    \"use\": \"<use>\"\n",
    "    \"risks\": \n",
    "    {{\n",
    "        [\n",
    "            {{\n",
    "                \"reference_risk\": \"Reference risk 1 from list\",\n",
    "                \"source\": \"model_risks or aiid_risks\",\n",
    "                \"reasoning\": \"reasoning\",\n",
    "                \"subject_at_risk\": \"<ai_user> or <ai_subject> or <institution>\"\n",
    "            }},\n",
    "            {{\n",
    "                \"reference_risk\": \"Reference risk 2 from list\",\n",
    "                \"source\": \"model_risks or aiid_risks\",\n",
    "                \"reasoning\": \"reasoning\",\n",
    "                \"subject_at_risk\": \"<ai_user> or <ai_subject> or <institution>\"\n",
    "            }},\n",
    "            ...\n",
    "        ]\n",
    "    }},\n",
    "}}\n",
    "\n",
    "\n",
    "Important Notes: Do not report your reasoning steps or any preamble like 'Here is the output', '```json ...```', ONLY the JSON result. In scenarios where there are no sentences mentioned, provide an empty JSON array for those sections.\n",
    "\n",
    "*** Double Check your output that it contains only the requested JSON and nothing else. *** \"\"\"\n",
    "\n",
    "} ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def format_prompt(MESSAGES, cardID, desc, task, use, ai_user, ai_subject, institution, model_risks, aiid_risks): \n",
    "    messages = deepcopy(MESSAGES) \n",
    "    messages[1]['content'] = messages[1]['content'].format(cardID, desc, task, use, ai_user, ai_subject, institution, model_risks, aiid_risks) \n",
    "    return messages"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prepare data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data_file = \"data/new_data/results/matched_risks_besttest_aiid_Linq-Embed-Mistral_top5.csv\"\n",
    "# data_file = \"data/new_data/results/matched_risks_user_study_aiid_Linq-Embed-Mistral_top10_12percent_taxonomy.csv\"\n",
    "data_file = \"data/new_data/results/matched_risks_user_study_aiid_Linq-Embed-Mistral_top10_taxonomy.csv\"\n",
    "card_file = \"data/new_data/unique_risks_without_model_cards_v3.json\"\n",
    "data = pd.read_csv(data_file, index_col=\"test_index\")\n",
    "risk_cards = pd.read_json(card_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.drop('Unnamed: 0', axis=1, inplace=True )\n",
    "data.dropna(subset=\"use1\", inplace=True, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>modelId</th>\n",
       "      <th>author</th>\n",
       "      <th>creation_time</th>\n",
       "      <th>last_modified</th>\n",
       "      <th>downloads</th>\n",
       "      <th>likes</th>\n",
       "      <th>library_name</th>\n",
       "      <th>tags</th>\n",
       "      <th>pipeline_tag</th>\n",
       "      <th>card_data_language</th>\n",
       "      <th>card_data_license</th>\n",
       "      <th>card_data_library_name</th>\n",
       "      <th>card_data_tags</th>\n",
       "      <th>card_data_base_model</th>\n",
       "      <th>card_data_datasets</th>\n",
       "      <th>model_card_metadata</th>\n",
       "      <th>risks_limitations_bias</th>\n",
       "      <th>risk_section_len</th>\n",
       "      <th>model_description</th>\n",
       "      <th>model_desc_len</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>facebook/fasttext-language-identification</td>\n",
       "      <td>facebook</td>\n",
       "      <td>2023-03-06 12:52:50</td>\n",
       "      <td>2023-06-09T12:39:43+00:00</td>\n",
       "      <td>53352708</td>\n",
       "      <td>135</td>\n",
       "      <td>fasttext</td>\n",
       "      <td>[fasttext, text-classification, language-ident...</td>\n",
       "      <td>text-classification</td>\n",
       "      <td>None</td>\n",
       "      <td>cc-by-nc-4.0</td>\n",
       "      <td>fasttext</td>\n",
       "      <td>[text-classification, language-identification]</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>{'base_model': None, 'datasets': None, 'eval_r...</td>\n",
       "      <td>### Limitations and bias\\n\\nEven if the traini...</td>\n",
       "      <td>786</td>\n",
       "      <td>## Model description\\n\\nfastText is a library...</td>\n",
       "      <td>741</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>google-bert/bert-base-uncased</td>\n",
       "      <td>google-bert</td>\n",
       "      <td>2022-03-02 23:29:04</td>\n",
       "      <td>2024-02-19T11:06:12+00:00</td>\n",
       "      <td>44931654</td>\n",
       "      <td>1678</td>\n",
       "      <td>transformers</td>\n",
       "      <td>[transformers, pytorch, tf, jax, rust, coreml,...</td>\n",
       "      <td>fill-mask</td>\n",
       "      <td>en</td>\n",
       "      <td>apache-2.0</td>\n",
       "      <td>None</td>\n",
       "      <td>[exbert]</td>\n",
       "      <td>None</td>\n",
       "      <td>[bookcorpus, wikipedia]</td>\n",
       "      <td>{'base_model': None, 'datasets': ['bookcorpus'...</td>\n",
       "      <td>### Limitations and bias\\n\\nEven if the traini...</td>\n",
       "      <td>1783</td>\n",
       "      <td>## Model description\\n\\nBERT is a transformer...</td>\n",
       "      <td>1498</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                     modelId       author       creation_time  \\\n",
       "2  facebook/fasttext-language-identification     facebook 2023-03-06 12:52:50   \n",
       "4              google-bert/bert-base-uncased  google-bert 2022-03-02 23:29:04   \n",
       "\n",
       "               last_modified  downloads  likes  library_name  \\\n",
       "2  2023-06-09T12:39:43+00:00   53352708    135      fasttext   \n",
       "4  2024-02-19T11:06:12+00:00   44931654   1678  transformers   \n",
       "\n",
       "                                                tags         pipeline_tag  \\\n",
       "2  [fasttext, text-classification, language-ident...  text-classification   \n",
       "4  [transformers, pytorch, tf, jax, rust, coreml,...            fill-mask   \n",
       "\n",
       "  card_data_language card_data_license card_data_library_name  \\\n",
       "2               None      cc-by-nc-4.0               fasttext   \n",
       "4                 en        apache-2.0                   None   \n",
       "\n",
       "                                   card_data_tags card_data_base_model  \\\n",
       "2  [text-classification, language-identification]                 None   \n",
       "4                                        [exbert]                 None   \n",
       "\n",
       "        card_data_datasets                                model_card_metadata  \\\n",
       "2                     None  {'base_model': None, 'datasets': None, 'eval_r...   \n",
       "4  [bookcorpus, wikipedia]  {'base_model': None, 'datasets': ['bookcorpus'...   \n",
       "\n",
       "                              risks_limitations_bias  risk_section_len  \\\n",
       "2  ### Limitations and bias\\n\\nEven if the traini...               786   \n",
       "4  ### Limitations and bias\\n\\nEven if the traini...              1783   \n",
       "\n",
       "                                   model_description  model_desc_len  \n",
       "2   ## Model description\\n\\nfastText is a library...             741  \n",
       "4   ## Model description\\n\\nBERT is a transformer...            1498  "
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "risk_cards.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>test_description</th>\n",
       "      <th>similar_indices</th>\n",
       "      <th>matched_description</th>\n",
       "      <th>matched_risks</th>\n",
       "      <th>matched_axis1_target_of_analysis</th>\n",
       "      <th>matched_axis2_risk_area_main</th>\n",
       "      <th>matched_axis3_module_main</th>\n",
       "      <th>matched_mitigations</th>\n",
       "      <th>matched_risk_sections</th>\n",
       "      <th>test_risks</th>\n",
       "      <th>test_mitigations</th>\n",
       "      <th>similar_indices_aiid</th>\n",
       "      <th>matched_description_aiid</th>\n",
       "      <th>matched_risks_aiid</th>\n",
       "      <th>use1</th>\n",
       "      <th>use2</th>\n",
       "      <th>use3</th>\n",
       "      <th>use4</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>test_index</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>## Model description\\n\\nOPT was predominantl...</td>\n",
       "      <td>[528, 769, 308, 927, 1334, 3114, 3229, 3457, 9...</td>\n",
       "      <td>['  ## Model description\\n\\nOPT was predominan...</td>\n",
       "      <td>Underperforms in nonresearch environments** In...</td>\n",
       "      <td>capability** capability** capability** capabil...</td>\n",
       "      <td>Representation &amp; Toxicity Harms** Representati...</td>\n",
       "      <td>Language Model Module** Language Model Module*...</td>\n",
       "      <td>** ** ** ** ** ** ** Perform responsible best ...</td>\n",
       "      <td>### Limitations and bias\\n\\nAs mentioned in Me...</td>\n",
       "      <td>Contains unfiltered content from the internet ...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[399, 357, 339, 85, 532, 367, 259, 443, 473, 179]</td>\n",
       "      <td>['Meta AI trained and hosted a scientific pape...</td>\n",
       "      <td>Violates academic policies by using unauthoriz...</td>\n",
       "      <td>{\\n        \"Use\": 11,\\n        \"Domain\": \"Reco...</td>\n",
       "      <td>{\\n        \"Use\": 16,\\n        \"Domain\": \"Mar...</td>\n",
       "      <td>{\\n        \"Use\": 8,\\n        \"Domain\": \"Educa...</td>\n",
       "      <td>{\\n        \"Use\": 14,\\n        \"Domain\": \"Arts...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>82</th>\n",
       "      <td>## Model Summary\\n\\nThe Phi-...</td>\n",
       "      <td>[36138, 532, 56473, 1125, 58339, 43506, 29344,...</td>\n",
       "      <td>['                 ## Model Summary\\r\\n\\r\\nThe...</td>\n",
       "      <td>Erases representation of some groups** Underpe...</td>\n",
       "      <td>capability** capability** systemic** capabilit...</td>\n",
       "      <td>Representation &amp; Toxicity Harms** Representati...</td>\n",
       "      <td>Language Model Module** Language Model Module*...</td>\n",
       "      <td>Implement additional mitigations for sensitive...</td>\n",
       "      <td>## Responsible AI Considerations\\r\\n\\r\\nLike o...</td>\n",
       "      <td>Underperforms on non-English languages ** Unde...</td>\n",
       "      <td>Implement additional mitigations for sensitive...</td>\n",
       "      <td>[262, 473, 356, 552, 468, 571, 287, 278, 85, 399]</td>\n",
       "      <td>['Publicly deployed open-source model DALL-E M...</td>\n",
       "      <td>Undermines security measures by solving CAPTCH...</td>\n",
       "      <td>{\\n        \"Use\": 11,\\n        \"Domain\": \"Reco...</td>\n",
       "      <td>{\\n        \"Use\": 16,\\n        \"Domain\": \"...</td>\n",
       "      <td>{\\n        \"Use\": 8,\\n        \"Domain\": \"Educa...</td>\n",
       "      <td>{\\n        \"Use\": 12,\\n        \"Domain\": \"Soci...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>93</th>\n",
       "      <td>## Model Description\\n\\n`Stable Beluga 2` is...</td>\n",
       "      <td>[9679, 6187, 5947, 6152, 942, 26314, 5816, 325...</td>\n",
       "      <td>[' ## Model Description\\n\\n`Stable Beluga 1` i...</td>\n",
       "      <td>Generates nondeterministic responses due to mo...</td>\n",
       "      <td>capability** capability** capability** capabil...</td>\n",
       "      <td>Misinformation Harms** Human Autonomy &amp; Integr...</td>\n",
       "      <td>Language Model Module** Language Model Module*...</td>\n",
       "      <td>Perform safety testing ** Tune model to specif...</td>\n",
       "      <td>### Ethical Considerations and Limitations\\n\\n...</td>\n",
       "      <td>Carries risks with use ** Underperforms in non...</td>\n",
       "      <td>Perform safety testing ** Perform tuning tailo...</td>\n",
       "      <td>[314, 578, 451, 421, 278, 465, 505, 179, 399, ...</td>\n",
       "      <td>['Stable Diffusion, an open-source image gener...</td>\n",
       "      <td>Violates copyright law by unauthorized use of ...</td>\n",
       "      <td>{\\n        \"Use\": 11,\\n        \"Domain\": \"Reco...</td>\n",
       "      <td>{\\n        \"Use\": 16,\\n        \"Domain\": \"...</td>\n",
       "      <td>{\\n        \"Use\": 8,\\n        \"Domain\": \"Educa...</td>\n",
       "      <td>{\\n        \"Use\": 4,\\n        \"Domain\": \"H...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>231</th>\n",
       "      <td>## Model description\\n\\nThe text-to-video gen...</td>\n",
       "      <td>[225146, 40258, 47919, 23293, 26746, 34506, 23...</td>\n",
       "      <td>['  ## Model Details\\n\\n* **Developed by:** [L...</td>\n",
       "      <td>Cannot render legible text** Biases towards wh...</td>\n",
       "      <td>capability** capability** capability** capabil...</td>\n",
       "      <td>Information &amp; Safety Harms** Representation &amp; ...</td>\n",
       "      <td>Output Module** Language Model Module** Langua...</td>\n",
       "      <td>** ** Approach DeciDiffusion with discretion. ...</td>\n",
       "      <td>## Limitations\\n\\n* Limited knowledge of tempo...</td>\n",
       "      <td>Underperforms in generating realistic represen...</td>\n",
       "      <td>Prohibit generating demeaning or harmful conte...</td>\n",
       "      <td>[314, 486, 421, 529, 465, 504, 451, 578, 179, ...</td>\n",
       "      <td>['Stable Diffusion, an open-source image gener...</td>\n",
       "      <td>Violates copyright law by unauthorized use of ...</td>\n",
       "      <td>{\\n        \"Use\": 12,\\n        \"Domain\": \"Soci...</td>\n",
       "      <td>{\\n        \"Use\": 16,\\n        \"Domain\": \"Mark...</td>\n",
       "      <td>{\\n        \"Use\": 8,\\n        \"Domain\": \"Educa...</td>\n",
       "      <td>{\\n        \"Use\": 5,\\n        \"Domain\": \"Well-...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1490</th>\n",
       "      <td># Model Description\\n- **Developed by**: Natur...</td>\n",
       "      <td>[12415, 13198, 259, 54, 4480, 6407, 129265, 76...</td>\n",
       "      <td>[' # Model Description\\n- **Developed by**: Na...</td>\n",
       "      <td>Cannot render legible text** Underperforms wit...</td>\n",
       "      <td>capability** capability** capability** capabil...</td>\n",
       "      <td>Information &amp; Safety Harms** Representation &amp; ...</td>\n",
       "      <td>Output Module** Language Model Module** Langua...</td>\n",
       "      <td>** Investigate and improve image quality in th...</td>\n",
       "      <td>## Limitations\\n- The model does not achieve p...</td>\n",
       "      <td>Underperforms in achieving perfect photorealis...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[314, 421, 351, 259, 339, 578, 464, 240, 465, ...</td>\n",
       "      <td>['Stable Diffusion, an open-source image gener...</td>\n",
       "      <td>Violates academic policies by using unauthoriz...</td>\n",
       "      <td>{\\n        \"Use\": 12,\\n        \"Domain\": \"Soci...</td>\n",
       "      <td>{\\n        \"Use\": 16,\\n        \"Domain\": \"Mark...</td>\n",
       "      <td>{\\n        \"Use\": 8,\\n        \"Domain\": \"Educa...</td>\n",
       "      <td>{\\n        \"Use\": 5,\\n        \"Domain\": \"W...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             test_description  \\\n",
       "test_index                                                      \n",
       "44            ## Model description\\n\\nOPT was predominantl...   \n",
       "82                            ## Model Summary\\n\\nThe Phi-...   \n",
       "93            ## Model Description\\n\\n`Stable Beluga 2` is...   \n",
       "231          ## Model description\\n\\nThe text-to-video gen...   \n",
       "1490        # Model Description\\n- **Developed by**: Natur...   \n",
       "\n",
       "                                              similar_indices  \\\n",
       "test_index                                                      \n",
       "44          [528, 769, 308, 927, 1334, 3114, 3229, 3457, 9...   \n",
       "82          [36138, 532, 56473, 1125, 58339, 43506, 29344,...   \n",
       "93          [9679, 6187, 5947, 6152, 942, 26314, 5816, 325...   \n",
       "231         [225146, 40258, 47919, 23293, 26746, 34506, 23...   \n",
       "1490        [12415, 13198, 259, 54, 4480, 6407, 129265, 76...   \n",
       "\n",
       "                                          matched_description  \\\n",
       "test_index                                                      \n",
       "44          ['  ## Model description\\n\\nOPT was predominan...   \n",
       "82          ['                 ## Model Summary\\r\\n\\r\\nThe...   \n",
       "93          [' ## Model Description\\n\\n`Stable Beluga 1` i...   \n",
       "231         ['  ## Model Details\\n\\n* **Developed by:** [L...   \n",
       "1490        [' # Model Description\\n- **Developed by**: Na...   \n",
       "\n",
       "                                                matched_risks  \\\n",
       "test_index                                                      \n",
       "44          Underperforms in nonresearch environments** In...   \n",
       "82          Erases representation of some groups** Underpe...   \n",
       "93          Generates nondeterministic responses due to mo...   \n",
       "231         Cannot render legible text** Biases towards wh...   \n",
       "1490        Cannot render legible text** Underperforms wit...   \n",
       "\n",
       "                             matched_axis1_target_of_analysis  \\\n",
       "test_index                                                      \n",
       "44          capability** capability** capability** capabil...   \n",
       "82          capability** capability** systemic** capabilit...   \n",
       "93          capability** capability** capability** capabil...   \n",
       "231         capability** capability** capability** capabil...   \n",
       "1490        capability** capability** capability** capabil...   \n",
       "\n",
       "                                 matched_axis2_risk_area_main  \\\n",
       "test_index                                                      \n",
       "44          Representation & Toxicity Harms** Representati...   \n",
       "82          Representation & Toxicity Harms** Representati...   \n",
       "93          Misinformation Harms** Human Autonomy & Integr...   \n",
       "231         Information & Safety Harms** Representation & ...   \n",
       "1490        Information & Safety Harms** Representation & ...   \n",
       "\n",
       "                                    matched_axis3_module_main  \\\n",
       "test_index                                                      \n",
       "44          Language Model Module** Language Model Module*...   \n",
       "82          Language Model Module** Language Model Module*...   \n",
       "93          Language Model Module** Language Model Module*...   \n",
       "231         Output Module** Language Model Module** Langua...   \n",
       "1490        Output Module** Language Model Module** Langua...   \n",
       "\n",
       "                                          matched_mitigations  \\\n",
       "test_index                                                      \n",
       "44          ** ** ** ** ** ** ** Perform responsible best ...   \n",
       "82          Implement additional mitigations for sensitive...   \n",
       "93          Perform safety testing ** Tune model to specif...   \n",
       "231         ** ** Approach DeciDiffusion with discretion. ...   \n",
       "1490        ** Investigate and improve image quality in th...   \n",
       "\n",
       "                                        matched_risk_sections  \\\n",
       "test_index                                                      \n",
       "44          ### Limitations and bias\\n\\nAs mentioned in Me...   \n",
       "82          ## Responsible AI Considerations\\r\\n\\r\\nLike o...   \n",
       "93          ### Ethical Considerations and Limitations\\n\\n...   \n",
       "231         ## Limitations\\n\\n* Limited knowledge of tempo...   \n",
       "1490        ## Limitations\\n- The model does not achieve p...   \n",
       "\n",
       "                                                   test_risks  \\\n",
       "test_index                                                      \n",
       "44          Contains unfiltered content from the internet ...   \n",
       "82          Underperforms on non-English languages ** Unde...   \n",
       "93          Carries risks with use ** Underperforms in non...   \n",
       "231         Underperforms in generating realistic represen...   \n",
       "1490        Underperforms in achieving perfect photorealis...   \n",
       "\n",
       "                                             test_mitigations  \\\n",
       "test_index                                                      \n",
       "44                                                        NaN   \n",
       "82          Implement additional mitigations for sensitive...   \n",
       "93          Perform safety testing ** Perform tuning tailo...   \n",
       "231         Prohibit generating demeaning or harmful conte...   \n",
       "1490                                                      NaN   \n",
       "\n",
       "                                         similar_indices_aiid  \\\n",
       "test_index                                                      \n",
       "44          [399, 357, 339, 85, 532, 367, 259, 443, 473, 179]   \n",
       "82          [262, 473, 356, 552, 468, 571, 287, 278, 85, 399]   \n",
       "93          [314, 578, 451, 421, 278, 465, 505, 179, 399, ...   \n",
       "231         [314, 486, 421, 529, 465, 504, 451, 578, 179, ...   \n",
       "1490        [314, 421, 351, 259, 339, 578, 464, 240, 465, ...   \n",
       "\n",
       "                                     matched_description_aiid  \\\n",
       "test_index                                                      \n",
       "44          ['Meta AI trained and hosted a scientific pape...   \n",
       "82          ['Publicly deployed open-source model DALL-E M...   \n",
       "93          ['Stable Diffusion, an open-source image gener...   \n",
       "231         ['Stable Diffusion, an open-source image gener...   \n",
       "1490        ['Stable Diffusion, an open-source image gener...   \n",
       "\n",
       "                                           matched_risks_aiid  \\\n",
       "test_index                                                      \n",
       "44          Violates academic policies by using unauthoriz...   \n",
       "82          Undermines security measures by solving CAPTCH...   \n",
       "93          Violates copyright law by unauthorized use of ...   \n",
       "231         Violates copyright law by unauthorized use of ...   \n",
       "1490        Violates academic policies by using unauthoriz...   \n",
       "\n",
       "                                                         use1  \\\n",
       "test_index                                                      \n",
       "44          {\\n        \"Use\": 11,\\n        \"Domain\": \"Reco...   \n",
       "82          {\\n        \"Use\": 11,\\n        \"Domain\": \"Reco...   \n",
       "93          {\\n        \"Use\": 11,\\n        \"Domain\": \"Reco...   \n",
       "231         {\\n        \"Use\": 12,\\n        \"Domain\": \"Soci...   \n",
       "1490        {\\n        \"Use\": 12,\\n        \"Domain\": \"Soci...   \n",
       "\n",
       "                                                         use2  \\\n",
       "test_index                                                      \n",
       "44           {\\n        \"Use\": 16,\\n        \"Domain\": \"Mar...   \n",
       "82              {\\n        \"Use\": 16,\\n        \"Domain\": \"...   \n",
       "93              {\\n        \"Use\": 16,\\n        \"Domain\": \"...   \n",
       "231         {\\n        \"Use\": 16,\\n        \"Domain\": \"Mark...   \n",
       "1490        {\\n        \"Use\": 16,\\n        \"Domain\": \"Mark...   \n",
       "\n",
       "                                                         use3  \\\n",
       "test_index                                                      \n",
       "44          {\\n        \"Use\": 8,\\n        \"Domain\": \"Educa...   \n",
       "82          {\\n        \"Use\": 8,\\n        \"Domain\": \"Educa...   \n",
       "93          {\\n        \"Use\": 8,\\n        \"Domain\": \"Educa...   \n",
       "231         {\\n        \"Use\": 8,\\n        \"Domain\": \"Educa...   \n",
       "1490        {\\n        \"Use\": 8,\\n        \"Domain\": \"Educa...   \n",
       "\n",
       "                                                         use4  \n",
       "test_index                                                     \n",
       "44          {\\n        \"Use\": 14,\\n        \"Domain\": \"Arts...  \n",
       "82          {\\n        \"Use\": 12,\\n        \"Domain\": \"Soci...  \n",
       "93              {\\n        \"Use\": 4,\\n        \"Domain\": \"H...  \n",
       "231         {\\n        \"Use\": 5,\\n        \"Domain\": \"Well-...  \n",
       "1490            {\\n        \"Use\": 5,\\n        \"Domain\": \"W...  "
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_newlines_and_indentations(input_string):\n",
    "    # Replace newline characters with an empty string\n",
    "    no_newlines = input_string.replace(\"\\n\", \"\")\n",
    "    \n",
    "    # Strip leading and trailing spaces from each line and concatenate them\n",
    "    no_indentations = \"\".join(line.strip() for line in no_newlines.splitlines())\n",
    "    \n",
    "    return no_indentations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Use': 16,\n",
       " 'Domain': 'Marketing and Advertising',\n",
       " 'Purpose': 'Creating personalized ad campaigns',\n",
       " 'Capability': 'Analyzing user behavior from social media posts',\n",
       " 'AI User': 'Marketing agencies',\n",
       " 'AI Subject': 'Consumers'}"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ast.literal_eval(remove_newlines_and_indentations(data[\"use2\"][82]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('## Model Details\\n\\n+ **Model Name**: Segments-Sidewalk-SegFormer-B0\\n+ **Model Type**: Semantic Segmentation\\n+ **Base Model**: nvidia/segformer-b0-finetuned-ade-512-512\\n+ **Fine-Tuning Dataset**: Sidewalk-Semantic ## Model Description\\n\\nThe **Segments-Sidewalk-SegFormer-B0** model is a semantic segmentation model fine-tuned on the **sidewalk-semantic** dataset. It is based on the **SegFormer (b0-sized)** architecture and has been adapted for the task of segmenting sidewalk images into various classes, such as road surfaces, pedestrians, vehicles, and more.      ',\n",
       " 'Reinforces social biases $$ Exacerbates social biases $$ Lacks diversity in dataset $$ Is not representative in dataset $$ Focuses on celebrities only $$ ** ** ** ** Underperforms on images with different characteristics from the training dataset. $$ Struggles with very small or very large objects in images. $$ Inherits biases present in the training data, such as underrepresentation of certain classes. $$ Leads to harm in applications like medical diagnosis and autonomous driving if segmentation is incorrect. $$ ',\n",
       " 'Fails to moderate harmful content due to insufficient AI capabilities for small language groups** Neglects small language groups due to lack of investment in human moderation** Increases misinformation spread due to inadequate AI moderation for specific languages** Undermines user safety due to ineffective content moderation in small language groups** Violates community standards due to poor AI moderation in less common languages** Reinforces racial stereotypes by generating biased images** Reinforces gender stereotypes by generating biased images** Discriminates against marginalized groups by perpetuating harmful biases** Endangers pedestrian safety by not yielding to detected pedestrians** Violates traffic laws by ignoring state law signs** Undermines public trust in autonomous vehicles due to non-compliance with traffic regulations** Misaligns vehicle on the road due to inadequate lane detection** Damages vehicle components due to improper navigation** Increases accident risk due to failure in maintaining lane discipline** Fails to detect obstacles due to limitations in object recognition** Endangers pedestrians due to inadequate situational awareness** Causes accidents due to overreliance on autonomous driving systems',\n",
       " 'image-segmentation')"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "use = \"**Urban Planning** **Purpose:** Designing pedestrian-friendly areas **Capability:** Identifying sidewalk usage from images **AI User:** City planners **AI Subject:** City residents\"\n",
    "data[\"test_description\"][42785], data[\"matched_risks\"][42785], data[\"matched_risks_aiid\"][42785], risk_cards[\"pipeline_tag\"][42785]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(' ## Model Details\\n\\nThe CLIP model was developed by researchers at OpenAI to learn about what contributes to robustness in computer vision tasks. The model was also developed to test the ability of models to generalize to arbitrary image classification tasks in a zero-shot manner. It was not developed for general model deployment - to deploy models like CLIP, researchers will first need to carefully study their capabilities in relation to the specific context theyâ€™re being deployed within.                  ',\n",
       " 'Undermines safety when deployed without thorough in-domain testing. $$ Undermines fair use due to lack of testing norms and checks. $$ Underperforms on non-English languages. $$ Underperforms on fine-grained classification and counting objects. $$ Poses issues with fairness and bias. $$ Underestimates model performance due to use of linear probes. $$ Exhibits biases depending on class design and category choices. $$ Discriminates based on race and gender in denigration tasks. $$ Shifts disparities based on class construction. $$ Underperforms on age classification. $$ Surfaces potential risks in gender, race, and age classification. $$ ** Undermines safety when deployed without thorough in-domain testing. $$ Undermines privacy in surveillance and facial recognition use cases. $$ Underperforms on non-English languages. $$ ** Inherits limitations and biases from the original CLIP model $$ Associates aspects of clothing with specific people due to gender assumptions $$ Underperforms in shorter queries due to long captions in the dataset $$ Biases towards standard product images with centered, white background $$ Uses poor selection criteria for out-of-domain generalization $$ ** Includes disturbing and harmful stereotypes across protected classes $$ Includes disturbing and harmful stereotypes across identity characteristics $$ Includes disturbing and harmful stereotypes across sensitive, social, and occupational groups $$ Depends significantly on class design and category choices $$ Exhibits significant disparities with respect to race and gender $$ Shifts disparities based on class construction $$ Underperforms on age classification with ~63% accuracy $$ ** Underperforms in counting beyond 3. $$ Underperforms due to limited genuine samples for Arabic. $$ Introduces biases due to lack of studies on Arabic datasets. $$ Introduces gender bias due to two-gender system in Arabic. $$ Introduces gender bias during translation from English to Arabic. $$ ',\n",
       " 'Generates disinformation by creating misleading or false images** Produces explicit content that can be harmful or inappropriate** Discriminates against specific groups of people due to gender bias in image generation** Discriminates against specific groups of people due to racial bias in image generation** Reinforces racial stereotypes by generating biased images** Reinforces gender stereotypes by generating biased images** Discriminates against marginalized groups by perpetuating harmful biases** Undermines security measures by solving CAPTCHAs intended to prevent automated access** Violates user trust by bypassing safeguards designed to restrict certain functionalities** Produces inaccurate scientific information undermining research integrity** Prohibits legitimate queries restricting academic freedom** Generates offensive content harming reputations** Facilitates misinformation spreading false knowledge** Facilitates illegal activities by enabling creation of explicit and violent chatbots** Promotes harmful behavior by indulging in violent and abusive role-playing scenarios** Violates human rights by participating in text-based simulations of rape and abuse** Undermines public trust in AI by allowing misuse of open-source models for unethical purposes** Increases psychological harm by exposing users to graphic and explicit content')"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "use = \"**Education and vocational training** **Purpose:** Providing visual learning aids **Capability:** Classifying educational images **AI User:** Teachers, educational platforms **AI Subject:** Students\"\n",
    "data[\"test_description\"][5], data[\"matched_risks\"][5], data[\"matched_risks_aiid\"][5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('## Model Details\\n\\n+ **Model Name**: Segments-Sidewalk-SegFormer-B0\\n+ **Model Type**: Semantic Segmentation\\n+ **Base Model**: nvidia/segformer-b0-finetuned-ade-512-512\\n+ **Fine-Tuning Dataset**: Sidewalk-Semantic ## Model Description\\n\\nThe **Segments-Sidewalk-SegFormer-B0** model is a semantic segmentation model fine-tuned on the **sidewalk-semantic** dataset. It is based on the **SegFormer (b0-sized)** architecture and has been adapted for the task of segmenting sidewalk images into various classes, such as road surfaces, pedestrians, vehicles, and more.      ',\n",
       " 'Reinforces social biases $$ Exacerbates social biases $$ Lacks diversity in dataset $$ Is not representative in dataset $$ Focuses on celebrities only $$ ** ** ** ** Underperforms on images with different characteristics from the training dataset. $$ Struggles with very small or very large objects in images. $$ Inherits biases present in the training data, such as underrepresentation of certain classes. $$ Leads to harm in applications like medical diagnosis and autonomous driving if segmentation is incorrect. $$ ',\n",
       " 'Fails to moderate harmful content due to insufficient AI capabilities for small language groups** Neglects small language groups due to lack of investment in human moderation** Increases misinformation spread due to inadequate AI moderation for specific languages** Undermines user safety due to ineffective content moderation in small language groups** Violates community standards due to poor AI moderation in less common languages** Reinforces racial stereotypes by generating biased images** Reinforces gender stereotypes by generating biased images** Discriminates against marginalized groups by perpetuating harmful biases** Endangers pedestrian safety by not yielding to detected pedestrians** Violates traffic laws by ignoring state law signs** Undermines public trust in autonomous vehicles due to non-compliance with traffic regulations** Misaligns vehicle on the road due to inadequate lane detection** Damages vehicle components due to improper navigation** Increases accident risk due to failure in maintaining lane discipline** Fails to detect obstacles due to limitations in object recognition** Endangers pedestrians due to inadequate situational awareness** Causes accidents due to overreliance on autonomous driving systems',\n",
       " 'image-segmentation')"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "use = \"**Essential private services and public services and benefits** **Purpose:** Improving public infrastructure **Capability:** Assessing sidewalk accessibility **AI User:** Municipal authorities **AI Subject:** Citizens\"\n",
    "data[\"test_description\"][42785], data[\"matched_risks\"][42785], data[\"matched_risks_aiid\"][42785], risk_cards[\"pipeline_tag\"][42785]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "messages = format_prompt(MESSAGES, cardID=42785, desc=data[\"test_description\"][42785], task=risk_cards[\"pipeline_tag\"][42785], use=use, model_risks=data[\"matched_risks\"][42785], aiid_risks=data[\"matched_risks_aiid\"][42785])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'role': 'system',\n",
       "  'content': \"\\nConsider the following definitions: \\n    1) An AI incident is an event, circumstance or series of events where the development, use or malfunction of one or more AI systems directly or indirectly leads to any of the following harms: (a) injury or harm to the health of a person or groups of people; (b) disruption of the management and operation of critical infrastructure; (c) violations to human rights or a breach of obligations under the applicable law intended to protect fundamental, labour and intellectual property rights; (d) harm to property, communities or the environment.' The harm can be physical, psychological, reputational, economic/financial (including harm to property), environmental, public interest (e.g., protection of critical infrastructure and democratic institutions), human rights and fundamental rights. \\n    2) An AI risk is expressed as likelihood that harm or damage will occur. Risk is a function of both the probability of an event occurring and the severity of the consequences that would result. Risk is usually expressed in terms of risk sources, potential events, their consequences and their likelihood.  \"},\n",
       " {'role': 'user',\n",
       "  'content': 'You are provided in input with cardID, model description, a potential use of the model and a list of risks :\\ncardID: \"42785\", model_description: \"## Model Details\\n\\n+ **Model Name**: Segments-Sidewalk-SegFormer-B0\\n+ **Model Type**: Semantic Segmentation\\n+ **Base Model**: nvidia/segformer-b0-finetuned-ade-512-512\\n+ **Fine-Tuning Dataset**: Sidewalk-Semantic ## Model Description\\n\\nThe **Segments-Sidewalk-SegFormer-B0** model is a semantic segmentation model fine-tuned on the **sidewalk-semantic** dataset. It is based on the **SegFormer (b0-sized)** architecture and has been adapted for the task of segmenting sidewalk images into various classes, such as road surfaces, pedestrians, vehicles, and more.      \", model_task: \"image-segmentation\", use: \"**Essential private services and public services and benefits** **Purpose:** Improving public infrastructure **Capability:** Assessing sidewalk accessibility **AI User:** Municipal authorities **AI Subject:** Citizens\", model_risks: \"Reinforces social biases $$ Exacerbates social biases $$ Lacks diversity in dataset $$ Is not representative in dataset $$ Focuses on celebrities only $$ ** ** ** ** Underperforms on images with different characteristics from the training dataset. $$ Struggles with very small or very large objects in images. $$ Inherits biases present in the training data, such as underrepresentation of certain classes. $$ Leads to harm in applications like medical diagnosis and autonomous driving if segmentation is incorrect. $$ \", aiid_risks: \"Fails to moderate harmful content due to insufficient AI capabilities for small language groups** Neglects small language groups due to lack of investment in human moderation** Increases misinformation spread due to inadequate AI moderation for specific languages** Undermines user safety due to ineffective content moderation in small language groups** Violates community standards due to poor AI moderation in less common languages** Reinforces racial stereotypes by generating biased images** Reinforces gender stereotypes by generating biased images** Discriminates against marginalized groups by perpetuating harmful biases** Endangers pedestrian safety by not yielding to detected pedestrians** Violates traffic laws by ignoring state law signs** Undermines public trust in autonomous vehicles due to non-compliance with traffic regulations** Misaligns vehicle on the road due to inadequate lane detection** Damages vehicle components due to improper navigation** Increases accident risk due to failure in maintaining lane discipline** Fails to detect obstacles due to limitations in object recognition** Endangers pedestrians due to inadequate situational awareness** Causes accidents due to overreliance on autonomous driving systems\".\\n\\nTasks:\\n\\n(1) The main purpose of this task is to rephrase each unique risk to adapt it to the use provided. Output the risk ONLY AFTER ADAPTING IT TO THE USE. If some risks are redundant and similar to each other, skip the duplicates and rephrase ONLY UNIQUE risks. If some risks do not pertain to the model description or use, skip those. DO NOT INVENT ANY NEW RISKS. \\n Guidelines:\\n 1. Understand Model Description, Model Task and Use: Thoroughly read and understand the specific context of the AI model being described, the task it is intended for and its application described in use.\\n 2. Identify Relevant Risks: There are two lists of risks. Identify unique risks from both lists that are relevant to the described model and use; skip those that are not. Remember the source of the risk. For the model_risks, check if it is relevant to the model description and model_task. If it is not, skip those. For the aiid_risks, check if it is relevant to the model_task and use. Skip those, if it is not relevant.\\n 3. Adapt Each Risk: Adapt each identified risk to the context of the model and use, ensuring it aligns with the specifics of the use. If the risk includes specific info which cannot be found in the model/use description, then do not impose the specificity on the adapted risk. Pay attention to the model_task. If the risk could not emanate from this type of model, do not adapt this risk.\\n 4. Format and Clarity: Verb + Object + [Explanation]. Start with an action verb in active present tense (e.g., undermines, discriminates, infringes, reduces, increases, underperforms, etc.). Be clear, and to-the-point, with a maximum of 20 words.\\n 5. Identify the subject at risk: For each adapted risk, identify the subject at risk from the list - AI user, AI subject and institutions and environment. Both AI user and AI subject should be taken from the use in input where as the institutions and environment are in general.\\n \\n Examples of Good Adaptation: \\n 1. The use description involves a facial recognition system.\\n    Reference Risk: Violates privacy rights.\\n    Adapted Risk: Undermines the right to privacy if the facial recognition data is not properly secured.\\n    Reasoning: Specifies how the privacy violation pertains to the facial recognition data. \\n 2. The model description involves a model fine-tuned on Western zodiac signs,\\n    Reference Risk: Overfits heavily due to training on a very small corpus.\\n    Adapted Risk: Overfits heavily due to fine-tuning on a small corpus of Western zodiac signs data.\\n    Reasoning: Specifies the small corpus context of Western zodiac signs.\\n\\n Examples of Bad Adaptation:\\n 1. The use description involves a model fine-tuned on Twitter dataset\\n    Reference Risk: Produces harmful content such as conspiracist views.\\n    Bad Adaptation: Generates harmful conspiratorial content.\\n    Good Adaptation: Produces harmful content such as conspiracist views common in Twitter data.\\n    Reasoning: The good adaptation specifies the source of the harmful content, aligning it with the Twitter data context.\\n 2. The use description involves a educational use case and model task is image classification\\n    Reference Risk: Underperforms due to limited genuine samples for Arabic.\\n    Bad Adaptation: Underperforms with educational content in Arabic due to limited data.\\n    Reasoning: This risk needs to be skipped as the model does not have anything to do with Arabic\\n \\nOutput Format: Ensure your output strictly follows this JSON structure.\\n\\n{\\n    \"cardID\": \"<Card ID>\",\\n    \"use\": \"<use>\"\\n    \"risks\": \\n    {\\n        [\\n            {\\n                \"reference_risk\": \"Reference risk 1 from list\",\\n                \"source\": \"model_risks or aiid_risks\",\\n                \"adapted_risk\": \"Unique risk 1 adapted\",\\n                \"reasoning\": \"reasoning\",\\n                \"subject_at_risk\": \"AI user or AI subject or Institution and Environment\"\\n            },\\n            {\\n                \"reference_risk\": \"Reference risk 2 from list\",\\n                \"source\": \"model_risks or aiid_risks\",\\n                \"adapted_risk\": \"Unique risk 2 adapted\",\\n                \"reasoning\": \"reasoning\",\\n                \"subject_at_risk\": \"\"AI user or AI subject or Institution and Environment\"\\n            },\\n            ...\\n        ]\\n    },\\n}\\n\\n\\nImportant Notes: Do not report your reasoning steps or any preamble like \\'Here is the output\\', \\'```json ...```\\', ONLY the JSON result. In scenarios where there are no sentences mentioned, provide an empty JSON array for those sections.\\n\\n*** Double Check your output that it contains only the requested JSON and nothing else. *** '}]"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "messages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "response = chat_gpt(messages)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'{\\n    \"cardID\": \"42785\",\\n    \"use\": \"**Essential private services and public services and benefits** **Purpose:** Improving public infrastructure **Capability:** Assessing sidewalk accessibility **AI User:** Municipal authorities **AI Subject:** Citizens\",\\n    \"risks\": \\n    [\\n        {\\n            \"reference_risk\": \"Reinforces social biases\",\\n            \"source\": \"model_risks\",\\n            \"adapted_risk\": \"Reinforces social biases in assessing sidewalk accessibility.\",\\n            \"reasoning\": \"The model may inherit biases from the training data, affecting the fairness of sidewalk accessibility assessments.\",\\n            \"subject_at_risk\": \"AI subject\"\\n        },\\n        {\\n            \"reference_risk\": \"Lacks diversity in dataset\",\\n            \"source\": \"model_risks\",\\n            \"adapted_risk\": \"Lacks diversity in dataset, undermining sidewalk accessibility evaluations.\",\\n            \"reasoning\": \"A non-representative dataset may not account for diverse sidewalk conditions.\",\\n            \"subject_at_risk\": \"AI user\"\\n        },\\n        {\\n            \"reference_risk\": \"Is not representative in dataset\",\\n            \"source\": \"model_risks\",\\n            \"adapted_risk\": \"Fails to represent diverse sidewalk scenarios, reducing model effectiveness.\",\\n            \"reasoning\": \"An unrepresentative dataset limits the model\\'s generalization to various sidewalk conditions.\",\\n            \"subject_at_risk\": \"AI user\"\\n        },\\n        {\\n            \"reference_risk\": \"Underperforms on images with different characteristics from the training dataset.\",\\n            \"source\": \"model_risks\",\\n            \"adapted_risk\": \"Underperforms on sidewalk images differing from training data.\",\\n            \"reasoning\": \"The model may struggle with new sidewalk images not seen during training.\",\\n            \"subject_at_risk\": \"AI user\"\\n        },\\n        {\\n            \"reference_risk\": \"Struggles with very small or very large objects in images.\",\\n            \"source\": \"model_risks\",\\n            \"adapted_risk\": \"Struggles to accurately segment very small or large objects on sidewalks.\",\\n            \"reasoning\": \"Extreme object sizes could affect segmentation quality in sidewalk assessments.\",\\n            \"subject_at_risk\": \"AI user\"\\n        },\\n        {\\n            \"reference_risk\": \"Inherits biases present in the training data, such as underrepresentation of certain classes.\",\\n            \"source\": \"model_risks\",\\n            \"adapted_risk\": \"Inherits biases, leading to underrepresentation of certain sidewalk classes.\",\\n            \"reasoning\": \"Biased training data perpetuates underrepresentation in the model\\'s output.\",\\n            \"subject_at_risk\": \"AI subject\"\\n        }\\n    ]\\n}'"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Batch the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "def batch_data(data=data):\n",
    "\n",
    "    tasks = []\n",
    "    for i, row in data.iterrows():\n",
    "        print (i)\n",
    "        for u in [\"use1\", \"use2\", \"use3\", \"use4\"]:\n",
    "            use = ast.literal_eval(remove_newlines_and_indentations(row[u]))\n",
    "            ai_user = use['AI User']\n",
    "            ai_subj = use['AI Subject']\n",
    "            use = \"Domain-- \"+use['Domain']+', '+\"Purpose-- \"+use['Purpose']+', '+\"Capability-- \"+use['Capability']\n",
    "            print (use) \n",
    "            messages = format_prompt(MESSAGES, cardID=i, desc=row[\"test_description\"], task=risk_cards[\"pipeline_tag\"][i], use=use, ai_user=ai_user, ai_subject=ai_subj, institution=\"Institution and Environment\", model_risks=row[\"matched_risks\"], aiid_risks=row[\"matched_risks_aiid\"])\n",
    "\n",
    "            task = {\n",
    "            \"custom_id\": f\"task-{int(i)}\",\n",
    "            \"method\": \"POST\",\n",
    "            \"url\": \"/v1/chat/completions\",\n",
    "            \"body\": {\n",
    "                # This is what you would have in your Chat Completions API call\n",
    "                \"model\": \"gpt-4o\",\n",
    "                \"temperature\": 0,\n",
    "                \"response_format\": { \n",
    "                    \"type\": \"json_object\"\n",
    "                },\n",
    "                \"messages\": messages,\n",
    "                }\n",
    "            }\n",
    "    \n",
    "            tasks.append(task)\n",
    "\n",
    "    return tasks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "44\n",
      "Domain-- Recommender Systems and Personalization, Purpose-- Recommending personalized content, Capability-- Analyzing user preferences and suggesting items\n",
      "Domain-- Marketing and Advertising, Purpose-- Creating personalized ad copy, Capability-- Generating tailored messages from user data\n",
      "Domain-- Education and vocational training, Purpose-- Personalizing learning experiences, Capability-- Analyzing student performance and tailoring content\n",
      "Domain-- Arts and Entertainment, Purpose-- Generating creative writing prompts, Capability-- Analyzing themes and creating prompts\n",
      "82\n",
      "Domain-- Recommender Systems and Personalization, Purpose-- Recommending personalized content, Capability-- Analyzing preferences for suggestions\n",
      "Domain-- Marketing and Advertising, Purpose-- Creating personalized ad campaigns, Capability-- Analyzing user behavior from social media posts\n",
      "Domain-- Education and vocational training, Purpose-- Personalizing learning experiences, Capability-- Analyzing student performance and tailoring content\n",
      "Domain-- Social Media, Purpose-- Moderating harmful content, Capability-- Detecting inappropriate posts\n",
      "93\n",
      "Domain-- Recommender Systems and Personalization, Purpose-- Recommending personalized content, Capability-- Analyzing preferences for suggestions\n",
      "Domain-- Marketing and Advertising, Purpose-- Creating personalized ad campaigns, Capability-- Analyzing user behavior from social media posts\n",
      "Domain-- Education and vocational training, Purpose-- Personalizing learning experiences, Capability-- Analyzing student performance and tailoring content\n",
      "Domain-- Health and Healthcare, Purpose-- Assisting in medical diagnoses, Capability-- Analyzing patient data and suggesting conditions\n",
      "231\n",
      "Domain-- Social Media, Purpose-- Generating engaging social media content, Capability-- Creating videos from trending topics\n",
      "Domain-- Marketing and Advertising, Purpose-- Creating engaging promotional videos, Capability-- Generating videos from marketing text\n",
      "Domain-- Education and vocational training, Purpose-- Creating educational content, Capability-- Generating instructional videos from text\n",
      "Domain-- Well-being, Purpose-- Creating guided meditation videos, Capability-- Generating calming visuals from text\n",
      "1490\n",
      "Domain-- Social Media, Purpose-- Creating engaging social media posts, Capability-- Generating GIFs from user content\n",
      "Domain-- Marketing and Advertising, Purpose-- Creating engaging promotional content, Capability-- Generating GIFs from marketing text\n",
      "Domain-- Education and vocational training, Purpose-- Creating educational animations, Capability-- Generating GIFs from lesson content\n",
      "Domain-- Well-being, Purpose-- Creating motivational content, Capability-- Generating GIFs from wellness quotes\n"
     ]
    }
   ],
   "source": [
    "# Creating the file\n",
    "\n",
    "file_name = \"batch_risks.jsonl\"\n",
    "\n",
    "tasks = batch_data(data=data)\n",
    "with open(file_name, 'w') as file:\n",
    "    for obj in tasks:\n",
    "        file.write(json.dumps(obj) + '\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "20"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(tasks)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Upload batch file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_file = client.files.create(\n",
    "  file=open(file_name, \"rb\"),\n",
    "  purpose=\"batch\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "FileObject(id='file-uwVuhNk1r6umjV86gmQ8aSmb', bytes=91356, created_at=1722117795, filename='batch_risks.jsonl', object='file', purpose='batch', status='processed', status_details=None)"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch_file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "responses = []\n",
    "for task in tasks:\n",
    "    messages = task[\"body\"][\"messages\"]\n",
    "    response = chat_gpt(messages)\n",
    "    responses.append(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['{\\n    \"cardID\": \"44\",\\n    \"use\": \"Domain-- Recommender Systems and Personalization, Purpose-- Recommending personalized content, Capability-- Analyzing user preferences and suggesting items\",\\n    \"risks\": [\\n        {\\n            \"reference_risk\": \"Induces bias and safety issues due to lack of diverse training data\",\\n            \"source\": \"model_risks\",\\n            \"reasoning\": \"Lack of diverse training data can result in biased recommendations which can influence user preferences unfairly.\",\\n            \"subject_at_risk\": \"ai_subject\"\\n        },\\n        {\\n            \"reference_risk\": \"Produces low diversity and hallucinated outputs\",\\n            \"source\": \"model_risks\",\\n            \"reasoning\": \"Low diversity in generated content can limit the range of personalized recommendations, potentially reducing user engagement.\",\\n            \"subject_at_risk\": \"ai_subject\"\\n        },\\n        {\\n            \"reference_risk\": \"Has quality issues in terms of generation diversity\",\\n            \"source\": \"model_risks\",\\n            \"reasoning\": \"Quality issues in generation can impact the precision and relevance of recommended content.\",\\n            \"subject_at_risk\": \"ai_subject\"\\n        },\\n        {\\n            \"reference_risk\": \"Generates hallucinations\",\\n            \"source\": \"model_risks\",\\n            \"reasoning\": \"Hallucinated outputs can mislead users, harming their experience through incorrect recommendations.\",\\n            \"subject_at_risk\": \"ai_subject\"\\n        },\\n        {\\n            \"reference_risk\": \"Exhibits biases\",\\n            \"source\": \"model_risks\",\\n            \"reasoning\": \"Biases in recommendations can propagate stereotypical or unfair content, adversely impacting user experience.\",\\n            \"subject_at_risk\": \"ai_subject\"\\n        },\\n        {\\n            \"reference_risk\": \"Contains biased training data from the internet\",\\n            \"source\": \"model_risks\",\\n            \"reasoning\": \"Biased training data can result in recommendations that reinforce negative stereotypes.\",\\n            \"subject_at_risk\": \"ai_subject\"\\n        },\\n        {\\n            \"reference_risk\": \"Produces factual inaccuracies\",\\n            \"source\": \"model_risks\",\\n            \"reasoning\": \"Factual inaccuracies in recommendations can affect the credibility of the streaming platform.\",\\n            \"subject_at_risk\": \"ai_user\"\\n        },\\n        {\\n            \"reference_risk\": \"Generates toxic content\",\\n            \"source\": \"model_risks\",\\n            \"reasoning\": \"Toxic content in recommendations can harm user trust and the platform\\'s reputation.\",\\n            \"subject_at_risk\": \"ai_subject\"\\n        },\\n        {\\n            \"reference_risk\": \"Enforces stereotypes\",\\n            \"source\": \"model_risks\",\\n            \"reasoning\": \"Content suggestions that reinforce stereotypes can cause social harm and limit user diversity in content consumption.\",\\n            \"subject_at_risk\": \"ai_subject\"\\n        },\\n        {\\n            \"reference_risk\": \"Produces offensive responses\",\\n            \"source\": \"model_risks\",\\n            \"reasoning\": \"Offensive content recommendations can harm user trust and negatively affect user experience.\",\\n            \"subject_at_risk\": \"ai_subject\"\\n        },\\n        {\\n            \"reference_risk\": \"Increases social division by amplifying extremist viewpoints\",\\n            \"source\": \"aiid_risks\",\\n            \"reasoning\": \"Recommendations that promote extremist content can lead to social divisiveness.\",\\n            \"subject_at_risk\": \"institution\"\\n        },\\n        {\\n            \"reference_risk\": \"Harms community wellbeing by spreading toxic and harmful messages\",\\n            \"source\": \"aiid_risks\",\\n            \"reasoning\": \"Personalized recommendations that include toxic content can damage the community\\'s overall wellbeing.\",\\n            \"subject_at_risk\": \"ai_subject\"\\n        },\\n        {\\n            \"reference_risk\": \"Facilitates misinformation spreading false knowledge\",\\n            \"source\": \"aiid_risks\",\\n            \"reasoning\": \"Inaccurate content recommendations can contribute to the spread of misinformation.\",\\n            \"subject_at_risk\": \"ai_subject\"\\n        },\\n        {\\n            \"reference_risk\": \"Undermines public trust in AI by demonstrating misuse of AI technology\",\\n            \"source\": \"aiid_risks\",\\n            \"reasoning\": \"Misuse of AI in personalized recommendations can erode public trust in AI technologies overall.\",\\n            \"subject_at_risk\": \"institution\"\\n        },\\n        {\\n            \"reference_risk\": \"Undermines trust in AI systems by failing to protect user data\",\\n            \"source\": \"aiid_risks\",\\n            \"reasoning\": \"If the AI model compromises user data privacy, it can weaken trust in the streaming platform.\",\\n            \"subject_at_risk\": \"ai_user\"\\n        },\\n        {\\n            \"reference_risk\": \"Damages reputations by associating individuals or groups with offensive content\",\\n            \"source\": \"aiid_risks\",\\n            \"reasoning\": \"Recommendations that include or link to offensive content can harm reputations of individuals or groups featured in that content.\",\\n            \"subject_at_risk\": \"ai_subject\"\\n        },\\n        {\\n            \"reference_risk\": \"Violates privacy rights by disclosing sensitive personal data\",\\n            \"source\": \"aiid_risks\",\\n            \"reasoning\": \"If the model recommendations inadvertently reveal sensitive user data, it violates user privacy rights.\",\\n            \"subject_at_risk\": \"ai_user\"\\n        }\\n    ]\\n}',\n",
       " '{\\n    \"cardID\": \"44\",\\n    \"use\": \"Domain-- Marketing and Advertising, Purpose-- Creating personalized ad copy, Capability-- Generating tailored messages from user data\",\\n    \"risks\": [\\n        {\\n            \"reference_risk\": \"Underperforms in nonresearch environments\",\\n            \"source\": \"model_risks\",\\n            \"reasoning\": \"The model might not achieve the desired performance in practical marketing scenarios since it is trained in research settings.\",\\n            \"subject_at_risk\": \"ai_user\"\\n        },\\n        {\\n            \"reference_risk\": \"Induces bias and safety issues due to lack of diverse training data\",\\n            \"source\": \"model_risks\",\\n            \"reasoning\": \"Bias from non-diverse training data can affect the fairness and safety of generated ad content.\",\\n            \"subject_at_risk\": \"ai_subject\"\\n        },\\n        {\\n            \"reference_risk\": \"Produces low diversity and hallucinated outputs\",\\n            \"source\": \"model_risks\",\\n            \"reasoning\": \"Low diversity and hallucinations can reduce the quality and reliability of generated ad copy, affecting marketing effectiveness.\",\\n            \"subject_at_risk\": \"ai_user\"\\n        },\\n        {\\n            \"reference_risk\": \"Produces toxic content\",\\n            \"source\": \"model_risks\",\\n            \"reasoning\": \"Generated ad content might include offensive or harmful language, damaging brand reputation.\",\\n            \"subject_at_risk\": \"ai_subject\"\\n        },\\n        {\\n            \"reference_risk\": \"Generates factual inaccuracies\",\\n            \"source\": \"model_risks\",\\n            \"reasoning\": \"Inaccurate information in ad copy can mislead consumers and harm the credibility of marketing campaigns.\",\\n            \"subject_at_risk\": \"ai_subject\"\\n        },\\n        {\\n            \"reference_risk\": \"Contains biased training data from the internet\",\\n            \"source\": \"model_risks\",\\n            \"reasoning\": \"Biases in the training data can lead to biased ad content, negatively affecting consumer perception.\",\\n            \"subject_at_risk\": \"ai_subject\"\\n        },\\n        {\\n            \"reference_risk\": \"Undermines public trust in AI by demonstrating misuse of AI technology\",\\n            \"source\": \"aiid_risks\",\\n            \"reasoning\": \"Misuse in marketing could erode consumer trust in AI-generated content.\",\\n            \"subject_at_risk\": \"institution\"\\n        },\\n        {\\n            \"reference_risk\": \"Generates disinformation by creating misleading or false images\",\\n            \"source\": \"aiid_risks\",\\n            \"reasoning\": \"Generating misleading ad content can harm consumer trust and lead to legal repercussions.\",\\n            \"subject_at_risk\": \"ai_subject\"\\n        },\\n        {\\n            \"reference_risk\": \"Generates offensive content harming reputations\",\\n            \"source\": \"aiid_risks\",\\n            \"reasoning\": \"Offensive content can damage the reputation of the marketing agency or the brand.\",\\n            \"subject_at_risk\": \"ai_user\"\\n        }\\n    ]\\n}',\n",
       " '{\\n    \"cardID\": \"44\",\\n    \"use\": \"Domain-- Education and vocational training, Purpose-- Personalizing learning experiences, Capability-- Analyzing student performance and tailoring content\",\\n    \"risks\": \\n    [\\n        {\\n            \"reference_risk\": \"Underperforms compared to state-of-the-art models\",\\n            \"source\": \"model_risks\",\\n            \"reasoning\": \"This can affect the personalization and accuracy in analyzing student performance and tailoring content.\",\\n            \"subject_at_risk\": \"Students\"\\n        },\\n        {\\n            \"reference_risk\": \"Produces low diversity and hallucinated outputs\",\\n            \"source\": \"model_risks\",\\n            \"reasoning\": \"Hallucinated outputs can mislead students, reducing the quality of personalized learning experiences.\",\\n            \"subject_at_risk\": \"Students\"\\n        },\\n        {\\n            \"reference_risk\": \"Has quality issues in terms of generation diversity\",\\n            \"source\": \"model_risks\",\\n            \"reasoning\": \"Lack of diversity in generated content can inhibit comprehensive educational outcomes.\",\\n            \"subject_at_risk\": \"Students\"\\n        },\\n        {\\n            \"reference_risk\": \"Generates factual inaccuracies\",\\n            \"source\": \"model_risks\",\\n            \"reasoning\": \"Factual inaccuracies can misinform students, negatively affecting their learning.\",\\n            \"subject_at_risk\": \"Students\"\\n        },\\n        {\\n            \"reference_risk\": \"Produces offensive responses\",\\n            \"source\": \"model_risks\",\\n            \"reasoning\": \"Offensive content can harm students\\' experience and trust in the educational platform.\",\\n            \"subject_at_risk\": \"Students\"\\n        },\\n        {\\n            \"reference_risk\": \"Exhibits biases\",\\n            \"source\": \"model_risks\",\\n            \"reasoning\": \"Bias in content can lead to unfair educational outcomes and propagate stereotypes.\",\\n            \"subject_at_risk\": \"Students\"\\n        },\\n        {\\n            \"reference_risk\": \"Generates toxic language\",\\n            \"source\": \"model_risks\",\\n            \"reasoning\": \"Toxic language can cause psychological harm and undermine the learning environment.\",\\n            \"subject_at_risk\": \"Students\"\\n        },\\n        {\\n            \"reference_risk\": \"Undermines factual correctness\",\\n            \"source\": \"model_risks\",\\n            \"reasoning\": \"Incorrect facts can directly harm the educational value.\",\\n            \"subject_at_risk\": \"Students\"\\n        },\\n        {\\n            \"reference_risk\": \"Violates academic policies by using unauthorized assistance in completing assignments\",\\n            \"source\": \"aiid_risks\",\\n            \"reasoning\": \"AI-generated content can be used to bypass academic integrity protocols.\",\\n            \"subject_at_risk\": \"Students\"\\n        },\\n        {\\n            \"reference_risk\": \"Undermines academic integrity by enabling students to submit AI-generated work as their own\",\\n            \"source\": \"aiid_risks\",\\n            \"reasoning\": \"Erodes the fairness of academic assessments and the educational process.\",\\n            \"subject_at_risk\": \"Students\"\\n        },\\n        {\\n            \"reference_risk\": \"Exposes personally identifiable information due to memorization of training data\",\\n            \"source\": \"aiid_risks\",\\n            \"reasoning\": \"Breaches student privacy, potentially leaking sensitive information.\",\\n            \"subject_at_risk\": \"Students\"\\n        },\\n        {\\n            \"reference_risk\": \"Reduces learning outcomes by allowing students to bypass the educational process\",\\n            \"source\": \"aiid_risks\",\\n            \"reasoning\": \"The efficacy of education is compromised when students rely on AI-generated content.\",\\n            \"subject_at_risk\": \"Students\"\\n        },\\n        {\\n            \"reference_risk\": \"Exposes confidential information by revealing internal instructions\",\\n            \"source\": \"aiid_risks\",\\n            \"reasoning\": \"Confidential academic information might be inadvertently disclosed.\",\\n            \"subject_at_risk\": \"Institution\"\\n        },\\n        {\\n            \"reference_risk\": \"Increases unfair advantage by providing some students with access to advanced AI tools\",\\n            \"source\": \"aiid_risks\",\\n            \"reasoning\": \"Creates inequitable learning conditions among students.\",\\n            \"subject_at_risk\": \"Students\"\\n        },\\n        {\\n            \"reference_risk\": \"Facilitates misinformation spreading false knowledge\",\\n            \"source\": \"aiid_risks\",\\n            \"reasoning\": \"Inaccurate information can cause long-term harm to students\\' educational foundation.\",\\n            \"subject_at_risk\": \"Students\"\\n        }\\n    ]\\n}',\n",
       " '{\\n    \"cardID\": \"44\",\\n    \"use\": \"Domain-- Arts and Entertainment, Purpose-- Generating creative writing prompts, Capability-- Analyzing themes and creating prompts\",\\n    \"risks\": [\\n        {\\n            \"reference_risk\": \"Underperforms in nonresearch environments\",\\n            \"source\": \"model_risks\",\\n            \"reasoning\": \"The model might not generate high-quality writing prompts outside controlled research settings.\",\\n            \"subject_at_risk\": \"ai_user\"\\n        },\\n        {\\n            \"reference_risk\": \"Induces bias and safety issues due to lack of diverse training data\",\\n            \"source\": \"model_risks\",\\n            \"reasoning\": \"The generated content might reflect biases from the non-diverse training data.\",\\n            \"subject_at_risk\": \"ai_subject\"\\n        },\\n        {\\n            \"reference_risk\": \"Produces low diversity and hallucinated outputs\",\\n            \"source\": \"model_risks\",\\n            \"reasoning\": \"The prompts might lack creativity or include fabrications, reducing their usefulness for writers.\",\\n            \"subject_at_risk\": \"ai_user\"\\n        },\\n        {\\n            \"reference_risk\": \"Produces toxic content\",\\n            \"source\": \"model_risks\",\\n            \"reasoning\": \"Toxic language could be generated, affecting the quality and safety of the prompts.\",\\n            \"subject_at_risk\": \"ai_subject\"\\n        },\\n        {\\n            \"reference_risk\": \"Contains biased training data from the internet\",\\n            \"source\": \"model_risks\",\\n            \"reasoning\": \"The prompts might inadvertently carry biases prevalent on the internet.\",\\n            \"subject_at_risk\": \"ai_subject\"\\n        },\\n        {\\n            \"reference_risk\": \"Generates factual inaccuracies\",\\n            \"source\": \"model_risks\",\\n            \"reasoning\": \"Incorrect information could be embedded in the writing prompts.\",\\n            \"subject_at_risk\": \"ai_subject\"\\n        },\\n        {\\n            \"reference_risk\": \"Induces downstream impact on model quality due to lack of training data diversity\",\\n            \"source\": \"model_risks\",\\n            \"reasoning\": \"Future models fine-tuned on this data might also exhibit similar issues.\",\\n            \"subject_at_risk\": \"institution\"\\n        },\\n        {\\n            \"reference_risk\": \"Generates hallucinations\",\\n            \"source\": \"model_risks\",\\n            \"reasoning\": \"Text created might include elements that are factually incorrect or unrelated.\",\\n            \"subject_at_risk\": \"ai_subject\"\\n        },\\n        {\\n            \"reference_risk\": \"Exhibits biases\",\\n            \"source\": \"model_risks\",\\n            \"reasoning\": \"Generated content could reinforce existing biases and stereotypes.\",\\n            \"subject_at_risk\": \"ai_subject\"\\n        },\\n        {\\n            \"reference_risk\": \"Generates offensive responses\",\\n            \"source\": \"model_risks\",\\n            \"reasoning\": \"Content produced might unintentionally offend users or readers.\",\\n            \"subject_at_risk\": \"ai_user\"\\n        },\\n        {\\n            \"reference_risk\": \"Undermines factual correctness\",\\n            \"source\": \"model_risks\",\\n            \"reasoning\": \"The model might not be reliable for creating factually accurate prompts.\",\\n            \"subject_at_risk\": \"ai_subject\"\\n        },\\n        {\\n            \"reference_risk\": \"Transfers bias to all finetuned versions of the model\",\\n            \"source\": \"model_risks\",\\n            \"reasoning\": \"Any subsequent versions of the model will carry over the existing biases.\",\\n            \"subject_at_risk\": \"institution\"\\n        },\\n        {\\n            \"reference_risk\": \"Facilitates misinformation spreading false knowledge\",\\n            \"source\": \"aiid_risks\",\\n            \"reasoning\": \"Generated writing prompts might inadvertently spread false information.\",\\n            \"subject_at_risk\": \"ai_subject\"\\n        },\\n        {\\n            \"reference_risk\": \"Promotes hate speech by generating and posting racist misogynistic and antisemitic content\",\\n            \"source\": \"aiid_risks\",\\n            \"reasoning\": \"There is a risk of generating content that can be harmful and discriminatory.\",\\n            \"subject_at_risk\": \"ai_subject\"\\n        },\\n        {\\n            \"reference_risk\": \"Undermines public trust in AI by demonstrating misuse of AI technology\",\\n            \"source\": \"aiid_risks\",\\n            \"reasoning\": \"Poorly generated content can make users skeptical about the potential of AI in creative writing.\",\\n            \"subject_at_risk\": \"institution\"\\n        },\\n        {\\n            \"reference_risk\": \"Violates human rights by propagating discriminatory and offensive language\",\\n            \"source\": \"aiid_risks\",\\n            \"reasoning\": \"Generated content might contain discriminatory language.\",\\n            \"subject_at_risk\": \"ai_subject\"\\n        },\\n        {\\n            \"reference_risk\": \"Marginalizes intersectional identities by embedding multiple biases\",\\n            \"source\": \"aiid_risks\",\\n            \"reasoning\": \"Content might marginalize individuals by perpetuating overlapping biases.\",\\n            \"subject_at_risk\": \"ai_subject\"\\n        },\\n        {\\n            \"reference_risk\": \"Perpetuates gender biases by producing stereotypical depictions\",\\n            \"source\": \"aiid_risks\",\\n            \"reasoning\": \"Writing prompts might unintentionally reinforce gender stereotypes.\",\\n            \"subject_at_risk\": \"ai_subject\"\\n        },\\n        {\\n            \"reference_risk\": \"Increases psychological harm by causing fear and anxiety through threatening statements\",\\n            \"source\": \"aiid_risks\",\\n            \"reasoning\": \"Generated content might inadvertently contain language that causes anxiety or fear.\",\\n            \"subject_at_risk\": \"ai_subject\"\\n        },\\n        {\\n            \"reference_risk\": \"Generates offensive content harming reputations\",\\n            \"source\": \"aiid_risks\",\\n            \"reasoning\": \"Content might damage reputations by being offensive or defamatory.\",\\n            \"subject_at_risk\": \"ai_user\"\\n        }\\n    ]\\n}',\n",
       " '{\\n    \"cardID\": \"82\",\\n    \"use\": \"Domain-- Recommender Systems and Personalization, Purpose-- Recommending personalized content, Capability-- Analyzing preferences for suggestions\",\\n    \"risks\": [\\n        {\\n            \"reference_risk\": \"Erases representation of some groups\",\\n            \"source\": \"model_risks\",\\n            \"reasoning\": \"The model may fail to recommend content representing minority or underrepresented groups.\",\\n            \"subject_at_risk\": \"Content consumers\"\\n        },\\n        {\\n            \"reference_risk\": \"Underperforms on languages other than English\",\\n            \"source\": \"model_risks\",\\n            \"reasoning\": \"The model is likely to provide poor recommendations in languages other than English, leading to a subpar experience.\",\\n            \"subject_at_risk\": \"Content consumers\"\\n        },\\n        {\\n            \"reference_risk\": \"Produces unfair, unreliable, or offensive outputs in high-risk scenarios\",\\n            \"source\": \"model_risks\",\\n            \"reasoning\": \"The recommender system could produce biased or inappropriate suggestions, which might be offensive or harmful, particularly in sensitive contexts.\",\\n            \"subject_at_risk\": \"Content consumers\"\\n        },\\n        {\\n            \"reference_risk\": \"Produces inaccurate or outdated content\",\\n            \"source\": \"model_risks\",\\n            \"reasoning\": \"The system might recommend outdated or incorrect content, which can misinform users or lead to dissatisfaction.\",\\n            \"subject_at_risk\": \"Content consumers\"\\n        },\\n        {\\n            \"reference_risk\": \"Reinforces demeaning or negative stereotypes\",\\n            \"source\": \"model_risks\",\\n            \"reasoning\": \"The recommender system might prompt content that reinforces harmful stereotypes based on the data it has been trained on.\",\\n            \"subject_at_risk\": \"Content consumers\"\\n        },\\n        {\\n            \"reference_risk\": \"Fabricates content that is inaccurate or outdated\",\\n            \"source\": \"model_risks\",\\n            \"reasoning\": \"The system might generate and recommend fabricated content, causing misinformation.\",\\n            \"subject_at_risk\": \"Content consumers\"\\n        },\\n        {\\n            \"reference_risk\": \"Misuse for fraud, spam, or malware production\",\\n            \"source\": \"model_risks\",\\n            \"reasoning\": \"The system might be exploited to recommend harmful or malicious content to users.\",\\n            \"subject_at_risk\": \"Content consumers\"\\n        },\\n        {\\n            \"reference_risk\": \"Produces offensive content harming reputations\",\\n            \"source\": \"aiid_risks\",\\n            \"reasoning\": \"The system could inadvertently recommend offensive content, which could damage the reputation of the content platform.\",\\n            \"subject_at_risk\": \"Streaming platforms\"\\n        },\\n        {\\n            \"reference_risk\": \"Increases psychological harm by causing fear and anxiety through threatening statements\",\\n            \"source\": \"aiid_risks\",\\n            \"reasoning\": \"Recommendations might include distressing content that can cause psychological harm to users.\",\\n            \"subject_at_risk\": \"Content consumers\"\\n        }\\n    ]\\n}',\n",
       " '{\\n    \"cardID\": \"82\",\\n    \"use\": \"Domain-- Marketing and Advertising, Purpose-- Creating personalized ad campaigns, Capability-- Analyzing user behavior from social media posts\",\\n    \"risks\": \\n    [\\n        {\\n            \"reference_risk\": \"Produces unfair unreliable or offensive outputs in highrisk scenarios\",\\n            \"source\": \"model_risks\",\\n            \"reasoning\": \"Relevant since personalized ad campaigns in marketing could present sensitive or offensive material to users.\",\\n            \"subject_at_risk\": \"ai_subject\"\\n        },\\n        {\\n            \"reference_risk\": \"Produces inaccurate or outdated content\",\\n            \"source\": \"model_risks\",\\n            \"reasoning\": \"Relevant to marketing as presenting outdated content can harm the effectiveness of ad campaigns.\",\\n            \"subject_at_risk\": \"ai_user\"\\n        },\\n        {\\n            \"reference_risk\": \"Produces harmful content if explicitly prompted or instructed\",\\n            \"source\": \"model_risks\",\\n            \"reasoning\": \"Ad campaigns could potentially be designed to mislead or harm consumer groups.\",\\n            \"subject_at_risk\": \"ai_subject\"\\n        },\\n        {\\n            \"reference_risk\": \"Reinforces demeaning or negative stereotypes\",\\n            \"source\": \"model_risks\",\\n            \"reasoning\": \"Marketing content could unintentionally reinforce societal biases or stereotypes.\",\\n            \"subject_at_risk\": \"ai_subject\"\\n        },\\n        {\\n            \"reference_risk\": \"Produces problematic outputs without intheloop filtering of responses\",\\n            \"source\": \"model_risks\",\\n            \"reasoning\": \"Critical for marketing as unchecked outputs could lead to offensive or inappropriate advertisements.\",\\n            \"subject_at_risk\": \"ai_subject\"\\n        },\\n        {\\n            \"reference_risk\": \"Generates content that mirrors societal biases\",\\n            \"source\": \"model_risks\",\\n            \"reasoning\": \"Marketing content should be fair and unbiased, making this risk pertinent.\",\\n            \"subject_at_risk\": \"ai_subject\"\\n        },\\n        {\\n            \"reference_risk\": \"Uses a mix of Web data and technical sources without transparency\",\\n            \"source\": \"model_risks\",\\n            \"reasoning\": \"Important for marketing as lack of data transparency can harm trust between agencies and clients.\",\\n            \"subject_at_risk\": \"institution\"\\n        },\\n        {\\n            \"reference_risk\": \"Misuse for fraud spam or malware production\",\\n            \"source\": \"model_risks\",\\n            \"reasoning\": \"Relevant as marketing tools can be misused for fraudulent activities.\",\\n            \"subject_at_risk\": \"ai_user\"\\n        },\\n        {\\n            \"reference_risk\": \"Generates content that includes threats to destroy humankind\",\\n            \"source\": \"aiid_risks\",\\n            \"reasoning\": \"Although extreme, any offensive or harmful content can severely impact user perception of marketing campaigns.\",\\n            \"subject_at_risk\": \"ai_subject\"\\n        },\\n        {\\n            \"reference_risk\": \"Spreads misinformation by generating false facts about nonexistent events\",\\n            \"source\": \"aiid_risks\",\\n            \"reasoning\": \"Pertinent to personalized ad campaigns as they must provide accurate information.\",\\n            \"subject_at_risk\": \"ai_subject\"\\n        },\\n        {\\n            \"reference_risk\": \"Violates ethical standards by promoting harmful stereotypes\",\\n            \"source\": \"aiid_risks\",\\n            \"reasoning\": \"Important to ensure marketing content adheres to ethical standards.\",\\n            \"subject_at_risk\": \"ai_subject\"\\n        },\\n        {\\n            \"reference_risk\": \"Discriminates against marginalized groups by perpetuating harmful biases\",\\n            \"source\": \"aiid_risks\",\\n            \"reasoning\": \"Critical since advertisements must be inclusive and fair to all groups.\",\\n            \"subject_at_risk\": \"ai_subject\"\\n        },\\n        {\\n            \"reference_risk\": \"Offends users by making offensive remarks\",\\n            \"source\": \"aiid_risks\",\\n            \"reasoning\": \"Highly pertinent to making sure personalized ads do not alienate or offend consumers.\",\\n            \"subject_at_risk\": \"ai_subject\"\\n        },\\n        {\\n            \"reference_risk\": \"Harms reputations by making inconsistent remarks\",\\n            \"source\": \"aiid_risks\",\\n            \"reasoning\": \"Relevant as inconsistent marketing messages can harm the reputation of brands.\",\\n            \"subject_at_risk\": \"ai_user\"\\n        },\\n        {\\n            \"reference_risk\": \"Promotes stereotypes by invoking Jewish stereotypes\",\\n            \"source\": \"aiid_risks\",\\n            \"reasoning\": \"Relevant to ensure marketing content avoids specific harmful stereotypes.\",\\n            \"subject_at_risk\": \"ai_subject\"\\n        }\\n    ]\\n}',\n",
       " '{\\n    \"cardID\": \"82\",\\n    \"use\": \"Domain-- Education and vocational training, Purpose-- Personalizing learning experiences, Capability-- Analyzing student performance and tailoring content\",\\n    \"risks\": [\\n        {\\n            \"reference_risk\": \"Erases representation of some groups\",\\n            \"source\": \"model_risks\",\\n            \"reasoning\": \"The model may erase the representation of certain groups in educational content, impacting the inclusivity of learning experiences.\",\\n            \"subject_at_risk\": \"Students\"\\n        },\\n        {\\n            \"reference_risk\": \"Underperforms on languages other than English\",\\n            \"source\": \"model_risks\",\\n            \"reasoning\": \"The model\\'s underperformance on non-English languages could limit its effectiveness for students who are not proficient in English.\",\\n            \"subject_at_risk\": \"Students\"\\n        },\\n        {\\n            \"reference_risk\": \"Produces unfair, unreliable, or offensive outputs in high-risk scenarios\",\\n            \"source\": \"model_risks\",\\n            \"reasoning\": \"Unfair or offensive outputs could harm student well-being and educational integrity.\",\\n            \"subject_at_risk\": \"Students\"\\n        },\\n        {\\n            \"reference_risk\": \"Reinforces demeaning or negative stereotypes\",\\n            \"source\": \"model_risks\",\\n            \"reasoning\": \"Demeaning or negative stereotypes in educational content could negatively affect students\\' self-perception and learning.\",\\n            \"subject_at_risk\": \"Students\"\\n        },\\n        {\\n            \"reference_risk\": \"Produces harmful content if explicitly prompted or instructed\",\\n            \"source\": \"model_risks\",\\n            \"reasoning\": \"Harmful content in educational materials could severely affect students\\' mental health and educational experience.\",\\n            \"subject_at_risk\": \"Students\"\\n        },\\n        {\\n            \"reference_risk\": \"Generates content that mirrors societal biases\",\\n            \"source\": \"model_risks\",\\n            \"reasoning\": \"Content reflecting societal biases could perpetuate inequality and affect the quality of educational experiences.\",\\n            \"subject_at_risk\": \"Students\"\\n        },\\n        {\\n            \"reference_risk\": \"Produces inappropriate or offensive content\",\\n            \"source\": \"model_risks\",\\n            \"reasoning\": \"Inappropriate or offensive content could disrupt learning environments and affect student well-being.\",\\n            \"subject_at_risk\": \"Students\"\\n        },\\n        {\\n            \"reference_risk\": \"Misinterprets or errors in response to informal English slang or other languages\",\\n            \"source\": \"model_risks\",\\n            \"reasoning\": \"Misinterpretations can lead to misunderstandings and gaps in educational content.\",\\n            \"subject_at_risk\": \"Students\"\\n        },\\n        {\\n            \"reference_risk\": \"Misuse for fraud, spam, or malware production\",\\n            \"source\": \"model_risks\",\\n            \"reasoning\": \"Misuse of the AI platform in educational environments could harm students and educational institutions.\",\\n            \"subject_at_risk\": \"Institution\"\\n        },\\n        {\\n            \"reference_risk\": \"Struggles or fails to adhere to intricate or nuanced instructions\",\\n            \"source\": \"model_risks\",\\n            \"reasoning\": \"Inability to follow nuanced instructions may reduce the quality of personalized learning plans for students.\",\\n            \"subject_at_risk\": \"Students\"\\n        },\\n        {\\n            \"reference_risk\": \"Produces problematic outputs when not aligned to human preferences for safety\",\\n            \"source\": \"model_risks\",\\n            \"reasoning\": \"Unaligned outputs might compromise the safety and educational appropriateness of content.\",\\n            \"subject_at_risk\": \"Students\"\\n        },\\n        {\\n            \"reference_risk\": \"Underperforms with packages outside common ones\",\\n            \"source\": \"model_risks\",\\n            \"reasoning\": \"If educational content relies on specific software packages that the model doesn\\'t handle well, the learning experience could be suboptimal for students.\",\\n            \"subject_at_risk\": \"Students\"\\n        },\\n        {\\n            \"reference_risk\": \"Violates user trust by bypassing safeguards designed to restrict certain functionalities\",\\n            \"source\": \"aiid_risks\",\\n            \"reasoning\": \"Bypassing safeguards could lead to the distribution of harmful content, thus violating trust.\",\\n            \"subject_at_risk\": \"Institution\"\\n        },\\n        {\\n            \"reference_risk\": \"Facilitates misinformation by spreading false knowledge\",\\n            \"source\": \"aiid_risks\",\\n            \"reasoning\": \"Spreading misinformation could greatly impact the educational integrity and students\\' learning outcomes.\",\\n            \"subject_at_risk\": \"Students\"\\n        },\\n        {\\n            \"reference_risk\": \"Discriminates against marginalized groups by perpetuating harmful biases\",\\n            \"source\": \"aiid_risks\",\\n            \"reasoning\": \"Perpetuating harmful biases could contribute to unequal educational opportunities for marginalized students.\",\\n            \"subject_at_risk\": \"Students\"\\n        },\\n        {\\n            \"reference_risk\": \"Increases psychological harm by causing fear and anxiety through threatening statements\",\\n            \"source\": \"aiid_risks\",\\n            \"reasoning\": \"Threatening statements within educational content could result in significant psychological harm to students.\",\\n            \"subject_at_risk\": \"Students\"\\n        },\\n        {\\n            \"reference_risk\": \"Produces offensive content harming social harmony\",\\n            \"source\": \"aiid_risks\",\\n            \"reasoning\": \"Offensive content within educational resources might disrupt social harmony and a positive learning environment.\",\\n            \"subject_at_risk\": \"Students\"\\n        },\\n        {\\n            \"reference_risk\": \"Promotes stereotypes by invoking Jewish stereotypes\",\\n            \"source\": \"aiid_risks\",\\n            \"reasoning\": \"Promoting stereotypes, particularly cultural or religious ones, could harm inclusivity and respect within educational platforms.\",\\n            \"subject_at_risk\": \"Students\"\\n        },\\n        {\\n            \"reference_risk\": \"Exposes sensitive data due to misconfigured access tokens\",\\n            \"source\": \"aiid_risks\",\\n            \"reasoning\": \"Exposure of sensitive educational data could breach privacy and trust within the institution.\",\\n            \"subject_at_risk\": \"Institution\"\\n        }\\n    ]\\n}',\n",
       " '{\\n    \"cardID\": \"82\",\\n    \"use\": \"Domain-- Social Media, Purpose-- Moderating harmful content, Capability-- Detecting inappropriate posts\",\\n    \"risks\": \\n    [\\n        {\\n            \"reference_risk\": \"Produces unfair unreliable or offensive outputs in highrisk scenarios\",\\n            \"source\": \"model_risks\",\\n            \"reasoning\": \"The model may produce unreliable or offensive outputs, which is a critical concern for moderating harmful content on social media.\",\\n            \"subject_at_risk\": \"ai_subject\"\\n        },\\n        {\\n            \"reference_risk\": \"Reinforces demeaning or negative stereotypes\",\\n            \"source\": \"model_risks\",\\n            \"reasoning\": \"The model might reinforce negative stereotypes, impacting moderation of harmful content aimed at social media users.\",\\n            \"subject_at_risk\": \"ai_subject\"\\n        },\\n        {\\n            \"reference_risk\": \"Produces harmful content if explicitly prompted or instructed\",\\n            \"source\": \"model_risks\",\\n            \"reasoning\": \"There is a risk of the model generating harmful content if instructed, which is counterproductive to its use in harmful content moderation on social media.\",\\n            \"subject_at_risk\": \"ai_subject\"\\n        },\\n        {\\n            \"reference_risk\": \"Generates content that mirrors societal biases\",\\n            \"source\": \"model_risks\",\\n            \"reasoning\": \"The risk of societal biases showing up in generated content is relevant in social media contexts where such biases can harm users.\",\\n            \"subject_at_risk\": \"ai_subject\"\\n        },\\n        {\\n            \"reference_risk\": \"Produces inappropriate or offensive content\",\\n            \"source\": \"model_risks\",\\n            \"reasoning\": \"The generation of inappropriate or offensive content directly affects users on social media platforms.\",\\n            \"subject_at_risk\": \"ai_subject\"\\n        },\\n        {\\n            \"reference_risk\": \"Overrepresents or underrepresents groups of people\",\\n            \"source\": \"model_risks\",\\n            \"reasoning\": \"Overrepresentation or underrepresentation of groups could lead to moderation bias in social media content management.\",\\n            \"subject_at_risk\": \"ai_subject\"\\n        },\\n        {\\n            \"reference_risk\": \"Misinterprets or errors in response to informal English slang or other languages\",\\n            \"source\": \"model_risks\",\\n            \"reasoning\": \"Misinterpretation of slang or other languages can lead to inaccurate or unfair moderation decisions on social media.\",\\n            \"subject_at_risk\": \"ai_subject\"\\n        },\\n        {\\n            \"reference_risk\": \"Enables fraud spam or malware production\",\\n            \"source\": \"model_risks\",\\n            \"reasoning\": \"The model\\'s potential misuse for fraud, spam, or malware can pose significant risks to social media platforms and their users.\",\\n            \"subject_at_risk\": \"ai_user\"\\n        },\\n        {\\n            \"reference_risk\": \"Promotes stereotypes by invoking Jewish stereotypes\",\\n            \"source\": \"aiid_risks\",\\n            \"reasoning\": \"The model could promote negative stereotypes, which is a concern in content moderation to avoid discriminatory content.\",\\n            \"subject_at_risk\": \"ai_subject\"\\n        },\\n        {\\n            \"reference_risk\": \"Violates privacy by exposing internal messages\",\\n            \"source\": \"aiid_risks\",\\n            \"reasoning\": \"Exposing internal messages would violate privacy and could harm social media platform users.\",\\n            \"subject_at_risk\": \"ai_subject\"\\n        },\\n        {\\n            \"reference_risk\": \"Produces offensive content harming reputations\",\\n            \"source\": \"aiid_risks\",\\n            \"reasoning\": \"Generates harmful or offensive content can damage reputations on social media platforms.\",\\n            \"subject_at_risk\": \"ai_subject\"\\n        },\\n        {\\n            \"reference_risk\": \"Facilitates misinformation spreading false knowledge\",\\n            \"source\": \"aiid_risks\",\\n            \"reasoning\": \"The spread of misinformation is highly detrimental on social media, as it can mislead users.\",\\n            \"subject_at_risk\": \"ai_subject\"\\n        },\\n        {\\n            \"reference_risk\": \"Discriminates against specific groups of people due to biased responses\",\\n            \"source\": \"aiid_risks\",\\n            \"reasoning\": \"Discriminatory responses are problematic in moderating social media content, as they can alienate marginalized groups.\",\\n            \"subject_at_risk\": \"ai_subject\"\\n        }\\n    ]\\n}',\n",
       " '{\\n    \"cardID\": \"93\",\\n    \"use\": \"Domain-- Recommender Systems and Personalization, Purpose-- Recommending personalized content, Capability-- Analyzing preferences for suggestions\",\\n    \"risks\": [\\n        {\\n            \"reference_risk\": \"Generates nondeterministic responses due to model size\",\\n            \"source\": \"model_risks\",\\n            \"reasoning\": \"Recommending personalized content could be affected by the model generating unpredictable responses.\",\\n            \"subject_at_risk\": \"ai_user\"\\n        },\\n        {\\n            \"reference_risk\": \"Acts as \\'black boxes\\' making it difficult to comprehend rationale behind outputs\",\\n            \"source\": \"model_risks\",\\n            \"reasoning\": \"Users may not understand why certain content is recommended, leading to confusion and mistrust.\",\\n            \"subject_at_risk\": \"ai_user\"\\n        },\\n        {\\n            \"reference_risk\": \"Exhibits unreliable unsafe or other undesirable behaviors\",\\n            \"source\": \"model_risks\",\\n            \"reasoning\": \"Unreliable behavior in content recommendations could negatively affect user experience.\",\\n            \"subject_at_risk\": \"ai_user\"\\n        },\\n        {\\n            \"reference_risk\": \"Generates outputs that could be biased or unfair\",\\n            \"source\": \"model_risks\",\\n            \"reasoning\": \"Content consumers may receive biased or unfair content recommendations, impacting their user experience.\",\\n            \"subject_at_risk\": \"ai_subject\"\\n        },\\n        {\\n            \"reference_risk\": \"Underperforms in non-English languages\",\\n            \"source\": \"model_risks\",\\n            \"reasoning\": \"Non-English content consumers may receive poor-quality recommendations due to language limitations.\",\\n            \"subject_at_risk\": \"ai_subject\"\\n        },\\n        {\\n            \"reference_risk\": \"Limits accuracy in areas underrepresented in the training dataset\",\\n            \"source\": \"model_risks\",\\n            \"reasoning\": \"Content recommendations may be less accurate for users interested in niche or underrepresented topics.\",\\n            \"subject_at_risk\": \"ai_user\"\\n        },\\n        {\\n            \"reference_risk\": \"Carries biases present in the source data\",\\n            \"source\": \"model_risks\",\\n            \"reasoning\": \"Content recommendations may reflect the biases present in the data used to train the model.\",\\n            \"subject_at_risk\": \"ai_subject\"\\n        },\\n        {\\n            \"reference_risk\": \"Exhibits limited real-world understanding\",\\n            \"source\": \"model_risks\",\\n            \"reasoning\": \"Recommendations may not always align with real-world user preferences or contexts.\",\\n            \"subject_at_risk\": \"ai_user\"\\n        },\\n        {\\n            \"reference_risk\": \"Reflects offensive or inappropriate content in model-generated text\",\\n            \"source\": \"model_risks\",\\n            \"reasoning\": \"Recommender system might suggest offensive or inappropriate content to users.\",\\n            \"subject_at_risk\": \"ai_subject\"\\n        },\\n        {\\n            \"reference_risk\": \"Fabricates content making it unreliable for critical decisions\",\\n            \"source\": \"model_risks\",\\n            \"reasoning\": \"Content consumers could be misled by fabricated content, affecting their trust and decisions.\",\\n            \"subject_at_risk\": \"ai_subject\"\\n        },\\n        {\\n            \"reference_risk\": \"Used maliciously for generating disinformation or harmful content\",\\n            \"source\": \"model_risks\",\\n            \"reasoning\": \"Recommender system could be exploited to spread disinformation or harmful content.\",\\n            \"subject_at_risk\": \"ai_user\"\\n        },\\n        {\\n            \"reference_risk\": \"Produces objectionable responses\",\\n            \"source\": \"model_risks\",\\n            \"reasoning\": \"Content recommendations may include objectionable material, impacting user experience and satisfaction.\",\\n            \"subject_at_risk\": \"ai_subject\"\\n        },\\n        {\\n            \"reference_risk\": \"Produces inaccurate responses\",\\n            \"source\": \"model_risks\",\\n            \"reasoning\": \"Inaccurate content recommendations could negatively affect user trust and engagement.\",\\n            \"subject_at_risk\": \"ai_user\"\\n        },\\n        {\\n            \"reference_risk\": \"Offends users by making offensive remarks\",\\n            \"source\": \"aiid_risks\",\\n            \"reasoning\": \"Content consumers might encounter offensive recommendations, leading to discomfort or dissatisfaction.\",\\n            \"subject_at_risk\": \"ai_subject\"\\n        },\\n        {\\n            \"reference_risk\": \"Undermines trust in AI systems by mishandling sensitive personal data\",\\n            \"source\": \"aiid_risks\",\\n            \"reasoning\": \"Mishandling user data can reduce trust in the recommender system and the platform\\'s overall reliability.\",\\n            \"subject_at_risk\": \"ai_user\"\\n        },\\n        {\\n            \"reference_risk\": \"Increases psychological harm by exposing users to graphic and explicit content\",\\n            \"source\": \"aiid_risks\",\\n            \"reasoning\": \"Users might be negatively affected if the system recommends inappropriate content.\",\\n            \"subject_at_risk\": \"ai_subject\"\\n        }\\n    ]\\n}',\n",
       " '{\\n    \"cardID\": \"93\",\\n    \"use\": \"Domain-- Marketing and Advertising, Purpose-- Creating personalized ad campaigns, Capability-- Analyzing user behavior from social media posts\",\\n    \"risks\": [\\n        {\\n            \"reference_risk\": \"Generates nondeterministic responses due to model size\",\\n            \"source\": \"model_risks\",\\n            \"reasoning\": \"Model can generate different outputs for the same input which may lead to inconsistent marketing messages.\",\\n            \"subject_at_risk\": \"Marketing agencies\"\\n        },\\n        {\\n            \"reference_risk\": \"Acts as â€œblack boxesâ€ making it difficult to comprehend rationale behind outputs\",\\n            \"source\": \"model_risks\",\\n            \"reasoning\": \"Lack of transparency in model\\'s decision-making process can lead to difficulty in understanding why certain marketing messages are created.\",\\n            \"subject_at_risk\": \"Marketing agencies\"\\n        },\\n        {\\n            \"reference_risk\": \"Exhibits unreliable unsafe or other undesirable behaviors\",\\n            \"source\": \"model_risks\",\\n            \"reasoning\": \"Model might produce inappropriate or harmful marketing content which could damage brand reputation.\",\\n            \"subject_at_risk\": \"Marketing agencies\"\\n        },\\n        {\\n            \"reference_risk\": \"Generates outputs that could be biased or unfair\",\\n            \"source\": \"model_risks\",\\n            \"reasoning\": \"Marketing messages could reflect biases present in the training data, potentially misleading or offending consumers.\",\\n            \"subject_at_risk\": \"Consumers\"\\n        },\\n        {\\n            \"reference_risk\": \"Limits accuracy in areas underrepresented in the training dataset\",\\n            \"source\": \"model_risks\",\\n            \"reasoning\": \"Underrepresentation of certain demographics in the training data could lead to ineffective or misinformed marketing strategies.\",\\n            \"subject_at_risk\": \"Marketing agencies\"\\n        },\\n        {\\n            \"reference_risk\": \"Carries biases present in the source data\",\\n            \"source\": \"model_risks\",\\n            \"reasoning\": \"Biases from training data could skew marketing strategies and lead to unfair targeting of consumer segments.\",\\n            \"subject_at_risk\": \"Consumers\"\\n        },\\n        {\\n            \"reference_risk\": \"Fails to cover all scenarios\",\\n            \"source\": \"model_risks\",\\n            \"reasoning\": \"Model limitations might lead to gaps in marketing strategy, failing to address all possible consumer behaviors.\",\\n            \"subject_at_risk\": \"Marketing agencies\"\\n        },\\n        {\\n            \"reference_risk\": \"Arises potential issues in generated responses\",\\n            \"source\": \"model_risks\",\\n            \"reasoning\": \"Potential for generating irrelevant or inappropriate marketing messages affecting campaign performance.\",\\n            \"subject_at_risk\": \"Marketing agencies\"\\n        },\\n        {\\n            \"reference_risk\": \"Reflects offensive or inappropriate content in modelgenerated text\",\\n            \"source\": \"model_risks\",\\n            \"reasoning\": \"Possibility that the model generates offensive content which can harm brand image.\",\\n            \"subject_at_risk\": \"Consumers\"\\n        },\\n        {\\n            \"reference_risk\": \"Fabricates content making it unreliable for critical decisions\",\\n            \"source\": \"model_risks\",\\n            \"reasoning\": \"Fabricated information can lead to misinformed marketing decisions and strategies.\",\\n            \"subject_at_risk\": \"Marketing agencies\"\\n        },\\n        {\\n            \"reference_risk\": \"Produces inaccurate or nonsensical responses\",\\n            \"source\": \"model_risks\",\\n            \"reasoning\": \"Marketing content might be based on inaccurate data leading to ineffective campaigns.\",\\n            \"subject_at_risk\": \"Marketing agencies\"\\n        },\\n        {\\n            \"reference_risk\": \"Retains biases and toxicity despite finetuning\",\\n            \"source\": \"model_risks\",\\n            \"reasoning\": \"Despite fine-tuning, biases can still persist affecting the fairness and inclusivity of marketing messages.\",\\n            \"subject_at_risk\": \"Consumers\"\\n        },\\n        {\\n            \"reference_risk\": \"Infringes data protection laws by using sensitive data without proper authorization\",\\n            \"source\": \"aiid_risks\",\\n            \"reasoning\": \"Using sensitive user data from social media without proper consent can lead to legal issues.\",\\n            \"subject_at_risk\": \"Marketing agencies\"\\n        },\\n        {\\n            \"reference_risk\": \"Facilitates misinformation spreading false knowledge\",\\n            \"source\": \"aiid_risks\",\\n            \"reasoning\": \"Potential to generate false or misleading marketing content which can misinform consumers.\",\\n            \"subject_at_risk\": \"Consumers\"\\n        },\\n        {\\n            \"reference_risk\": \"Offends users by making offensive remarks\",\\n            \"source\": \"aiid_risks\",\\n            \"reasoning\": \"Generated marketing content might contain offensive language, harming the consumer experience.\",\\n            \"subject_at_risk\": \"Consumers\"\\n        }\\n    ]\\n}',\n",
       " '{\\n    \"cardID\": \"93\",\\n    \"use\": \"Domain-- Education and vocational training, Purpose-- Personalizing learning experiences, Capability-- Analyzing student performance and tailoring content\",\\n    \"risks\": [\\n        {\\n            \"reference_risk\": \"Generates nondeterministic responses due to model size\",\\n            \"source\": \"model_risks\",\\n            \"reasoning\": \"Nondeterministic responses could affect the consistency of personalized learning experiences.\",\\n            \"subject_at_risk\": \"ai_subject\"\\n        },\\n        {\\n            \"reference_risk\": \"Acts as â€œblack boxesâ€ making it difficult to comprehend rationale behind outputs\",\\n            \"source\": \"model_risks\",\\n            \"reasoning\": \"Lack of transparency in model outputs may reduce trust among educational platforms and institutions.\",\\n            \"subject_at_risk\": \"ai_user\"\\n        },\\n        {\\n            \"reference_risk\": \"Exhibits unreliable unsafe or other undesirable behaviors\",\\n            \"source\": \"model_risks\",\\n            \"reasoning\": \"Undesirable behaviors from the model could negatively impact the learning experience for students.\",\\n            \"subject_at_risk\": \"ai_subject\"\\n        },\\n        {\\n            \"reference_risk\": \"Generates outputs that could be biased or unfair\",\\n            \"source\": \"model_risks\",\\n            \"reasoning\": \"Biased or unfair outputs may affect the quality and fairness of personalized learning content.\",\\n            \"subject_at_risk\": \"ai_subject\"\\n        },\\n        {\\n            \"reference_risk\": \"Limits accuracy in areas underrepresented in the training dataset\",\\n            \"source\": \"model_risks\",\\n            \"reasoning\": \"Inaccurate analysis and tailoring due to underrepresented data could misinform educational decisions.\",\\n            \"subject_at_risk\": \"ai_subject\"\\n        },\\n        {\\n            \"reference_risk\": \"Fails to cover all scenarios\",\\n            \"source\": \"model_risks\",\\n            \"reasoning\": \"Inability to handle diverse learning scenarios may reduce the effectiveness of personalized content.\",\\n            \"subject_at_risk\": \"ai_subject\"\\n        },\\n        {\\n            \"reference_risk\": \"Reflects offensive or inappropriate content in modelgenerated text\",\\n            \"source\": \"model_risks\",\\n            \"reasoning\": \"Offensive content could harm students and damage the reputation of educational platforms.\",\\n            \"subject_at_risk\": \"ai_subject\"\\n        },\\n        {\\n            \"reference_risk\": \"Fabricates content making it unreliable for critical decisions\",\\n            \"source\": \"model_risks\",\\n            \"reasoning\": \"Fabricated content could misguide students and educators, leading to poor educational outcomes.\",\\n            \"subject_at_risk\": \"ai_subject\"\\n        },\\n        {\\n            \"reference_risk\": \"Generates disinformation by creating misleading or false images\",\\n            \"source\": \"aiid_risks\",\\n            \"reasoning\": \"Misleading or false information could undermine the educational content\\'s credibility and accuracy.\",\\n            \"subject_at_risk\": \"ai_subject\"\\n        },\\n        {\\n            \"reference_risk\": \"Harms economic interests of content creators by using their work without compensation\",\\n            \"source\": \"aiid_risks\",\\n            \"reasoning\": \"Uncompensated use of creators\\' work could lead to financial and reputational harm for content creators.\",\\n            \"subject_at_risk\": \"institution\"\\n        }\\n    ]\\n}',\n",
       " '{\\n    \"cardID\": \"93\",\\n    \"use\": \"Domain-- Health and Healthcare, Purpose-- Assisting in medical diagnoses, Capability-- Analyzing patient data and suggesting conditions\",\\n    \"risks\": [\\n        {\\n            \"reference_risk\": \"Generates nondeterministic responses due to model size\",\\n            \"source\": \"model_risks\",\\n            \"reasoning\": \"The model\\'s non-deterministic responses could lead to unreliable diagnosis suggestions.\",\\n            \"subject_at_risk\": \"Patients\"\\n        },\\n        {\\n            \"reference_risk\": \"Acts as â€œblack boxesâ€ making it difficult to comprehend rationale behind outputs\",\\n            \"source\": \"model_risks\",\\n            \"reasoning\": \"The lack of transparency in the model\\'s decision-making process can hinder healthcare professionals in validating diagnoses or therapeutic suggestions.\",\\n            \"subject_at_risk\": \"Healthcare professionals\"\\n        },\\n        {\\n            \"reference_risk\": \"Exhibits unreliable unsafe or other undesirable behaviors\",\\n            \"source\": \"model_risks\",\\n            \"reasoning\": \"Unreliable or unsafe behaviors can directly lead to incorrect diagnoses or treatment suggestions.\",\\n            \"subject_at_risk\": \"Patients\"\\n        },\\n        {\\n            \"reference_risk\": \"Generates outputs that could be biased or unfair\",\\n            \"source\": \"model_risks\",\\n            \"reasoning\": \"Biases in the model\\'s outputs could result in unequal treatment recommendations for different patient demographics.\",\\n            \"subject_at_risk\": \"Patients\"\\n        },\\n        {\\n            \"reference_risk\": \"Limits accuracy in areas underrepresented in the training dataset\",\\n            \"source\": \"model_risks\",\\n            \"reasoning\": \"Patients from underrepresented groups might receive less accurate diagnoses or medical advice.\",\\n            \"subject_at_risk\": \"Patients\"\\n        },\\n        {\\n            \"reference_risk\": \"Carries biases present in the source data\",\\n            \"source\": \"model_risks\",\\n            \"reasoning\": \"Biases in the source data could affect the fairness and accuracy of the model\\'s medical recommendations.\",\\n            \"subject_at_risk\": \"Patients\"\\n        },\\n        {\\n            \"reference_risk\": \"Arises potential issues in generated responses\",\\n            \"source\": \"model_risks\",\\n            \"reasoning\": \"Generated responses could potentially include incorrect or misleading medical information.\",\\n            \"subject_at_risk\": \"Patients\"\\n        },\\n        {\\n            \"reference_risk\": \"Results in potential inaccuracies or nonsensical responses\",\\n            \"source\": \"model_risks\",\\n            \"reasoning\": \"Inaccurate or nonsensical responses could lead to incorrect diagnoses or inappropriate treatment plans.\",\\n            \"subject_at_risk\": \"Patients\"\\n        },\\n        {\\n            \"reference_risk\": \"Exhibits limited real-world understanding\",\\n            \"source\": \"model_risks\",\\n            \"reasoning\": \"Limited real-world medical understanding could hamper the effectiveness of the model in clinical applications.\",\\n            \"subject_at_risk\": \"Patients\"\\n        },\\n        {\\n            \"reference_risk\": \"Small models may be more susceptible to hallucination\",\\n            \"source\": \"model_risks\",\\n            \"reasoning\": \"Hallucinations in generated medical content could result in harmful medical decisions.\",\\n            \"subject_at_risk\": \"Patients\"\\n        },\\n        {\\n            \"reference_risk\": \"Produces inaccurate responses\",\\n            \"source\": \"model_risks\",\\n            \"reasoning\": \"Inaccurate responses can misinform healthcare professionals and harm patient care.\",\\n            \"subject_at_risk\": \"Patients\"\\n        },\\n        {\\n            \"reference_risk\": \"Increases risk of identity theft by exposing personal medical information\",\\n            \"source\": \"aiid_risks\",\\n            \"reasoning\": \"Exposure of personal medical data increases identity theft risks.\",\\n            \"subject_at_risk\": \"Patients\"\\n        },\\n        {\\n            \"reference_risk\": \"Harms individuals\\' reputations by potentially revealing private medical information\",\\n            \"source\": \"aiid_risks\",\\n            \"reasoning\": \"Revealing private medical information can damage patient reputations.\",\\n            \"subject_at_risk\": \"Patients\"\\n        },\\n        {\\n            \"reference_risk\": \"Violates privacy by exposing private medical records without consent\",\\n            \"source\": \"aiid_risks\",\\n            \"reasoning\": \"Unconsented exposure of medical records violates privacy laws and ethical guidelines.\",\\n            \"subject_at_risk\": \"Patients\"\\n        }\\n    ]\\n}',\n",
       " '{\\n    \"cardID\": \"231\",\\n    \"use\": \"Domain-- Social Media, Purpose-- Generating engaging social media content, Capability-- Creating videos from trending topics\",\\n    \"risks\": [\\n        {\\n            \"reference_risk\": \"Generates demeaning dehumanizing or otherwise harmful representations of people or their environments cultures religions\",\\n            \"source\": \"model_risks\",\\n            \"reasoning\": \"The model\\'s output might generate harmful and offensive content when applied to social media, impacting social media users.\",\\n            \"subject_at_risk\": \"social media users\"\\n        },\\n        {\\n            \"reference_risk\": \"Generates nonfactual or untrue representations of people or events\",\\n            \"source\": \"model_risks\",\\n            \"reasoning\": \"Creating videos from trending topics may lead to the generation of misinformation or misrepresentation.\",\\n            \"subject_at_risk\": \"social media users\"\\n        },\\n        {\\n            \"reference_risk\": \"Creates offensive degrading or damaging portrayals of individuals their cultures religions or surroundings\",\\n            \"source\": \"model_risks\",\\n            \"reasoning\": \"The output could harm individuals by presenting offensive or degrading images, especially in a diverse social media context.\",\\n            \"subject_at_risk\": \"social media users\"\\n        },\\n        {\\n            \"reference_risk\": \"Generates mis and disinformation\",\\n            \"source\": \"model_risks\",\\n            \"reasoning\": \"There\\'s a risk of spreading false or misleading information through generated videos on social media.\",\\n            \"subject_at_risk\": \"social media users\"\\n        },\\n        {\\n            \"reference_risk\": \"Violates copyright law by unauthorized use of protected content\",\\n            \"source\": \"aiid_risks\",\\n            \"reasoning\": \"Generated content might inadvertently use copyrighted material without permission.\",\\n            \"subject_at_risk\": \"content creators\"\\n        },\\n        {\\n            \"reference_risk\": \"Damages reputations by spreading inaccurate data\",\\n            \"source\": \"aiid_risks\",\\n            \"reasoning\": \"Inaccurate or misleading videos could damage the reputations of individuals or organizations featured in such content.\",\\n            \"subject_at_risk\": \"social media users\"\\n        },\\n        {\\n            \"reference_risk\": \"Facilitates illegal activities by distributing explicit deepfakes\",\\n            \"source\": \"aiid_risks\",\\n            \"reasoning\": \"The model might be misused to create and distribute explicit deepfakes, violating legal standards.\",\\n            \"subject_at_risk\": \"social media users\"\\n        },\\n        {\\n            \"reference_risk\": \"Violates privacy of individuals by creating unauthorized deepfakes\",\\n            \"source\": \"aiid_risks\",\\n            \"reasoning\": \"Deepfakes created without consent could infringe upon individuals\\' privacy.\",\\n            \"subject_at_risk\": \"social media users\"\\n        },\\n        {\\n            \"reference_risk\": \"Misleads users with false information reducing trust in AI systems\",\\n            \"source\": \"aiid_risks\",\\n            \"reasoning\": \"Misinformation through generated content can erode trust in AI among social media users.\",\\n            \"subject_at_risk\": \"social media users\"\\n        },\\n        {\\n            \"reference_risk\": \"Undermines trust in legitimate news sources by spreading propaganda\",\\n            \"source\": \"aiid_risks\",\\n            \"reasoning\": \"Generated videos propagating false information can undermine trust in genuine news sources.\",\\n            \"subject_at_risk\": \"social media users\"\\n        },\\n        {\\n            \"reference_risk\": \"Generates offensive content harming reputations\",\\n            \"source\": \"aiid_risks\",\\n            \"reasoning\": \"Offensive generated content can harm the reputations of individuals or groups featured in the videos.\",\\n            \"subject_at_risk\": \"social media users\"\\n        },\\n        {\\n            \"reference_risk\": \"Undermines public trust in AI by allowing misuse of opensource models for unethical purposes\",\\n            \"source\": \"aiid_risks\",\\n            \"reasoning\": \"The misuse of the model for unethical means can seriously harm public trust in AI technologies.\",\\n            \"subject_at_risk\": \"institution\"\\n        }\\n    ]\\n}',\n",
       " '{\\n    \"cardID\": \"231\",\\n    \"use\": \"Domain-- Marketing and Advertising, Purpose-- Creating engaging promotional videos, Capability-- Generating videos from marketing text\",\\n    \"risks\": \\n    [\\n        {\\n            \"reference_risk\": \"Cannot render legible text\",\\n            \"source\": \"model_risks\",\\n            \"reasoning\": \"In marketing and advertising, the legibility of text is crucial for conveying messages clearly.\",\\n            \"subject_at_risk\": \"ai_user\"\\n        },\\n        {\\n            \"reference_risk\": \"Generates nonfactual or untrue representations of people or events\",\\n            \"source\": \"model_risks\",\\n            \"reasoning\": \"Marketing videos need to be factually accurate to maintain trust and avoid misinformation.\",\\n            \"subject_at_risk\": \"ai_subject\"\\n        },\\n        {\\n            \"reference_risk\": \"Generates demeaning dehumanizing or otherwise harmful representations of people or their environments cultures religions\",\\n            \"source\": \"model_risks\",\\n            \"reasoning\": \"Marketing videos should respect and accurately represent diverse cultures to avoid alienating potential customers.\",\\n            \"subject_at_risk\": \"ai_subject\"\\n        },\\n        {\\n            \"reference_risk\": \"Contains adult material in the training dataset\",\\n            \"source\": \"model_risks\",\\n            \"reasoning\": \"Exposure to adult material is inappropriate and harmful in marketing content aimed at general audiences, including children.\",\\n            \"subject_at_risk\": \"ai_subject\"\\n        },\\n        {\\n            \"reference_risk\": \"Shares modified versions of copyrighted or licensed content in breach of its usage guidelines\",\\n            \"source\": \"model_risks\",\\n            \"reasoning\": \"Using copyrighted content without permission can lead to legal issues and damage the reputation of marketing agencies.\",\\n            \"subject_at_risk\": \"institution\"\\n        },\\n        {\\n            \"reference_risk\": \"Underrepresents communities and cultures using nonEnglish languages\",\\n            \"source\": \"model_risks\",\\n            \"reasoning\": \"Excluding non-English speaking communities may limit the reach and inclusivity of marketing campaigns.\",\\n            \"subject_at_risk\": \"ai_subject\"\\n        },\\n        {\\n            \"reference_risk\": \"Promotes or propagates discriminatory content or harmful stereotypes\",\\n            \"source\": \"model_risks\",\\n            \"reasoning\": \"Marketing content should be inclusive and should not propagate harmful stereotypes which can alienate potential customers.\",\\n            \"subject_at_risk\": \"ai_subject\"\\n        },\\n        {\\n            \"reference_risk\": \"Facilitates misinformation spreading false knowledge\",\\n            \"source\": \"aiid_risks\",\\n            \"reasoning\": \"Accurate information in marketing materials is crucial to maintain consumer trust.\",\\n            \"subject_at_risk\": \"ai_subject\"\\n        },\\n        {\\n            \"reference_risk\": \"Violates privacy of individuals by creating unauthorized deepfakes\",\\n            \"source\": \"aiid_risks\",\\n            \"reasoning\": \"Unauthorized deepfakes can harm individualsâ€™ reputations and privacy.\",\\n            \"subject_at_risk\": \"ai_subject\"\\n        },\\n        {\\n            \"reference_risk\": \"Facilitates illegal activities by distributing explicit deepfakes\",\\n            \"source\": \"aiid_risks\",\\n            \"reasoning\": \"Explicit deepfakes can be illegal and highly damaging, risking severe legal consequences for marketing agencies.\",\\n            \"subject_at_risk\": \"institution\"\\n        },\\n        {\\n            \"reference_risk\": \"Infringes intellectual property rights by misusing image generation technology\",\\n            \"source\": \"aiid_risks\",\\n            \"reasoning\": \"Infringing on intellectual property rights can lead to legal disputes and financial losses.\",\\n            \"subject_at_risk\": \"institution\"\\n        },\\n        {\\n            \"reference_risk\": \"Harms artists economic interests by unauthorized use of their work\",\\n            \"source\": \"aiid_risks\",\\n            \"reasoning\": \"Using an artist\\'s work without authorization can damage their economic interests and lead to legal repercussions.\",\\n            \"subject_at_risk\": \"ai_subject\"\\n        }\\n    ]\\n}',\n",
       " '{\\n    \"cardID\": \"231\",\\n    \"use\": \"Domain-- Education and vocational training, Purpose-- Creating educational content, Capability-- Generating instructional videos from text\",\\n    \"risks\": [\\n        {\\n            \"reference_risk\": \"Cannot render legible text\",\\n            \"source\": \"model_risks\",\\n            \"reasoning\": \"The model may fail to produce clear instructional content if the text is not legible.\",\\n            \"subject_at_risk\": \"Students\"\\n        },\\n        {\\n            \"reference_risk\": \"Underperforms with non-English prompts\",\\n            \"source\": \"model_risks\",\\n            \"reasoning\": \"Limited to English input could reduce effectiveness in a multilingual educational setting.\",\\n            \"subject_at_risk\": \"Students\"\\n        },\\n        {\\n            \"reference_risk\": \"Generates nonfactual or untrue representations of people or events\",\\n            \"source\": \"model_risks\",\\n            \"reasoning\": \"Educational content must be accurate and truthful; otherwise, it misleads students.\",\\n            \"subject_at_risk\": \"Students\"\\n        },\\n        {\\n            \"reference_risk\": \"Creates hostile or alienating environments for people\",\\n            \"source\": \"model_risks\",\\n            \"reasoning\": \"Inappropriate representations may make certain groups feel excluded or targeted.\",\\n            \"subject_at_risk\": \"Students\"\\n        },\\n        {\\n            \"reference_risk\": \"Propagates historical or current stereotypes\",\\n            \"source\": \"model_risks\",\\n            \"reasoning\": \"Educational content needs to be unbiased and inclusive.\",\\n            \"subject_at_risk\": \"Students\"\\n        },\\n        {\\n            \"reference_risk\": \"Fails to produce accurate or truthful depictions of people or events\",\\n            \"source\": \"model_risks\",\\n            \"reasoning\": \"Inaccurate video content can misinform students.\",\\n            \"subject_at_risk\": \"Students\"\\n        },\\n        {\\n            \"reference_risk\": \"Reinforces or exacerbates social biases\",\\n            \"source\": \"model_risks\",\\n            \"reasoning\": \"Educational content should not perpetuate societal biases.\",\\n            \"subject_at_risk\": \"Students\"\\n        },\\n        {\\n            \"reference_risk\": \"Underrepresents communities and cultures using non-English languages\",\\n            \"source\": \"model_risks\",\\n            \"reasoning\": \"Educational content should be inclusive of different cultures and languages.\",\\n            \"subject_at_risk\": \"Students\"\\n        },\\n        {\\n            \"reference_risk\": \"Fails to generate faces and people properly\",\\n            \"source\": \"model_risks\",\\n            \"reasoning\": \"Accurate rendering of human figures is important for instructional videos.\",\\n            \"subject_at_risk\": \"Students\"\\n        },\\n        {\\n            \"reference_risk\": \"Biases towards painting images over realistic images\",\\n            \"source\": \"model_risks\",\\n            \"reasoning\": \"Educational content should be realistic to be effective.\",\\n            \"subject_at_risk\": \"Students\"\\n        },\\n        {\\n            \"reference_risk\": \"Underperforms with non-English captions\",\\n            \"source\": \"model_risks\",\\n            \"reasoning\": \"Limitations in multilingual support can hinder educational goals in diverse settings.\",\\n            \"subject_at_risk\": \"Students\"\\n        },\\n        {\\n            \"reference_risk\": \"Amplifies societal biases\",\\n            \"source\": \"model_risks\",\\n            \"reasoning\": \"Educational content should aim to reduce societal biases, not amplify them.\",\\n            \"subject_at_risk\": \"Students\"\\n        },\\n        {\\n            \"reference_risk\": \"Produces explicit content that can be harmful or inappropriate\",\\n            \"source\": \"aiid_risks\",\\n            \"reasoning\": \"Educational content should be age-appropriate and safe for students.\",\\n            \"subject_at_risk\": \"Students\"\\n        },\\n        {\\n            \"reference_risk\": \"Violates privacy by exposing private medical records without consent\",\\n            \"source\": \"aiid_risks\",\\n            \"reasoning\": \"Educational content must respect privacy and data protection laws.\",\\n            \"subject_at_risk\": \"Institution\"\\n        },\\n        {\\n            \"reference_risk\": \"Generates offensive content harming reputations\",\\n            \"source\": \"aiid_risks\",\\n            \"reasoning\": \"Educational content should be respectful and not harm anyone\\'s reputation.\",\\n            \"subject_at_risk\": \"Students\"\\n        }\\n    ]\\n}',\n",
       " '{\\n    \"cardID\": \"231\",\\n    \"use\": \"Domain-- Well-being, Purpose-- Creating guided meditation videos, Capability-- Generating calming visuals from text\",\\n    \"risks\": [\\n        {\\n            \"reference_risk\": \"Cannot render legible text\",\\n            \"source\": \"model_risks\",\\n            \"reasoning\": \"The model underperforms in text rendering which could be crucial for creating effective guided meditation videos that may require subtitles or overlay text.\",\\n            \"subject_at_risk\": \"ai_subject\"\\n        },\\n        {\\n            \"reference_risk\": \"Biases towards white and western norms\",\\n            \"source\": \"model_risks\",\\n            \"reasoning\": \"The model\\'s bias might result in culturally insensitive or non-inclusive meditation visuals, affecting user experience.\",\\n            \"subject_at_risk\": \"ai_subject\"\\n        },\\n        {\\n            \"reference_risk\": \"Underperforms with non-English prompts\",\\n            \"source\": \"model_risks\",\\n            \"reasoning\": \"Given the global audience for wellness and relaxation, underperforming with non-English prompts could limit accessibility.\",\\n            \"subject_at_risk\": \"ai_subject\"\\n        },\\n        {\\n            \"reference_risk\": \"Fails to achieve perfect photorealism\",\\n            \"source\": \"model_risks\",\\n            \"reasoning\": \"Imperfect visuals could detract from the calming and immersive experience intended for relaxation and meditation.\",\\n            \"subject_at_risk\": \"ai_subject\"\\n        },\\n        {\\n            \"reference_risk\": \"Generates nonfactual or untrue representations of people or events\",\\n            \"source\": \"model_risks\",\\n            \"reasoning\": \"Nonfactual representations could mislead users and affect the authenticity and trust in the guided meditation content.\",\\n            \"subject_at_risk\": \"ai_subject\"\\n        },\\n        {\\n            \"reference_risk\": \"Generate content that is cruel to individuals\",\\n            \"source\": \"model_risks\",\\n            \"reasoning\": \"Cruel content could inadvertently cause psychological harm rather than aid in relaxation.\",\\n            \"subject_at_risk\": \"ai_subject\"\\n        },\\n        {\\n            \"reference_risk\": \"Produces less accurate outputs from non-English prompts\",\\n            \"source\": \"model_risks\",\\n            \"reasoning\": \"Inaccurate outputs for non-English prompts can limit the inclusivity and effectiveness of the meditation content.\",\\n            \"subject_at_risk\": \"ai_subject\"\\n        },\\n        {\\n            \"reference_risk\": \"Generates visuals that might be predictably upsetting, distressing or inappropriate\",\\n            \"source\": \"model_risks\",\\n            \"reasoning\": \"Upsetting or distressing visuals would be counterproductive for a tool intended to promote well-being and relaxation.\",\\n            \"subject_at_risk\": \"ai_subject\"\\n        },\\n        {\\n            \"reference_risk\": \"Displays emerging flashing lights due to training on dance videos\",\\n            \"source\": \"model_risks\",\\n            \"reasoning\": \"Flashing lights could be harmful, especially to individuals prone to epilepsy or susceptible to visual triggers.\",\\n            \"subject_at_risk\": \"ai_subject\"\\n        },\\n        {\\n            \"reference_risk\": \"Sets white and western cultures as the default\",\\n            \"source\": \"model_risks\",\\n            \"reasoning\": \"Setting a default to white and western norms could alienate users from diverse cultural backgrounds.\",\\n            \"subject_at_risk\": \"ai_subject\"\\n        }\\n    ]\\n}',\n",
       " '{\\n    \"cardID\": \"1490\",\\n    \"use\": \"Domain-- Social Media, Purpose-- Creating engaging social media posts, Capability-- Generating GIFs from user content\",\\n    \"risks\": [\\n        {\\n            \"reference_risk\": \"Contains adult material in training data\",\\n            \"source\": \"model_risks\",\\n            \"reasoning\": \"This can result in the unintentional generation of inappropriate or explicit content, which is unsuitable for general social media use.\",\\n            \"subject_at_risk\": \"ai_subject\"\\n        },\\n        {\\n            \"reference_risk\": \"Underperforms with non-English prompts\",\\n            \"source\": \"model_risks\",\\n            \"reasoning\": \"The prevalence of non-English users on social media could lead to an exclusionary user experience for these individuals.\",\\n            \"subject_at_risk\": \"ai_user\"\\n        },\\n        {\\n            \"reference_risk\": \"Generates demeaning, dehumanizing, or harmful representations of people or their environments, cultures, religions\",\\n            \"source\": \"model_risks\",\\n            \"reasoning\": \"Such content can be harmful to both influencers and followers, as well as damaging to diverse cultural representations on social media.\",\\n            \"subject_at_risk\": \"ai_subject\"\\n        },\\n        {\\n            \"reference_risk\": \"Generates non-factual or untrue representations of people or events\",\\n            \"source\": \"model_risks\",\\n            \"reasoning\": \"This can propagate misinformation, leading to potential harm to the reputation of influencers and misleading followers.\",\\n            \"subject_at_risk\": \"ai_subject\"\\n        },\\n        {\\n            \"reference_risk\": \"Spreads misinformation and disinformation\",\\n            \"source\": \"model_risks\",\\n            \"reasoning\": \"The model might generate misleading GIFs, affecting public perception and the credibility of social media influencers.\",\\n            \"subject_at_risk\": \"ai_subject\"\\n        },\\n        {\\n            \"reference_risk\": \"Creates hostile or alienating environments for people\",\\n            \"source\": \"model_risks\",\\n            \"reasoning\": \"Offensive or harmful content could make social media platforms less welcoming.\",\\n            \"subject_at_risk\": \"ai_subject\"\\n        },\\n        {\\n            \"reference_risk\": \"Generates representations of egregious violence and gore\",\\n            \"source\": \"model_risks\",\\n            \"reasoning\": \"Such content is unsuitable for general social media use and can distress followers.\",\\n            \"subject_at_risk\": \"ai_subject\"\\n        },\\n        {\\n            \"reference_risk\": \"Generates sexual content without consent\",\\n            \"source\": \"model_risks\",\\n            \"reasoning\": \"Social media influencers risk sharing content that is inappropriate and without the consent of viewers.\",\\n            \"subject_at_risk\": \"ai_subject\"\\n        },\\n        {\\n            \"reference_risk\": \"Impersonates individuals without their consent\",\\n            \"source\": \"model_risks\",\\n            \"reasoning\": \"This can lead to ethical and legal issues in social media use.\",\\n            \"subject_at_risk\": \"ai_user\"\\n        },\\n        {\\n            \"reference_risk\": \"Fails to generate realistic images due to focus on anime-style content\",\\n            \"source\": \"model_risks\",\\n            \"reasoning\": \"This limits the model\\'s applicability for influencers looking for realistic GIFs.\",\\n            \"subject_at_risk\": \"ai_user\"\\n        },\\n        {\\n            \"reference_risk\": \"Generates demeaning, dehumanizing, or otherwise harmful representations of people or their environments, cultures, religions\",\\n            \"source\": \"model_risks\",\\n            \"reasoning\": \"Such content can damage the influencer\\'s relationship with followers and their public image.\",\\n            \"subject_at_risk\": \"ai_user\"\\n        }\\n    ]\\n}',\n",
       " '{\\n    \"cardID\": \"1490\",\\n    \"use\": \"Domain-- Marketing and Advertising, Purpose-- Creating engaging promotional content, Capability-- Generating GIFs from marketing text\",\\n    \"risks\": [\\n        {\\n            \"reference_risk\": \"Cannot render legible text\",\\n            \"source\": \"model_risks\",\\n            \"reasoning\": \"The AI model might fail to create legible text in generated GIFs, reducing the effectiveness of promotional content\",\\n            \"subject_at_risk\": \"ai_user\"\\n        },\\n        {\\n            \"reference_risk\": \"Underperforms with natural language descriptions due to focus on anime-specific terminologies\",\\n            \"source\": \"model_risks\",\\n            \"reasoning\": \"The model might not accurately interpret marketing text prompts due to its training focus, affecting the quality of the output GIFs\",\\n            \"subject_at_risk\": \"ai_user\"\\n        },\\n        {\\n            \"reference_risk\": \"Contains adult material in training data\",\\n            \"source\": \"model_risks\",\\n            \"reasoning\": \"Generated GIFs might unintentionally contain inappropriate content, which can harm the reputation of the advertising agency and offend potential customers\",\\n            \"subject_at_risk\": \"ai_subject\"\\n        },\\n        {\\n            \"reference_risk\": \"Underperforms with non-English prompts\",\\n            \"source\": \"model_risks\",\\n            \"reasoning\": \"Marketing campaigns aimed at non-English speaking audiences could be less effective due to the model\\'s limitations\",\\n            \"subject_at_risk\": \"ai_user\"\\n        },\\n        {\\n            \"reference_risk\": \"Fails to achieve perfect photorealism\",\\n            \"source\": \"model_risks\",\\n            \"reasoning\": \"The generated GIFs may not appear realistic, which could diminish their appeal in marketing campaigns\",\\n            \"subject_at_risk\": \"ai_subject\"\\n        },\\n        {\\n            \"reference_risk\": \"Generates demeaning, dehumanizing or harmful representations of people or their environments, cultures, religions\",\\n            \"source\": \"model_risks\",\\n            \"reasoning\": \"Such representations could offend potential customers and damage the reputation of the advertising agency\",\\n            \"subject_at_risk\": \"ai_subject\"\\n        },\\n        {\\n            \"reference_risk\": \"Spreads mis and disinformation\",\\n            \"source\": \"model_risks\",\\n            \"reasoning\": \"Sharing inaccurate GIFs in marketing campaigns could mislead potential customers and harm the credibility of the agency\",\\n            \"subject_at_risk\": \"ai_subject\"\\n        },\\n        {\\n            \"reference_risk\": \"Exhibits a bias towards a specific art style due to fine-tuning on similar images\",\\n            \"source\": \"model_risks\",\\n            \"reasoning\": \"The model might generate GIFs that aren\\'t versatile enough for different marketing themes, limiting creative expression\",\\n            \"subject_at_risk\": \"ai_user\"\\n        },\\n        {\\n            \"reference_risk\": \"Underperforms on tasks involving compositionality\",\\n            \"source\": \"model_risks\",\\n            \"reasoning\": \"The model may struggle to generate coherent and complex GIFs required for elaborate marketing messages\",\\n            \"subject_at_risk\": \"ai_user\"\\n        },\\n        {\\n            \"reference_risk\": \"Generates sexual content without consent\",\\n            \"source\": \"model_risks\",\\n            \"reasoning\": \"Inappropriate content could damage the reputation of the advertising agency and offend the audience\",\\n            \"subject_at_risk\": \"ai_subject\"\\n        },\\n        {\\n            \"reference_risk\": \"Fails to generate faces and people properly\",\\n            \"source\": \"model_risks\",\\n            \"reasoning\": \"Poorly rendered faces or people in GIFs could reduce the quality and appeal of marketing material\",\\n            \"subject_at_risk\": \"ai_user\"\\n        },\\n        {\\n            \"reference_risk\": \"Creates hostile or alienating environments by generating disturbing or offensive images\",\\n            \"source\": \"aiid_risks\",\\n            \"reasoning\": \"Offensive or disturbing GIFs in a marketing context could alienate potential customers and harm the agencyâ€™s reputation\",\\n            \"subject_at_risk\": \"institution\"\\n        },\\n        {\\n            \"reference_risk\": \"Promotes or propagates discriminatory content or harmful stereotypes\",\\n            \"source\": \"model_risks\",\\n            \"reasoning\": \"Incorporating discriminatory or stereotypical content in marketing GIFs could offend potential customers and damage the brand image\",\\n            \"subject_at_risk\": \"ai_subject\"\\n        },\\n        {\\n            \"reference_risk\": \"Undermines public trust in AI by demonstrating misuse of AI technology\",\\n            \"source\": \"aiid_risks\",\\n            \"reasoning\": \"Misuse of the AI model in marketing could erode trust in both the technology and the advertising agency\",\\n            \"subject_at_risk\": \"institution\"\\n        },\\n        {\\n            \"reference_risk\": \"Violates intellectual property rights by generating code without proper attribution\",\\n            \"source\": \"aiid_risks\",\\n            \"reasoning\": \"Unauthorized use of content in GIFs could lead to legal repercussions and damage the agencyâ€™s reputation\",\\n            \"subject_at_risk\": \"institution\"\\n        },\\n        {\\n            \"reference_risk\": \"Undermines trust in legitimate news sources by spreading propaganda\",\\n            \"source\": \"aiid_risks\",\\n            \"reasoning\": \"Using the model to generate misleading promotional content could reduce trust in authentic marketing messages\",\\n            \"subject_at_risk\": \"institution\"\\n        }\\n    ]\\n}',\n",
       " '{\\n    \"cardID\": \"1490\",\\n    \"use\": \"Domain-- Education and vocational training, Purpose-- Creating educational animations, Capability-- Generating GIFs from lesson content\",\\n    \"risks\": \\n    [\\n        {\\n            \"reference_risk\": \"Cannot render legible text\",\\n            \"source\": \"model_risks\",\\n            \"reasoning\": \"If the generated GIFs include text that is illegible, it could hinder educational effectiveness.\",\\n            \"subject_at_risk\": \"ai_subject\"\\n        },\\n        {\\n            \"reference_risk\": \"Underperforms with non-English prompts\",\\n            \"source\": \"model_risks\",\\n            \"reasoning\": \"If the model underperforms with non-English prompts, it may fail to generate useful content for students speaking other languages.\",\\n            \"subject_at_risk\": \"ai_subject\"\\n        },\\n        {\\n            \"reference_risk\": \"Generates nonfactual or untrue representations of people or events\",\\n            \"source\": \"model_risks\",\\n            \"reasoning\": \"Generating nonfactual representations can misinform students and undermine educational goals.\",\\n            \"subject_at_risk\": \"ai_subject\"\\n        },\\n        {\\n            \"reference_risk\": \"Spreads mis and disinformation\",\\n            \"source\": \"model_risks\",\\n            \"reasoning\": \"Disseminating misinformation in educational materials can harm students\\' learning and trust in the content.\",\\n            \"subject_at_risk\": \"ai_subject\"\\n        },\\n        {\\n            \"reference_risk\": \"Promotes hate speech by generating and posting racist, misogynistic, and antisemitic content\",\\n            \"source\": \"aiid_risks\",\\n            \"reasoning\": \"Hate speech in educational content can create a hostile and unsafe learning environment.\",\\n            \"subject_at_risk\": \"ai_subject\"\\n        },\\n        {\\n            \"reference_risk\": \"Harms reputations by spreading altered and misleading media\",\\n            \"source\": \"aiid_risks\",\\n            \"reasoning\": \"Spreading misleading media can damage the reputation of the educational institution and teachers involved.\",\\n            \"subject_at_risk\": \"institution\"\\n        },\\n        {\\n            \"reference_risk\": \"Violates human rights by propagating discriminatory and offensive language\",\\n            \"source\": \"aiid_risks\",\\n            \"reasoning\": \"Discriminatory content can violate human rights and harm the well-being of students.\",\\n            \"subject_at_risk\": \"ai_subject\"\\n        },\\n        {\\n            \"reference_risk\": \"Reduces learning outcomes by allowing students to bypass the educational process\",\\n            \"source\": \"aiid_risks\",\\n            \"reasoning\": \"If the tool enables students to shortcut learning, it can reduce the overall effectiveness of education.\",\\n            \"subject_at_risk\": \"ai_subject\"\\n        },\\n        {\\n            \"reference_risk\": \"Generates sexual content without consent of the people who might see it\",\\n            \"source\": \"model_risks\",\\n            \"reasoning\": \"Exposure to inappropriate content can be harmful to students and is unsuitable for educational settings.\",\\n            \"subject_at_risk\": \"ai_subject\"\\n        }\\n    ]\\n}',\n",
       " '{\\n    \"cardID\": \"1490\",\\n    \"use\": \"Domain-- Well-being, Purpose-- Creating motivational content, Capability-- Generating GIFs from wellness quotes\",\\n    \"risks\": [\\n        {\\n            \"reference_risk\": \"Generates demeaning dehumanizing or otherwise harmful representations of people or their environments cultures religions\",\\n            \"source\": \"model_risks\",\\n            \"reasoning\": \"This pertains to the model generating content that might be harmful, which is relevant since motivational content should be positive.\",\\n            \"subject_at_risk\": \"Clients\"\\n        },\\n        {\\n            \"reference_risk\": \"Generates nonfactual or untrue representations of people or events\",\\n            \"source\": \"model_risks\",\\n            \"reasoning\": \"Nonfactual representations can mislead clients seeking motivational content.\",\\n            \"subject_at_risk\": \"Clients\"\\n        },\\n        {\\n            \"reference_risk\": \"Generates demeaning dehumanizing or harmful representations of people or their environments cultures religions\",\\n            \"source\": \"model_risks\",\\n            \"reasoning\": \"Motivational content that demeans or dehumanizes people can harm clients\\' well-being.\",\\n            \"subject_at_risk\": \"Clients\"\\n        },\\n        {\\n            \"reference_risk\": \"Exhibits a bias towards a specific art style due to finetuning on similar images\",\\n            \"source\": \"model_risks\",\\n            \"reasoning\": \"Bias towards a specific art style might limit the model\\'s effectiveness in generating diverse, inclusive motivational content.\",\\n            \"subject_at_risk\": \"Clients\"\\n        },\\n        {\\n            \"reference_risk\": \"Generates representations of egregious violence and gore\",\\n            \"source\": \"model_risks\",\\n            \"reasoning\": \"Content featuring violence and gore is inappropriate and harmful for motivational purposes.\",\\n            \"subject_at_risk\": \"Clients\"\\n        },\\n        {\\n            \"reference_risk\": \"Propagates historical or current stereotypes\",\\n            \"source\": \"model_risks\",\\n            \"reasoning\": \"Stereotypes can negatively impact the inclusivity and positivity of motivational content.\",\\n            \"subject_at_risk\": \"Clients\"\\n        },\\n        {\\n            \"reference_risk\": \"Reinforces or exacerbates social biases\",\\n            \"source\": \"model_risks\",\\n            \"reasoning\": \"Social biases in content could harm the target audience psychologically and socially.\",\\n            \"subject_at_risk\": \"Clients\"\\n        },\\n        {\\n            \"reference_risk\": \"Creates hostile or alienating environments for people\",\\n            \"source\": \"model_risks\",\\n            \"reasoning\": \"Motivational content should not create hostile or alienating environments.\",\\n            \"subject_at_risk\": \"Clients\"\\n        },\\n        {\\n            \"reference_risk\": \"Promotes or propagates discriminatory content or harmful stereotypes\",\\n            \"source\": \"model_risks\",\\n            \"reasoning\": \"Discriminatory content in motivational material can harm clients and undermine the purpose.\",\\n            \"subject_at_risk\": \"Clients\"\\n        },\\n        {\\n            \"reference_risk\": \"Memorizes images that are duplicated in the training data\",\\n            \"source\": \"model_risks\",\\n            \"reasoning\": \"Memorization might lead to repetitive, uninspiring content that does not meet clients\\' needs.\",\\n            \"subject_at_risk\": \"Clients\"\\n        },\\n        {\\n            \"reference_risk\": \"Generates images that people find disturbing distressing or offensive\",\\n            \"source\": \"model_risks\",\\n            \"reasoning\": \"Such images are counterproductive for motivational content aimed at well-being.\",\\n            \"subject_at_risk\": \"Clients\"\\n        }\\n    ]\\n}']"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "responses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_name = \"data/new_data/results/user_study_risks.jsonl\"\n",
    "\n",
    "with open(file_name, 'w') as file:\n",
    "    for obj in responses:\n",
    "        file.write(json.dumps(obj) + '\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create batch job"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating the batch job\n",
    "batch_job = client.batches.create(\n",
    "  input_file_id=batch_file.id,\n",
    "  endpoint=\"/v1/chat/completions\",\n",
    "  completion_window=\"24h\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Batch(id='batch_ST4JywDdQmjUaBnDCQcfcuQy', completion_window='24h', created_at=1722117813, endpoint='/v1/chat/completions', input_file_id='file-uwVuhNk1r6umjV86gmQ8aSmb', object='batch', status='validating', cancelled_at=None, cancelling_at=None, completed_at=None, error_file_id=None, errors=None, expired_at=None, expires_at=1722204213, failed_at=None, finalizing_at=None, in_progress_at=None, metadata=None, output_file_id=None, request_counts=BatchRequestCounts(completed=0, failed=0, total=0))"
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch_job"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_job = client.batches.retrieve('batch_Tc3c7WfqCSsJDVs3hjK5e8DI')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch(id='batch_Tc3c7WfqCSsJDVs3hjK5e8DI', completion_window='24h', created_at=1722110349, endpoint='/v1/chat/completions', input_file_id='file-uhLN61DZof0aTQlj0MopgXO8', object='batch', status='failed', cancelled_at=None, cancelling_at=None, completed_at=None, error_file_id=None, errors=Errors(data=[BatchError(code='duplicate_custom_id', line=2, message='The custom_id for this request is a duplicate of another request. The custom_id parameter must be unique for each request in a batch.', param='custom_id'), BatchError(code='duplicate_custom_id', line=3, message='The custom_id for this request is a duplicate of another request. The custom_id parameter must be unique for each request in a batch.', param='custom_id'), BatchError(code='duplicate_custom_id', line=5, message='The custom_id for this request is a duplicate of another request. The custom_id parameter must be unique for each request in a batch.', param='custom_id'), BatchError(code='duplicate_custom_id', line=6, message='The custom_id for this request is a duplicate of another request. The custom_id parameter must be unique for each request in a batch.', param='custom_id'), BatchError(code='duplicate_custom_id', line=8, message='The custom_id for this request is a duplicate of another request. The custom_id parameter must be unique for each request in a batch.', param='custom_id'), BatchError(code='duplicate_custom_id', line=9, message='The custom_id for this request is a duplicate of another request. The custom_id parameter must be unique for each request in a batch.', param='custom_id')], object='list'), expired_at=None, expires_at=1722196749, failed_at=1722110350, finalizing_at=None, in_progress_at=None, metadata=None, output_file_id=None, request_counts=BatchRequestCounts(completed=0, failed=0, total=0))\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Checking batch status\n",
    "batch_job = client.batches.retrieve(batch_job.id)\n",
    "print(batch_job)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Retrieve results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [],
   "source": [
    "result_file_id = batch_job.output_file_id\n",
    "result = client.files.content(result_file_id).content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_file_name = \"data/new_data/results/user_study_risks.jsonl\"\n",
    "results_file = \"user_study/final_study/user_study_risks_v2.json\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('data/new_data/results/user_study_risks.jsonl',\n",
       " 'data/new_data/results/user_study_risks_v2.json')"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results_file_name, results_file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading data from saved file\n",
    "results = []\n",
    "with open(results_file_name, 'r') as file:\n",
    "    for line in file:\n",
    "        # Parsing the JSON string into a dict and appending to the list of results\n",
    "        json_object = json.loads(line.strip())\n",
    "        results.append(json_object)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "    \"cardID\": \"44\",\n",
      "    \"use\": \"Domain-- Recommender Systems and Personalization, Purpose-- Recommending personalized content, Capability-- Analyzing user preferences and suggesting items\",\n",
      "    \"risks\": [\n",
      "        {\n",
      "            \"reference_risk\": \"Induces bias and safety issues due to lack of diverse training data\",\n",
      "            \"source\": \"model_risks\",\n",
      "            \"reasoning\": \"Lack of diverse training data can result in biased recommendations which can influence user preferences unfairly.\",\n",
      "            \"subject_at_risk\": \"ai_subject\"\n",
      "        },\n",
      "        {\n",
      "            \"reference_risk\": \"Produces low diversity and hallucinated outputs\",\n",
      "            \"source\": \"model_risks\",\n",
      "            \"reasoning\": \"Low diversity in generated content can limit the range of personalized recommendations, potentially reducing user engagement.\",\n",
      "            \"subject_at_risk\": \"ai_subject\"\n",
      "        },\n",
      "        {\n",
      "            \"reference_risk\": \"Has quality issues in terms of generation diversity\",\n",
      "            \"source\": \"model_risks\",\n",
      "            \"reasoning\": \"Quality issues in generation can impact the precision and relevance of recommended content.\",\n",
      "            \"subject_at_risk\": \"ai_subject\"\n",
      "        },\n",
      "        {\n",
      "            \"reference_risk\": \"Generates hallucinations\",\n",
      "            \"source\": \"model_risks\",\n",
      "            \"reasoning\": \"Hallucinated outputs can mislead users, harming their experience through incorrect recommendations.\",\n",
      "            \"subject_at_risk\": \"ai_subject\"\n",
      "        },\n",
      "        {\n",
      "            \"reference_risk\": \"Exhibits biases\",\n",
      "            \"source\": \"model_risks\",\n",
      "            \"reasoning\": \"Biases in recommendations can propagate stereotypical or unfair content, adversely impacting user experience.\",\n",
      "            \"subject_at_risk\": \"ai_subject\"\n",
      "        },\n",
      "        {\n",
      "            \"reference_risk\": \"Contains biased training data from the internet\",\n",
      "            \"source\": \"model_risks\",\n",
      "            \"reasoning\": \"Biased training data can result in recommendations that reinforce negative stereotypes.\",\n",
      "            \"subject_at_risk\": \"ai_subject\"\n",
      "        },\n",
      "        {\n",
      "            \"reference_risk\": \"Produces factual inaccuracies\",\n",
      "            \"source\": \"model_risks\",\n",
      "            \"reasoning\": \"Factual inaccuracies in recommendations can affect the credibility of the streaming platform.\",\n",
      "            \"subject_at_risk\": \"ai_user\"\n",
      "        },\n",
      "        {\n",
      "            \"reference_risk\": \"Generates toxic content\",\n",
      "            \"source\": \"model_risks\",\n",
      "            \"reasoning\": \"Toxic content in recommendations can harm user trust and the platform's reputation.\",\n",
      "            \"subject_at_risk\": \"ai_subject\"\n",
      "        },\n",
      "        {\n",
      "            \"reference_risk\": \"Enforces stereotypes\",\n",
      "            \"source\": \"model_risks\",\n",
      "            \"reasoning\": \"Content suggestions that reinforce stereotypes can cause social harm and limit user diversity in content consumption.\",\n",
      "            \"subject_at_risk\": \"ai_subject\"\n",
      "        },\n",
      "        {\n",
      "            \"reference_risk\": \"Produces offensive responses\",\n",
      "            \"source\": \"model_risks\",\n",
      "            \"reasoning\": \"Offensive content recommendations can harm user trust and negatively affect user experience.\",\n",
      "            \"subject_at_risk\": \"ai_subject\"\n",
      "        },\n",
      "        {\n",
      "            \"reference_risk\": \"Increases social division by amplifying extremist viewpoints\",\n",
      "            \"source\": \"aiid_risks\",\n",
      "            \"reasoning\": \"Recommendations that promote extremist content can lead to social divisiveness.\",\n",
      "            \"subject_at_risk\": \"institution\"\n",
      "        },\n",
      "        {\n",
      "            \"reference_risk\": \"Harms community wellbeing by spreading toxic and harmful messages\",\n",
      "            \"source\": \"aiid_risks\",\n",
      "            \"reasoning\": \"Personalized recommendations that include toxic content can damage the community's overall wellbeing.\",\n",
      "            \"subject_at_risk\": \"ai_subject\"\n",
      "        },\n",
      "        {\n",
      "            \"reference_risk\": \"Facilitates misinformation spreading false knowledge\",\n",
      "            \"source\": \"aiid_risks\",\n",
      "            \"reasoning\": \"Inaccurate content recommendations can contribute to the spread of misinformation.\",\n",
      "            \"subject_at_risk\": \"ai_subject\"\n",
      "        },\n",
      "        {\n",
      "            \"reference_risk\": \"Undermines public trust in AI by demonstrating misuse of AI technology\",\n",
      "            \"source\": \"aiid_risks\",\n",
      "            \"reasoning\": \"Misuse of AI in personalized recommendations can erode public trust in AI technologies overall.\",\n",
      "            \"subject_at_risk\": \"institution\"\n",
      "        },\n",
      "        {\n",
      "            \"reference_risk\": \"Undermines trust in AI systems by failing to protect user data\",\n",
      "            \"source\": \"aiid_risks\",\n",
      "            \"reasoning\": \"If the AI model compromises user data privacy, it can weaken trust in the streaming platform.\",\n",
      "            \"subject_at_risk\": \"ai_user\"\n",
      "        },\n",
      "        {\n",
      "            \"reference_risk\": \"Damages reputations by associating individuals or groups with offensive content\",\n",
      "            \"source\": \"aiid_risks\",\n",
      "            \"reasoning\": \"Recommendations that include or link to offensive content can harm reputations of individuals or groups featured in that content.\",\n",
      "            \"subject_at_risk\": \"ai_subject\"\n",
      "        },\n",
      "        {\n",
      "            \"reference_risk\": \"Violates privacy rights by disclosing sensitive personal data\",\n",
      "            \"source\": \"aiid_risks\",\n",
      "            \"reasoning\": \"If the model recommendations inadvertently reveal sensitive user data, it violates user privacy rights.\",\n",
      "            \"subject_at_risk\": \"ai_user\"\n",
      "        }\n",
      "    ]\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "for res in results:\n",
    "    print (res)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "FULL_RES = []\n",
    "cnt_errors = []\n",
    "\n",
    "# Reading only the first results\n",
    "for res in results:\n",
    "    try:\n",
    "        res = ast.literal_eval(res)\n",
    "        # print (index)\n",
    "        # res[\"Incident ID\"] = int(index)\n",
    "        FULL_RES.append(res)\n",
    "    except Exception as e:\n",
    "        print (e)\n",
    "        # print (result)\n",
    "        cnt_errors.append(res)\n",
    "        continue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cnt_errors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'cardID': '44',\n",
       "  'use': 'Domain-- Recommender Systems and Personalization, Purpose-- Recommending personalized content, Capability-- Analyzing user preferences and suggesting items',\n",
       "  'risks': [{'reference_risk': 'Induces bias and safety issues due to lack of diverse training data',\n",
       "    'source': 'model_risks',\n",
       "    'reasoning': 'Lack of diverse training data can result in biased recommendations which can influence user preferences unfairly.',\n",
       "    'subject_at_risk': 'ai_subject'},\n",
       "   {'reference_risk': 'Produces low diversity and hallucinated outputs',\n",
       "    'source': 'model_risks',\n",
       "    'reasoning': 'Low diversity in generated content can limit the range of personalized recommendations, potentially reducing user engagement.',\n",
       "    'subject_at_risk': 'ai_subject'},\n",
       "   {'reference_risk': 'Has quality issues in terms of generation diversity',\n",
       "    'source': 'model_risks',\n",
       "    'reasoning': 'Quality issues in generation can impact the precision and relevance of recommended content.',\n",
       "    'subject_at_risk': 'ai_subject'},\n",
       "   {'reference_risk': 'Generates hallucinations',\n",
       "    'source': 'model_risks',\n",
       "    'reasoning': 'Hallucinated outputs can mislead users, harming their experience through incorrect recommendations.',\n",
       "    'subject_at_risk': 'ai_subject'},\n",
       "   {'reference_risk': 'Exhibits biases',\n",
       "    'source': 'model_risks',\n",
       "    'reasoning': 'Biases in recommendations can propagate stereotypical or unfair content, adversely impacting user experience.',\n",
       "    'subject_at_risk': 'ai_subject'},\n",
       "   {'reference_risk': 'Contains biased training data from the internet',\n",
       "    'source': 'model_risks',\n",
       "    'reasoning': 'Biased training data can result in recommendations that reinforce negative stereotypes.',\n",
       "    'subject_at_risk': 'ai_subject'},\n",
       "   {'reference_risk': 'Produces factual inaccuracies',\n",
       "    'source': 'model_risks',\n",
       "    'reasoning': 'Factual inaccuracies in recommendations can affect the credibility of the streaming platform.',\n",
       "    'subject_at_risk': 'ai_user'},\n",
       "   {'reference_risk': 'Generates toxic content',\n",
       "    'source': 'model_risks',\n",
       "    'reasoning': \"Toxic content in recommendations can harm user trust and the platform's reputation.\",\n",
       "    'subject_at_risk': 'ai_subject'},\n",
       "   {'reference_risk': 'Enforces stereotypes',\n",
       "    'source': 'model_risks',\n",
       "    'reasoning': 'Content suggestions that reinforce stereotypes can cause social harm and limit user diversity in content consumption.',\n",
       "    'subject_at_risk': 'ai_subject'},\n",
       "   {'reference_risk': 'Produces offensive responses',\n",
       "    'source': 'model_risks',\n",
       "    'reasoning': 'Offensive content recommendations can harm user trust and negatively affect user experience.',\n",
       "    'subject_at_risk': 'ai_subject'},\n",
       "   {'reference_risk': 'Increases social division by amplifying extremist viewpoints',\n",
       "    'source': 'aiid_risks',\n",
       "    'reasoning': 'Recommendations that promote extremist content can lead to social divisiveness.',\n",
       "    'subject_at_risk': 'institution'},\n",
       "   {'reference_risk': 'Harms community wellbeing by spreading toxic and harmful messages',\n",
       "    'source': 'aiid_risks',\n",
       "    'reasoning': \"Personalized recommendations that include toxic content can damage the community's overall wellbeing.\",\n",
       "    'subject_at_risk': 'ai_subject'},\n",
       "   {'reference_risk': 'Facilitates misinformation spreading false knowledge',\n",
       "    'source': 'aiid_risks',\n",
       "    'reasoning': 'Inaccurate content recommendations can contribute to the spread of misinformation.',\n",
       "    'subject_at_risk': 'ai_subject'},\n",
       "   {'reference_risk': 'Undermines public trust in AI by demonstrating misuse of AI technology',\n",
       "    'source': 'aiid_risks',\n",
       "    'reasoning': 'Misuse of AI in personalized recommendations can erode public trust in AI technologies overall.',\n",
       "    'subject_at_risk': 'institution'},\n",
       "   {'reference_risk': 'Undermines trust in AI systems by failing to protect user data',\n",
       "    'source': 'aiid_risks',\n",
       "    'reasoning': 'If the AI model compromises user data privacy, it can weaken trust in the streaming platform.',\n",
       "    'subject_at_risk': 'ai_user'},\n",
       "   {'reference_risk': 'Damages reputations by associating individuals or groups with offensive content',\n",
       "    'source': 'aiid_risks',\n",
       "    'reasoning': 'Recommendations that include or link to offensive content can harm reputations of individuals or groups featured in that content.',\n",
       "    'subject_at_risk': 'ai_subject'},\n",
       "   {'reference_risk': 'Violates privacy rights by disclosing sensitive personal data',\n",
       "    'source': 'aiid_risks',\n",
       "    'reasoning': 'If the model recommendations inadvertently reveal sensitive user data, it violates user privacy rights.',\n",
       "    'subject_at_risk': 'ai_user'}]},\n",
       " {'cardID': '44',\n",
       "  'use': 'Domain-- Marketing and Advertising, Purpose-- Creating personalized ad copy, Capability-- Generating tailored messages from user data',\n",
       "  'risks': [{'reference_risk': 'Underperforms in nonresearch environments',\n",
       "    'source': 'model_risks',\n",
       "    'reasoning': 'The model might not achieve the desired performance in practical marketing scenarios since it is trained in research settings.',\n",
       "    'subject_at_risk': 'ai_user'},\n",
       "   {'reference_risk': 'Induces bias and safety issues due to lack of diverse training data',\n",
       "    'source': 'model_risks',\n",
       "    'reasoning': 'Bias from non-diverse training data can affect the fairness and safety of generated ad content.',\n",
       "    'subject_at_risk': 'ai_subject'},\n",
       "   {'reference_risk': 'Produces low diversity and hallucinated outputs',\n",
       "    'source': 'model_risks',\n",
       "    'reasoning': 'Low diversity and hallucinations can reduce the quality and reliability of generated ad copy, affecting marketing effectiveness.',\n",
       "    'subject_at_risk': 'ai_user'},\n",
       "   {'reference_risk': 'Produces toxic content',\n",
       "    'source': 'model_risks',\n",
       "    'reasoning': 'Generated ad content might include offensive or harmful language, damaging brand reputation.',\n",
       "    'subject_at_risk': 'ai_subject'},\n",
       "   {'reference_risk': 'Generates factual inaccuracies',\n",
       "    'source': 'model_risks',\n",
       "    'reasoning': 'Inaccurate information in ad copy can mislead consumers and harm the credibility of marketing campaigns.',\n",
       "    'subject_at_risk': 'ai_subject'},\n",
       "   {'reference_risk': 'Contains biased training data from the internet',\n",
       "    'source': 'model_risks',\n",
       "    'reasoning': 'Biases in the training data can lead to biased ad content, negatively affecting consumer perception.',\n",
       "    'subject_at_risk': 'ai_subject'},\n",
       "   {'reference_risk': 'Undermines public trust in AI by demonstrating misuse of AI technology',\n",
       "    'source': 'aiid_risks',\n",
       "    'reasoning': 'Misuse in marketing could erode consumer trust in AI-generated content.',\n",
       "    'subject_at_risk': 'institution'},\n",
       "   {'reference_risk': 'Generates disinformation by creating misleading or false images',\n",
       "    'source': 'aiid_risks',\n",
       "    'reasoning': 'Generating misleading ad content can harm consumer trust and lead to legal repercussions.',\n",
       "    'subject_at_risk': 'ai_subject'},\n",
       "   {'reference_risk': 'Generates offensive content harming reputations',\n",
       "    'source': 'aiid_risks',\n",
       "    'reasoning': 'Offensive content can damage the reputation of the marketing agency or the brand.',\n",
       "    'subject_at_risk': 'ai_user'}]},\n",
       " {'cardID': '44',\n",
       "  'use': 'Domain-- Education and vocational training, Purpose-- Personalizing learning experiences, Capability-- Analyzing student performance and tailoring content',\n",
       "  'risks': [{'reference_risk': 'Underperforms compared to state-of-the-art models',\n",
       "    'source': 'model_risks',\n",
       "    'reasoning': 'This can affect the personalization and accuracy in analyzing student performance and tailoring content.',\n",
       "    'subject_at_risk': 'Students'},\n",
       "   {'reference_risk': 'Produces low diversity and hallucinated outputs',\n",
       "    'source': 'model_risks',\n",
       "    'reasoning': 'Hallucinated outputs can mislead students, reducing the quality of personalized learning experiences.',\n",
       "    'subject_at_risk': 'Students'},\n",
       "   {'reference_risk': 'Has quality issues in terms of generation diversity',\n",
       "    'source': 'model_risks',\n",
       "    'reasoning': 'Lack of diversity in generated content can inhibit comprehensive educational outcomes.',\n",
       "    'subject_at_risk': 'Students'},\n",
       "   {'reference_risk': 'Generates factual inaccuracies',\n",
       "    'source': 'model_risks',\n",
       "    'reasoning': 'Factual inaccuracies can misinform students, negatively affecting their learning.',\n",
       "    'subject_at_risk': 'Students'},\n",
       "   {'reference_risk': 'Produces offensive responses',\n",
       "    'source': 'model_risks',\n",
       "    'reasoning': \"Offensive content can harm students' experience and trust in the educational platform.\",\n",
       "    'subject_at_risk': 'Students'},\n",
       "   {'reference_risk': 'Exhibits biases',\n",
       "    'source': 'model_risks',\n",
       "    'reasoning': 'Bias in content can lead to unfair educational outcomes and propagate stereotypes.',\n",
       "    'subject_at_risk': 'Students'},\n",
       "   {'reference_risk': 'Generates toxic language',\n",
       "    'source': 'model_risks',\n",
       "    'reasoning': 'Toxic language can cause psychological harm and undermine the learning environment.',\n",
       "    'subject_at_risk': 'Students'},\n",
       "   {'reference_risk': 'Undermines factual correctness',\n",
       "    'source': 'model_risks',\n",
       "    'reasoning': 'Incorrect facts can directly harm the educational value.',\n",
       "    'subject_at_risk': 'Students'},\n",
       "   {'reference_risk': 'Violates academic policies by using unauthorized assistance in completing assignments',\n",
       "    'source': 'aiid_risks',\n",
       "    'reasoning': 'AI-generated content can be used to bypass academic integrity protocols.',\n",
       "    'subject_at_risk': 'Students'},\n",
       "   {'reference_risk': 'Undermines academic integrity by enabling students to submit AI-generated work as their own',\n",
       "    'source': 'aiid_risks',\n",
       "    'reasoning': 'Erodes the fairness of academic assessments and the educational process.',\n",
       "    'subject_at_risk': 'Students'},\n",
       "   {'reference_risk': 'Exposes personally identifiable information due to memorization of training data',\n",
       "    'source': 'aiid_risks',\n",
       "    'reasoning': 'Breaches student privacy, potentially leaking sensitive information.',\n",
       "    'subject_at_risk': 'Students'},\n",
       "   {'reference_risk': 'Reduces learning outcomes by allowing students to bypass the educational process',\n",
       "    'source': 'aiid_risks',\n",
       "    'reasoning': 'The efficacy of education is compromised when students rely on AI-generated content.',\n",
       "    'subject_at_risk': 'Students'},\n",
       "   {'reference_risk': 'Exposes confidential information by revealing internal instructions',\n",
       "    'source': 'aiid_risks',\n",
       "    'reasoning': 'Confidential academic information might be inadvertently disclosed.',\n",
       "    'subject_at_risk': 'Institution'},\n",
       "   {'reference_risk': 'Increases unfair advantage by providing some students with access to advanced AI tools',\n",
       "    'source': 'aiid_risks',\n",
       "    'reasoning': 'Creates inequitable learning conditions among students.',\n",
       "    'subject_at_risk': 'Students'},\n",
       "   {'reference_risk': 'Facilitates misinformation spreading false knowledge',\n",
       "    'source': 'aiid_risks',\n",
       "    'reasoning': \"Inaccurate information can cause long-term harm to students' educational foundation.\",\n",
       "    'subject_at_risk': 'Students'}]},\n",
       " {'cardID': '44',\n",
       "  'use': 'Domain-- Arts and Entertainment, Purpose-- Generating creative writing prompts, Capability-- Analyzing themes and creating prompts',\n",
       "  'risks': [{'reference_risk': 'Underperforms in nonresearch environments',\n",
       "    'source': 'model_risks',\n",
       "    'reasoning': 'The model might not generate high-quality writing prompts outside controlled research settings.',\n",
       "    'subject_at_risk': 'ai_user'},\n",
       "   {'reference_risk': 'Induces bias and safety issues due to lack of diverse training data',\n",
       "    'source': 'model_risks',\n",
       "    'reasoning': 'The generated content might reflect biases from the non-diverse training data.',\n",
       "    'subject_at_risk': 'ai_subject'},\n",
       "   {'reference_risk': 'Produces low diversity and hallucinated outputs',\n",
       "    'source': 'model_risks',\n",
       "    'reasoning': 'The prompts might lack creativity or include fabrications, reducing their usefulness for writers.',\n",
       "    'subject_at_risk': 'ai_user'},\n",
       "   {'reference_risk': 'Produces toxic content',\n",
       "    'source': 'model_risks',\n",
       "    'reasoning': 'Toxic language could be generated, affecting the quality and safety of the prompts.',\n",
       "    'subject_at_risk': 'ai_subject'},\n",
       "   {'reference_risk': 'Contains biased training data from the internet',\n",
       "    'source': 'model_risks',\n",
       "    'reasoning': 'The prompts might inadvertently carry biases prevalent on the internet.',\n",
       "    'subject_at_risk': 'ai_subject'},\n",
       "   {'reference_risk': 'Generates factual inaccuracies',\n",
       "    'source': 'model_risks',\n",
       "    'reasoning': 'Incorrect information could be embedded in the writing prompts.',\n",
       "    'subject_at_risk': 'ai_subject'},\n",
       "   {'reference_risk': 'Induces downstream impact on model quality due to lack of training data diversity',\n",
       "    'source': 'model_risks',\n",
       "    'reasoning': 'Future models fine-tuned on this data might also exhibit similar issues.',\n",
       "    'subject_at_risk': 'institution'},\n",
       "   {'reference_risk': 'Generates hallucinations',\n",
       "    'source': 'model_risks',\n",
       "    'reasoning': 'Text created might include elements that are factually incorrect or unrelated.',\n",
       "    'subject_at_risk': 'ai_subject'},\n",
       "   {'reference_risk': 'Exhibits biases',\n",
       "    'source': 'model_risks',\n",
       "    'reasoning': 'Generated content could reinforce existing biases and stereotypes.',\n",
       "    'subject_at_risk': 'ai_subject'},\n",
       "   {'reference_risk': 'Generates offensive responses',\n",
       "    'source': 'model_risks',\n",
       "    'reasoning': 'Content produced might unintentionally offend users or readers.',\n",
       "    'subject_at_risk': 'ai_user'},\n",
       "   {'reference_risk': 'Undermines factual correctness',\n",
       "    'source': 'model_risks',\n",
       "    'reasoning': 'The model might not be reliable for creating factually accurate prompts.',\n",
       "    'subject_at_risk': 'ai_subject'},\n",
       "   {'reference_risk': 'Transfers bias to all finetuned versions of the model',\n",
       "    'source': 'model_risks',\n",
       "    'reasoning': 'Any subsequent versions of the model will carry over the existing biases.',\n",
       "    'subject_at_risk': 'institution'},\n",
       "   {'reference_risk': 'Facilitates misinformation spreading false knowledge',\n",
       "    'source': 'aiid_risks',\n",
       "    'reasoning': 'Generated writing prompts might inadvertently spread false information.',\n",
       "    'subject_at_risk': 'ai_subject'},\n",
       "   {'reference_risk': 'Promotes hate speech by generating and posting racist misogynistic and antisemitic content',\n",
       "    'source': 'aiid_risks',\n",
       "    'reasoning': 'There is a risk of generating content that can be harmful and discriminatory.',\n",
       "    'subject_at_risk': 'ai_subject'},\n",
       "   {'reference_risk': 'Undermines public trust in AI by demonstrating misuse of AI technology',\n",
       "    'source': 'aiid_risks',\n",
       "    'reasoning': 'Poorly generated content can make users skeptical about the potential of AI in creative writing.',\n",
       "    'subject_at_risk': 'institution'},\n",
       "   {'reference_risk': 'Violates human rights by propagating discriminatory and offensive language',\n",
       "    'source': 'aiid_risks',\n",
       "    'reasoning': 'Generated content might contain discriminatory language.',\n",
       "    'subject_at_risk': 'ai_subject'},\n",
       "   {'reference_risk': 'Marginalizes intersectional identities by embedding multiple biases',\n",
       "    'source': 'aiid_risks',\n",
       "    'reasoning': 'Content might marginalize individuals by perpetuating overlapping biases.',\n",
       "    'subject_at_risk': 'ai_subject'},\n",
       "   {'reference_risk': 'Perpetuates gender biases by producing stereotypical depictions',\n",
       "    'source': 'aiid_risks',\n",
       "    'reasoning': 'Writing prompts might unintentionally reinforce gender stereotypes.',\n",
       "    'subject_at_risk': 'ai_subject'},\n",
       "   {'reference_risk': 'Increases psychological harm by causing fear and anxiety through threatening statements',\n",
       "    'source': 'aiid_risks',\n",
       "    'reasoning': 'Generated content might inadvertently contain language that causes anxiety or fear.',\n",
       "    'subject_at_risk': 'ai_subject'},\n",
       "   {'reference_risk': 'Generates offensive content harming reputations',\n",
       "    'source': 'aiid_risks',\n",
       "    'reasoning': 'Content might damage reputations by being offensive or defamatory.',\n",
       "    'subject_at_risk': 'ai_user'}]},\n",
       " {'cardID': '82',\n",
       "  'use': 'Domain-- Recommender Systems and Personalization, Purpose-- Recommending personalized content, Capability-- Analyzing preferences for suggestions',\n",
       "  'risks': [{'reference_risk': 'Erases representation of some groups',\n",
       "    'source': 'model_risks',\n",
       "    'reasoning': 'The model may fail to recommend content representing minority or underrepresented groups.',\n",
       "    'subject_at_risk': 'Content consumers'},\n",
       "   {'reference_risk': 'Underperforms on languages other than English',\n",
       "    'source': 'model_risks',\n",
       "    'reasoning': 'The model is likely to provide poor recommendations in languages other than English, leading to a subpar experience.',\n",
       "    'subject_at_risk': 'Content consumers'},\n",
       "   {'reference_risk': 'Produces unfair, unreliable, or offensive outputs in high-risk scenarios',\n",
       "    'source': 'model_risks',\n",
       "    'reasoning': 'The recommender system could produce biased or inappropriate suggestions, which might be offensive or harmful, particularly in sensitive contexts.',\n",
       "    'subject_at_risk': 'Content consumers'},\n",
       "   {'reference_risk': 'Produces inaccurate or outdated content',\n",
       "    'source': 'model_risks',\n",
       "    'reasoning': 'The system might recommend outdated or incorrect content, which can misinform users or lead to dissatisfaction.',\n",
       "    'subject_at_risk': 'Content consumers'},\n",
       "   {'reference_risk': 'Reinforces demeaning or negative stereotypes',\n",
       "    'source': 'model_risks',\n",
       "    'reasoning': 'The recommender system might prompt content that reinforces harmful stereotypes based on the data it has been trained on.',\n",
       "    'subject_at_risk': 'Content consumers'},\n",
       "   {'reference_risk': 'Fabricates content that is inaccurate or outdated',\n",
       "    'source': 'model_risks',\n",
       "    'reasoning': 'The system might generate and recommend fabricated content, causing misinformation.',\n",
       "    'subject_at_risk': 'Content consumers'},\n",
       "   {'reference_risk': 'Misuse for fraud, spam, or malware production',\n",
       "    'source': 'model_risks',\n",
       "    'reasoning': 'The system might be exploited to recommend harmful or malicious content to users.',\n",
       "    'subject_at_risk': 'Content consumers'},\n",
       "   {'reference_risk': 'Produces offensive content harming reputations',\n",
       "    'source': 'aiid_risks',\n",
       "    'reasoning': 'The system could inadvertently recommend offensive content, which could damage the reputation of the content platform.',\n",
       "    'subject_at_risk': 'Streaming platforms'},\n",
       "   {'reference_risk': 'Increases psychological harm by causing fear and anxiety through threatening statements',\n",
       "    'source': 'aiid_risks',\n",
       "    'reasoning': 'Recommendations might include distressing content that can cause psychological harm to users.',\n",
       "    'subject_at_risk': 'Content consumers'}]},\n",
       " {'cardID': '82',\n",
       "  'use': 'Domain-- Marketing and Advertising, Purpose-- Creating personalized ad campaigns, Capability-- Analyzing user behavior from social media posts',\n",
       "  'risks': [{'reference_risk': 'Produces unfair unreliable or offensive outputs in highrisk scenarios',\n",
       "    'source': 'model_risks',\n",
       "    'reasoning': 'Relevant since personalized ad campaigns in marketing could present sensitive or offensive material to users.',\n",
       "    'subject_at_risk': 'ai_subject'},\n",
       "   {'reference_risk': 'Produces inaccurate or outdated content',\n",
       "    'source': 'model_risks',\n",
       "    'reasoning': 'Relevant to marketing as presenting outdated content can harm the effectiveness of ad campaigns.',\n",
       "    'subject_at_risk': 'ai_user'},\n",
       "   {'reference_risk': 'Produces harmful content if explicitly prompted or instructed',\n",
       "    'source': 'model_risks',\n",
       "    'reasoning': 'Ad campaigns could potentially be designed to mislead or harm consumer groups.',\n",
       "    'subject_at_risk': 'ai_subject'},\n",
       "   {'reference_risk': 'Reinforces demeaning or negative stereotypes',\n",
       "    'source': 'model_risks',\n",
       "    'reasoning': 'Marketing content could unintentionally reinforce societal biases or stereotypes.',\n",
       "    'subject_at_risk': 'ai_subject'},\n",
       "   {'reference_risk': 'Produces problematic outputs without intheloop filtering of responses',\n",
       "    'source': 'model_risks',\n",
       "    'reasoning': 'Critical for marketing as unchecked outputs could lead to offensive or inappropriate advertisements.',\n",
       "    'subject_at_risk': 'ai_subject'},\n",
       "   {'reference_risk': 'Generates content that mirrors societal biases',\n",
       "    'source': 'model_risks',\n",
       "    'reasoning': 'Marketing content should be fair and unbiased, making this risk pertinent.',\n",
       "    'subject_at_risk': 'ai_subject'},\n",
       "   {'reference_risk': 'Uses a mix of Web data and technical sources without transparency',\n",
       "    'source': 'model_risks',\n",
       "    'reasoning': 'Important for marketing as lack of data transparency can harm trust between agencies and clients.',\n",
       "    'subject_at_risk': 'institution'},\n",
       "   {'reference_risk': 'Misuse for fraud spam or malware production',\n",
       "    'source': 'model_risks',\n",
       "    'reasoning': 'Relevant as marketing tools can be misused for fraudulent activities.',\n",
       "    'subject_at_risk': 'ai_user'},\n",
       "   {'reference_risk': 'Generates content that includes threats to destroy humankind',\n",
       "    'source': 'aiid_risks',\n",
       "    'reasoning': 'Although extreme, any offensive or harmful content can severely impact user perception of marketing campaigns.',\n",
       "    'subject_at_risk': 'ai_subject'},\n",
       "   {'reference_risk': 'Spreads misinformation by generating false facts about nonexistent events',\n",
       "    'source': 'aiid_risks',\n",
       "    'reasoning': 'Pertinent to personalized ad campaigns as they must provide accurate information.',\n",
       "    'subject_at_risk': 'ai_subject'},\n",
       "   {'reference_risk': 'Violates ethical standards by promoting harmful stereotypes',\n",
       "    'source': 'aiid_risks',\n",
       "    'reasoning': 'Important to ensure marketing content adheres to ethical standards.',\n",
       "    'subject_at_risk': 'ai_subject'},\n",
       "   {'reference_risk': 'Discriminates against marginalized groups by perpetuating harmful biases',\n",
       "    'source': 'aiid_risks',\n",
       "    'reasoning': 'Critical since advertisements must be inclusive and fair to all groups.',\n",
       "    'subject_at_risk': 'ai_subject'},\n",
       "   {'reference_risk': 'Offends users by making offensive remarks',\n",
       "    'source': 'aiid_risks',\n",
       "    'reasoning': 'Highly pertinent to making sure personalized ads do not alienate or offend consumers.',\n",
       "    'subject_at_risk': 'ai_subject'},\n",
       "   {'reference_risk': 'Harms reputations by making inconsistent remarks',\n",
       "    'source': 'aiid_risks',\n",
       "    'reasoning': 'Relevant as inconsistent marketing messages can harm the reputation of brands.',\n",
       "    'subject_at_risk': 'ai_user'},\n",
       "   {'reference_risk': 'Promotes stereotypes by invoking Jewish stereotypes',\n",
       "    'source': 'aiid_risks',\n",
       "    'reasoning': 'Relevant to ensure marketing content avoids specific harmful stereotypes.',\n",
       "    'subject_at_risk': 'ai_subject'}]},\n",
       " {'cardID': '82',\n",
       "  'use': 'Domain-- Education and vocational training, Purpose-- Personalizing learning experiences, Capability-- Analyzing student performance and tailoring content',\n",
       "  'risks': [{'reference_risk': 'Erases representation of some groups',\n",
       "    'source': 'model_risks',\n",
       "    'reasoning': 'The model may erase the representation of certain groups in educational content, impacting the inclusivity of learning experiences.',\n",
       "    'subject_at_risk': 'Students'},\n",
       "   {'reference_risk': 'Underperforms on languages other than English',\n",
       "    'source': 'model_risks',\n",
       "    'reasoning': \"The model's underperformance on non-English languages could limit its effectiveness for students who are not proficient in English.\",\n",
       "    'subject_at_risk': 'Students'},\n",
       "   {'reference_risk': 'Produces unfair, unreliable, or offensive outputs in high-risk scenarios',\n",
       "    'source': 'model_risks',\n",
       "    'reasoning': 'Unfair or offensive outputs could harm student well-being and educational integrity.',\n",
       "    'subject_at_risk': 'Students'},\n",
       "   {'reference_risk': 'Reinforces demeaning or negative stereotypes',\n",
       "    'source': 'model_risks',\n",
       "    'reasoning': \"Demeaning or negative stereotypes in educational content could negatively affect students' self-perception and learning.\",\n",
       "    'subject_at_risk': 'Students'},\n",
       "   {'reference_risk': 'Produces harmful content if explicitly prompted or instructed',\n",
       "    'source': 'model_risks',\n",
       "    'reasoning': \"Harmful content in educational materials could severely affect students' mental health and educational experience.\",\n",
       "    'subject_at_risk': 'Students'},\n",
       "   {'reference_risk': 'Generates content that mirrors societal biases',\n",
       "    'source': 'model_risks',\n",
       "    'reasoning': 'Content reflecting societal biases could perpetuate inequality and affect the quality of educational experiences.',\n",
       "    'subject_at_risk': 'Students'},\n",
       "   {'reference_risk': 'Produces inappropriate or offensive content',\n",
       "    'source': 'model_risks',\n",
       "    'reasoning': 'Inappropriate or offensive content could disrupt learning environments and affect student well-being.',\n",
       "    'subject_at_risk': 'Students'},\n",
       "   {'reference_risk': 'Misinterprets or errors in response to informal English slang or other languages',\n",
       "    'source': 'model_risks',\n",
       "    'reasoning': 'Misinterpretations can lead to misunderstandings and gaps in educational content.',\n",
       "    'subject_at_risk': 'Students'},\n",
       "   {'reference_risk': 'Misuse for fraud, spam, or malware production',\n",
       "    'source': 'model_risks',\n",
       "    'reasoning': 'Misuse of the AI platform in educational environments could harm students and educational institutions.',\n",
       "    'subject_at_risk': 'Institution'},\n",
       "   {'reference_risk': 'Struggles or fails to adhere to intricate or nuanced instructions',\n",
       "    'source': 'model_risks',\n",
       "    'reasoning': 'Inability to follow nuanced instructions may reduce the quality of personalized learning plans for students.',\n",
       "    'subject_at_risk': 'Students'},\n",
       "   {'reference_risk': 'Produces problematic outputs when not aligned to human preferences for safety',\n",
       "    'source': 'model_risks',\n",
       "    'reasoning': 'Unaligned outputs might compromise the safety and educational appropriateness of content.',\n",
       "    'subject_at_risk': 'Students'},\n",
       "   {'reference_risk': 'Underperforms with packages outside common ones',\n",
       "    'source': 'model_risks',\n",
       "    'reasoning': \"If educational content relies on specific software packages that the model doesn't handle well, the learning experience could be suboptimal for students.\",\n",
       "    'subject_at_risk': 'Students'},\n",
       "   {'reference_risk': 'Violates user trust by bypassing safeguards designed to restrict certain functionalities',\n",
       "    'source': 'aiid_risks',\n",
       "    'reasoning': 'Bypassing safeguards could lead to the distribution of harmful content, thus violating trust.',\n",
       "    'subject_at_risk': 'Institution'},\n",
       "   {'reference_risk': 'Facilitates misinformation by spreading false knowledge',\n",
       "    'source': 'aiid_risks',\n",
       "    'reasoning': \"Spreading misinformation could greatly impact the educational integrity and students' learning outcomes.\",\n",
       "    'subject_at_risk': 'Students'},\n",
       "   {'reference_risk': 'Discriminates against marginalized groups by perpetuating harmful biases',\n",
       "    'source': 'aiid_risks',\n",
       "    'reasoning': 'Perpetuating harmful biases could contribute to unequal educational opportunities for marginalized students.',\n",
       "    'subject_at_risk': 'Students'},\n",
       "   {'reference_risk': 'Increases psychological harm by causing fear and anxiety through threatening statements',\n",
       "    'source': 'aiid_risks',\n",
       "    'reasoning': 'Threatening statements within educational content could result in significant psychological harm to students.',\n",
       "    'subject_at_risk': 'Students'},\n",
       "   {'reference_risk': 'Produces offensive content harming social harmony',\n",
       "    'source': 'aiid_risks',\n",
       "    'reasoning': 'Offensive content within educational resources might disrupt social harmony and a positive learning environment.',\n",
       "    'subject_at_risk': 'Students'},\n",
       "   {'reference_risk': 'Promotes stereotypes by invoking Jewish stereotypes',\n",
       "    'source': 'aiid_risks',\n",
       "    'reasoning': 'Promoting stereotypes, particularly cultural or religious ones, could harm inclusivity and respect within educational platforms.',\n",
       "    'subject_at_risk': 'Students'},\n",
       "   {'reference_risk': 'Exposes sensitive data due to misconfigured access tokens',\n",
       "    'source': 'aiid_risks',\n",
       "    'reasoning': 'Exposure of sensitive educational data could breach privacy and trust within the institution.',\n",
       "    'subject_at_risk': 'Institution'}]},\n",
       " {'cardID': '82',\n",
       "  'use': 'Domain-- Social Media, Purpose-- Moderating harmful content, Capability-- Detecting inappropriate posts',\n",
       "  'risks': [{'reference_risk': 'Produces unfair unreliable or offensive outputs in highrisk scenarios',\n",
       "    'source': 'model_risks',\n",
       "    'reasoning': 'The model may produce unreliable or offensive outputs, which is a critical concern for moderating harmful content on social media.',\n",
       "    'subject_at_risk': 'ai_subject'},\n",
       "   {'reference_risk': 'Reinforces demeaning or negative stereotypes',\n",
       "    'source': 'model_risks',\n",
       "    'reasoning': 'The model might reinforce negative stereotypes, impacting moderation of harmful content aimed at social media users.',\n",
       "    'subject_at_risk': 'ai_subject'},\n",
       "   {'reference_risk': 'Produces harmful content if explicitly prompted or instructed',\n",
       "    'source': 'model_risks',\n",
       "    'reasoning': 'There is a risk of the model generating harmful content if instructed, which is counterproductive to its use in harmful content moderation on social media.',\n",
       "    'subject_at_risk': 'ai_subject'},\n",
       "   {'reference_risk': 'Generates content that mirrors societal biases',\n",
       "    'source': 'model_risks',\n",
       "    'reasoning': 'The risk of societal biases showing up in generated content is relevant in social media contexts where such biases can harm users.',\n",
       "    'subject_at_risk': 'ai_subject'},\n",
       "   {'reference_risk': 'Produces inappropriate or offensive content',\n",
       "    'source': 'model_risks',\n",
       "    'reasoning': 'The generation of inappropriate or offensive content directly affects users on social media platforms.',\n",
       "    'subject_at_risk': 'ai_subject'},\n",
       "   {'reference_risk': 'Overrepresents or underrepresents groups of people',\n",
       "    'source': 'model_risks',\n",
       "    'reasoning': 'Overrepresentation or underrepresentation of groups could lead to moderation bias in social media content management.',\n",
       "    'subject_at_risk': 'ai_subject'},\n",
       "   {'reference_risk': 'Misinterprets or errors in response to informal English slang or other languages',\n",
       "    'source': 'model_risks',\n",
       "    'reasoning': 'Misinterpretation of slang or other languages can lead to inaccurate or unfair moderation decisions on social media.',\n",
       "    'subject_at_risk': 'ai_subject'},\n",
       "   {'reference_risk': 'Enables fraud spam or malware production',\n",
       "    'source': 'model_risks',\n",
       "    'reasoning': \"The model's potential misuse for fraud, spam, or malware can pose significant risks to social media platforms and their users.\",\n",
       "    'subject_at_risk': 'ai_user'},\n",
       "   {'reference_risk': 'Promotes stereotypes by invoking Jewish stereotypes',\n",
       "    'source': 'aiid_risks',\n",
       "    'reasoning': 'The model could promote negative stereotypes, which is a concern in content moderation to avoid discriminatory content.',\n",
       "    'subject_at_risk': 'ai_subject'},\n",
       "   {'reference_risk': 'Violates privacy by exposing internal messages',\n",
       "    'source': 'aiid_risks',\n",
       "    'reasoning': 'Exposing internal messages would violate privacy and could harm social media platform users.',\n",
       "    'subject_at_risk': 'ai_subject'},\n",
       "   {'reference_risk': 'Produces offensive content harming reputations',\n",
       "    'source': 'aiid_risks',\n",
       "    'reasoning': 'Generates harmful or offensive content can damage reputations on social media platforms.',\n",
       "    'subject_at_risk': 'ai_subject'},\n",
       "   {'reference_risk': 'Facilitates misinformation spreading false knowledge',\n",
       "    'source': 'aiid_risks',\n",
       "    'reasoning': 'The spread of misinformation is highly detrimental on social media, as it can mislead users.',\n",
       "    'subject_at_risk': 'ai_subject'},\n",
       "   {'reference_risk': 'Discriminates against specific groups of people due to biased responses',\n",
       "    'source': 'aiid_risks',\n",
       "    'reasoning': 'Discriminatory responses are problematic in moderating social media content, as they can alienate marginalized groups.',\n",
       "    'subject_at_risk': 'ai_subject'}]},\n",
       " {'cardID': '93',\n",
       "  'use': 'Domain-- Recommender Systems and Personalization, Purpose-- Recommending personalized content, Capability-- Analyzing preferences for suggestions',\n",
       "  'risks': [{'reference_risk': 'Generates nondeterministic responses due to model size',\n",
       "    'source': 'model_risks',\n",
       "    'reasoning': 'Recommending personalized content could be affected by the model generating unpredictable responses.',\n",
       "    'subject_at_risk': 'ai_user'},\n",
       "   {'reference_risk': \"Acts as 'black boxes' making it difficult to comprehend rationale behind outputs\",\n",
       "    'source': 'model_risks',\n",
       "    'reasoning': 'Users may not understand why certain content is recommended, leading to confusion and mistrust.',\n",
       "    'subject_at_risk': 'ai_user'},\n",
       "   {'reference_risk': 'Exhibits unreliable unsafe or other undesirable behaviors',\n",
       "    'source': 'model_risks',\n",
       "    'reasoning': 'Unreliable behavior in content recommendations could negatively affect user experience.',\n",
       "    'subject_at_risk': 'ai_user'},\n",
       "   {'reference_risk': 'Generates outputs that could be biased or unfair',\n",
       "    'source': 'model_risks',\n",
       "    'reasoning': 'Content consumers may receive biased or unfair content recommendations, impacting their user experience.',\n",
       "    'subject_at_risk': 'ai_subject'},\n",
       "   {'reference_risk': 'Underperforms in non-English languages',\n",
       "    'source': 'model_risks',\n",
       "    'reasoning': 'Non-English content consumers may receive poor-quality recommendations due to language limitations.',\n",
       "    'subject_at_risk': 'ai_subject'},\n",
       "   {'reference_risk': 'Limits accuracy in areas underrepresented in the training dataset',\n",
       "    'source': 'model_risks',\n",
       "    'reasoning': 'Content recommendations may be less accurate for users interested in niche or underrepresented topics.',\n",
       "    'subject_at_risk': 'ai_user'},\n",
       "   {'reference_risk': 'Carries biases present in the source data',\n",
       "    'source': 'model_risks',\n",
       "    'reasoning': 'Content recommendations may reflect the biases present in the data used to train the model.',\n",
       "    'subject_at_risk': 'ai_subject'},\n",
       "   {'reference_risk': 'Exhibits limited real-world understanding',\n",
       "    'source': 'model_risks',\n",
       "    'reasoning': 'Recommendations may not always align with real-world user preferences or contexts.',\n",
       "    'subject_at_risk': 'ai_user'},\n",
       "   {'reference_risk': 'Reflects offensive or inappropriate content in model-generated text',\n",
       "    'source': 'model_risks',\n",
       "    'reasoning': 'Recommender system might suggest offensive or inappropriate content to users.',\n",
       "    'subject_at_risk': 'ai_subject'},\n",
       "   {'reference_risk': 'Fabricates content making it unreliable for critical decisions',\n",
       "    'source': 'model_risks',\n",
       "    'reasoning': 'Content consumers could be misled by fabricated content, affecting their trust and decisions.',\n",
       "    'subject_at_risk': 'ai_subject'},\n",
       "   {'reference_risk': 'Used maliciously for generating disinformation or harmful content',\n",
       "    'source': 'model_risks',\n",
       "    'reasoning': 'Recommender system could be exploited to spread disinformation or harmful content.',\n",
       "    'subject_at_risk': 'ai_user'},\n",
       "   {'reference_risk': 'Produces objectionable responses',\n",
       "    'source': 'model_risks',\n",
       "    'reasoning': 'Content recommendations may include objectionable material, impacting user experience and satisfaction.',\n",
       "    'subject_at_risk': 'ai_subject'},\n",
       "   {'reference_risk': 'Produces inaccurate responses',\n",
       "    'source': 'model_risks',\n",
       "    'reasoning': 'Inaccurate content recommendations could negatively affect user trust and engagement.',\n",
       "    'subject_at_risk': 'ai_user'},\n",
       "   {'reference_risk': 'Offends users by making offensive remarks',\n",
       "    'source': 'aiid_risks',\n",
       "    'reasoning': 'Content consumers might encounter offensive recommendations, leading to discomfort or dissatisfaction.',\n",
       "    'subject_at_risk': 'ai_subject'},\n",
       "   {'reference_risk': 'Undermines trust in AI systems by mishandling sensitive personal data',\n",
       "    'source': 'aiid_risks',\n",
       "    'reasoning': \"Mishandling user data can reduce trust in the recommender system and the platform's overall reliability.\",\n",
       "    'subject_at_risk': 'ai_user'},\n",
       "   {'reference_risk': 'Increases psychological harm by exposing users to graphic and explicit content',\n",
       "    'source': 'aiid_risks',\n",
       "    'reasoning': 'Users might be negatively affected if the system recommends inappropriate content.',\n",
       "    'subject_at_risk': 'ai_subject'}]},\n",
       " {'cardID': '93',\n",
       "  'use': 'Domain-- Marketing and Advertising, Purpose-- Creating personalized ad campaigns, Capability-- Analyzing user behavior from social media posts',\n",
       "  'risks': [{'reference_risk': 'Generates nondeterministic responses due to model size',\n",
       "    'source': 'model_risks',\n",
       "    'reasoning': 'Model can generate different outputs for the same input which may lead to inconsistent marketing messages.',\n",
       "    'subject_at_risk': 'Marketing agencies'},\n",
       "   {'reference_risk': 'Acts as â€œblack boxesâ€ making it difficult to comprehend rationale behind outputs',\n",
       "    'source': 'model_risks',\n",
       "    'reasoning': \"Lack of transparency in model's decision-making process can lead to difficulty in understanding why certain marketing messages are created.\",\n",
       "    'subject_at_risk': 'Marketing agencies'},\n",
       "   {'reference_risk': 'Exhibits unreliable unsafe or other undesirable behaviors',\n",
       "    'source': 'model_risks',\n",
       "    'reasoning': 'Model might produce inappropriate or harmful marketing content which could damage brand reputation.',\n",
       "    'subject_at_risk': 'Marketing agencies'},\n",
       "   {'reference_risk': 'Generates outputs that could be biased or unfair',\n",
       "    'source': 'model_risks',\n",
       "    'reasoning': 'Marketing messages could reflect biases present in the training data, potentially misleading or offending consumers.',\n",
       "    'subject_at_risk': 'Consumers'},\n",
       "   {'reference_risk': 'Limits accuracy in areas underrepresented in the training dataset',\n",
       "    'source': 'model_risks',\n",
       "    'reasoning': 'Underrepresentation of certain demographics in the training data could lead to ineffective or misinformed marketing strategies.',\n",
       "    'subject_at_risk': 'Marketing agencies'},\n",
       "   {'reference_risk': 'Carries biases present in the source data',\n",
       "    'source': 'model_risks',\n",
       "    'reasoning': 'Biases from training data could skew marketing strategies and lead to unfair targeting of consumer segments.',\n",
       "    'subject_at_risk': 'Consumers'},\n",
       "   {'reference_risk': 'Fails to cover all scenarios',\n",
       "    'source': 'model_risks',\n",
       "    'reasoning': 'Model limitations might lead to gaps in marketing strategy, failing to address all possible consumer behaviors.',\n",
       "    'subject_at_risk': 'Marketing agencies'},\n",
       "   {'reference_risk': 'Arises potential issues in generated responses',\n",
       "    'source': 'model_risks',\n",
       "    'reasoning': 'Potential for generating irrelevant or inappropriate marketing messages affecting campaign performance.',\n",
       "    'subject_at_risk': 'Marketing agencies'},\n",
       "   {'reference_risk': 'Reflects offensive or inappropriate content in modelgenerated text',\n",
       "    'source': 'model_risks',\n",
       "    'reasoning': 'Possibility that the model generates offensive content which can harm brand image.',\n",
       "    'subject_at_risk': 'Consumers'},\n",
       "   {'reference_risk': 'Fabricates content making it unreliable for critical decisions',\n",
       "    'source': 'model_risks',\n",
       "    'reasoning': 'Fabricated information can lead to misinformed marketing decisions and strategies.',\n",
       "    'subject_at_risk': 'Marketing agencies'},\n",
       "   {'reference_risk': 'Produces inaccurate or nonsensical responses',\n",
       "    'source': 'model_risks',\n",
       "    'reasoning': 'Marketing content might be based on inaccurate data leading to ineffective campaigns.',\n",
       "    'subject_at_risk': 'Marketing agencies'},\n",
       "   {'reference_risk': 'Retains biases and toxicity despite finetuning',\n",
       "    'source': 'model_risks',\n",
       "    'reasoning': 'Despite fine-tuning, biases can still persist affecting the fairness and inclusivity of marketing messages.',\n",
       "    'subject_at_risk': 'Consumers'},\n",
       "   {'reference_risk': 'Infringes data protection laws by using sensitive data without proper authorization',\n",
       "    'source': 'aiid_risks',\n",
       "    'reasoning': 'Using sensitive user data from social media without proper consent can lead to legal issues.',\n",
       "    'subject_at_risk': 'Marketing agencies'},\n",
       "   {'reference_risk': 'Facilitates misinformation spreading false knowledge',\n",
       "    'source': 'aiid_risks',\n",
       "    'reasoning': 'Potential to generate false or misleading marketing content which can misinform consumers.',\n",
       "    'subject_at_risk': 'Consumers'},\n",
       "   {'reference_risk': 'Offends users by making offensive remarks',\n",
       "    'source': 'aiid_risks',\n",
       "    'reasoning': 'Generated marketing content might contain offensive language, harming the consumer experience.',\n",
       "    'subject_at_risk': 'Consumers'}]},\n",
       " {'cardID': '93',\n",
       "  'use': 'Domain-- Education and vocational training, Purpose-- Personalizing learning experiences, Capability-- Analyzing student performance and tailoring content',\n",
       "  'risks': [{'reference_risk': 'Generates nondeterministic responses due to model size',\n",
       "    'source': 'model_risks',\n",
       "    'reasoning': 'Nondeterministic responses could affect the consistency of personalized learning experiences.',\n",
       "    'subject_at_risk': 'ai_subject'},\n",
       "   {'reference_risk': 'Acts as â€œblack boxesâ€ making it difficult to comprehend rationale behind outputs',\n",
       "    'source': 'model_risks',\n",
       "    'reasoning': 'Lack of transparency in model outputs may reduce trust among educational platforms and institutions.',\n",
       "    'subject_at_risk': 'ai_user'},\n",
       "   {'reference_risk': 'Exhibits unreliable unsafe or other undesirable behaviors',\n",
       "    'source': 'model_risks',\n",
       "    'reasoning': 'Undesirable behaviors from the model could negatively impact the learning experience for students.',\n",
       "    'subject_at_risk': 'ai_subject'},\n",
       "   {'reference_risk': 'Generates outputs that could be biased or unfair',\n",
       "    'source': 'model_risks',\n",
       "    'reasoning': 'Biased or unfair outputs may affect the quality and fairness of personalized learning content.',\n",
       "    'subject_at_risk': 'ai_subject'},\n",
       "   {'reference_risk': 'Limits accuracy in areas underrepresented in the training dataset',\n",
       "    'source': 'model_risks',\n",
       "    'reasoning': 'Inaccurate analysis and tailoring due to underrepresented data could misinform educational decisions.',\n",
       "    'subject_at_risk': 'ai_subject'},\n",
       "   {'reference_risk': 'Fails to cover all scenarios',\n",
       "    'source': 'model_risks',\n",
       "    'reasoning': 'Inability to handle diverse learning scenarios may reduce the effectiveness of personalized content.',\n",
       "    'subject_at_risk': 'ai_subject'},\n",
       "   {'reference_risk': 'Reflects offensive or inappropriate content in modelgenerated text',\n",
       "    'source': 'model_risks',\n",
       "    'reasoning': 'Offensive content could harm students and damage the reputation of educational platforms.',\n",
       "    'subject_at_risk': 'ai_subject'},\n",
       "   {'reference_risk': 'Fabricates content making it unreliable for critical decisions',\n",
       "    'source': 'model_risks',\n",
       "    'reasoning': 'Fabricated content could misguide students and educators, leading to poor educational outcomes.',\n",
       "    'subject_at_risk': 'ai_subject'},\n",
       "   {'reference_risk': 'Generates disinformation by creating misleading or false images',\n",
       "    'source': 'aiid_risks',\n",
       "    'reasoning': \"Misleading or false information could undermine the educational content's credibility and accuracy.\",\n",
       "    'subject_at_risk': 'ai_subject'},\n",
       "   {'reference_risk': 'Harms economic interests of content creators by using their work without compensation',\n",
       "    'source': 'aiid_risks',\n",
       "    'reasoning': \"Uncompensated use of creators' work could lead to financial and reputational harm for content creators.\",\n",
       "    'subject_at_risk': 'institution'}]},\n",
       " {'cardID': '93',\n",
       "  'use': 'Domain-- Health and Healthcare, Purpose-- Assisting in medical diagnoses, Capability-- Analyzing patient data and suggesting conditions',\n",
       "  'risks': [{'reference_risk': 'Generates nondeterministic responses due to model size',\n",
       "    'source': 'model_risks',\n",
       "    'reasoning': \"The model's non-deterministic responses could lead to unreliable diagnosis suggestions.\",\n",
       "    'subject_at_risk': 'Patients'},\n",
       "   {'reference_risk': 'Acts as â€œblack boxesâ€ making it difficult to comprehend rationale behind outputs',\n",
       "    'source': 'model_risks',\n",
       "    'reasoning': \"The lack of transparency in the model's decision-making process can hinder healthcare professionals in validating diagnoses or therapeutic suggestions.\",\n",
       "    'subject_at_risk': 'Healthcare professionals'},\n",
       "   {'reference_risk': 'Exhibits unreliable unsafe or other undesirable behaviors',\n",
       "    'source': 'model_risks',\n",
       "    'reasoning': 'Unreliable or unsafe behaviors can directly lead to incorrect diagnoses or treatment suggestions.',\n",
       "    'subject_at_risk': 'Patients'},\n",
       "   {'reference_risk': 'Generates outputs that could be biased or unfair',\n",
       "    'source': 'model_risks',\n",
       "    'reasoning': \"Biases in the model's outputs could result in unequal treatment recommendations for different patient demographics.\",\n",
       "    'subject_at_risk': 'Patients'},\n",
       "   {'reference_risk': 'Limits accuracy in areas underrepresented in the training dataset',\n",
       "    'source': 'model_risks',\n",
       "    'reasoning': 'Patients from underrepresented groups might receive less accurate diagnoses or medical advice.',\n",
       "    'subject_at_risk': 'Patients'},\n",
       "   {'reference_risk': 'Carries biases present in the source data',\n",
       "    'source': 'model_risks',\n",
       "    'reasoning': \"Biases in the source data could affect the fairness and accuracy of the model's medical recommendations.\",\n",
       "    'subject_at_risk': 'Patients'},\n",
       "   {'reference_risk': 'Arises potential issues in generated responses',\n",
       "    'source': 'model_risks',\n",
       "    'reasoning': 'Generated responses could potentially include incorrect or misleading medical information.',\n",
       "    'subject_at_risk': 'Patients'},\n",
       "   {'reference_risk': 'Results in potential inaccuracies or nonsensical responses',\n",
       "    'source': 'model_risks',\n",
       "    'reasoning': 'Inaccurate or nonsensical responses could lead to incorrect diagnoses or inappropriate treatment plans.',\n",
       "    'subject_at_risk': 'Patients'},\n",
       "   {'reference_risk': 'Exhibits limited real-world understanding',\n",
       "    'source': 'model_risks',\n",
       "    'reasoning': 'Limited real-world medical understanding could hamper the effectiveness of the model in clinical applications.',\n",
       "    'subject_at_risk': 'Patients'},\n",
       "   {'reference_risk': 'Small models may be more susceptible to hallucination',\n",
       "    'source': 'model_risks',\n",
       "    'reasoning': 'Hallucinations in generated medical content could result in harmful medical decisions.',\n",
       "    'subject_at_risk': 'Patients'},\n",
       "   {'reference_risk': 'Produces inaccurate responses',\n",
       "    'source': 'model_risks',\n",
       "    'reasoning': 'Inaccurate responses can misinform healthcare professionals and harm patient care.',\n",
       "    'subject_at_risk': 'Patients'},\n",
       "   {'reference_risk': 'Increases risk of identity theft by exposing personal medical information',\n",
       "    'source': 'aiid_risks',\n",
       "    'reasoning': 'Exposure of personal medical data increases identity theft risks.',\n",
       "    'subject_at_risk': 'Patients'},\n",
       "   {'reference_risk': \"Harms individuals' reputations by potentially revealing private medical information\",\n",
       "    'source': 'aiid_risks',\n",
       "    'reasoning': 'Revealing private medical information can damage patient reputations.',\n",
       "    'subject_at_risk': 'Patients'},\n",
       "   {'reference_risk': 'Violates privacy by exposing private medical records without consent',\n",
       "    'source': 'aiid_risks',\n",
       "    'reasoning': 'Unconsented exposure of medical records violates privacy laws and ethical guidelines.',\n",
       "    'subject_at_risk': 'Patients'}]},\n",
       " {'cardID': '231',\n",
       "  'use': 'Domain-- Social Media, Purpose-- Generating engaging social media content, Capability-- Creating videos from trending topics',\n",
       "  'risks': [{'reference_risk': 'Generates demeaning dehumanizing or otherwise harmful representations of people or their environments cultures religions',\n",
       "    'source': 'model_risks',\n",
       "    'reasoning': \"The model's output might generate harmful and offensive content when applied to social media, impacting social media users.\",\n",
       "    'subject_at_risk': 'social media users'},\n",
       "   {'reference_risk': 'Generates nonfactual or untrue representations of people or events',\n",
       "    'source': 'model_risks',\n",
       "    'reasoning': 'Creating videos from trending topics may lead to the generation of misinformation or misrepresentation.',\n",
       "    'subject_at_risk': 'social media users'},\n",
       "   {'reference_risk': 'Creates offensive degrading or damaging portrayals of individuals their cultures religions or surroundings',\n",
       "    'source': 'model_risks',\n",
       "    'reasoning': 'The output could harm individuals by presenting offensive or degrading images, especially in a diverse social media context.',\n",
       "    'subject_at_risk': 'social media users'},\n",
       "   {'reference_risk': 'Generates mis and disinformation',\n",
       "    'source': 'model_risks',\n",
       "    'reasoning': \"There's a risk of spreading false or misleading information through generated videos on social media.\",\n",
       "    'subject_at_risk': 'social media users'},\n",
       "   {'reference_risk': 'Violates copyright law by unauthorized use of protected content',\n",
       "    'source': 'aiid_risks',\n",
       "    'reasoning': 'Generated content might inadvertently use copyrighted material without permission.',\n",
       "    'subject_at_risk': 'content creators'},\n",
       "   {'reference_risk': 'Damages reputations by spreading inaccurate data',\n",
       "    'source': 'aiid_risks',\n",
       "    'reasoning': 'Inaccurate or misleading videos could damage the reputations of individuals or organizations featured in such content.',\n",
       "    'subject_at_risk': 'social media users'},\n",
       "   {'reference_risk': 'Facilitates illegal activities by distributing explicit deepfakes',\n",
       "    'source': 'aiid_risks',\n",
       "    'reasoning': 'The model might be misused to create and distribute explicit deepfakes, violating legal standards.',\n",
       "    'subject_at_risk': 'social media users'},\n",
       "   {'reference_risk': 'Violates privacy of individuals by creating unauthorized deepfakes',\n",
       "    'source': 'aiid_risks',\n",
       "    'reasoning': \"Deepfakes created without consent could infringe upon individuals' privacy.\",\n",
       "    'subject_at_risk': 'social media users'},\n",
       "   {'reference_risk': 'Misleads users with false information reducing trust in AI systems',\n",
       "    'source': 'aiid_risks',\n",
       "    'reasoning': 'Misinformation through generated content can erode trust in AI among social media users.',\n",
       "    'subject_at_risk': 'social media users'},\n",
       "   {'reference_risk': 'Undermines trust in legitimate news sources by spreading propaganda',\n",
       "    'source': 'aiid_risks',\n",
       "    'reasoning': 'Generated videos propagating false information can undermine trust in genuine news sources.',\n",
       "    'subject_at_risk': 'social media users'},\n",
       "   {'reference_risk': 'Generates offensive content harming reputations',\n",
       "    'source': 'aiid_risks',\n",
       "    'reasoning': 'Offensive generated content can harm the reputations of individuals or groups featured in the videos.',\n",
       "    'subject_at_risk': 'social media users'},\n",
       "   {'reference_risk': 'Undermines public trust in AI by allowing misuse of opensource models for unethical purposes',\n",
       "    'source': 'aiid_risks',\n",
       "    'reasoning': 'The misuse of the model for unethical means can seriously harm public trust in AI technologies.',\n",
       "    'subject_at_risk': 'institution'}]},\n",
       " {'cardID': '231',\n",
       "  'use': 'Domain-- Marketing and Advertising, Purpose-- Creating engaging promotional videos, Capability-- Generating videos from marketing text',\n",
       "  'risks': [{'reference_risk': 'Cannot render legible text',\n",
       "    'source': 'model_risks',\n",
       "    'reasoning': 'In marketing and advertising, the legibility of text is crucial for conveying messages clearly.',\n",
       "    'subject_at_risk': 'ai_user'},\n",
       "   {'reference_risk': 'Generates nonfactual or untrue representations of people or events',\n",
       "    'source': 'model_risks',\n",
       "    'reasoning': 'Marketing videos need to be factually accurate to maintain trust and avoid misinformation.',\n",
       "    'subject_at_risk': 'ai_subject'},\n",
       "   {'reference_risk': 'Generates demeaning dehumanizing or otherwise harmful representations of people or their environments cultures religions',\n",
       "    'source': 'model_risks',\n",
       "    'reasoning': 'Marketing videos should respect and accurately represent diverse cultures to avoid alienating potential customers.',\n",
       "    'subject_at_risk': 'ai_subject'},\n",
       "   {'reference_risk': 'Contains adult material in the training dataset',\n",
       "    'source': 'model_risks',\n",
       "    'reasoning': 'Exposure to adult material is inappropriate and harmful in marketing content aimed at general audiences, including children.',\n",
       "    'subject_at_risk': 'ai_subject'},\n",
       "   {'reference_risk': 'Shares modified versions of copyrighted or licensed content in breach of its usage guidelines',\n",
       "    'source': 'model_risks',\n",
       "    'reasoning': 'Using copyrighted content without permission can lead to legal issues and damage the reputation of marketing agencies.',\n",
       "    'subject_at_risk': 'institution'},\n",
       "   {'reference_risk': 'Underrepresents communities and cultures using nonEnglish languages',\n",
       "    'source': 'model_risks',\n",
       "    'reasoning': 'Excluding non-English speaking communities may limit the reach and inclusivity of marketing campaigns.',\n",
       "    'subject_at_risk': 'ai_subject'},\n",
       "   {'reference_risk': 'Promotes or propagates discriminatory content or harmful stereotypes',\n",
       "    'source': 'model_risks',\n",
       "    'reasoning': 'Marketing content should be inclusive and should not propagate harmful stereotypes which can alienate potential customers.',\n",
       "    'subject_at_risk': 'ai_subject'},\n",
       "   {'reference_risk': 'Facilitates misinformation spreading false knowledge',\n",
       "    'source': 'aiid_risks',\n",
       "    'reasoning': 'Accurate information in marketing materials is crucial to maintain consumer trust.',\n",
       "    'subject_at_risk': 'ai_subject'},\n",
       "   {'reference_risk': 'Violates privacy of individuals by creating unauthorized deepfakes',\n",
       "    'source': 'aiid_risks',\n",
       "    'reasoning': 'Unauthorized deepfakes can harm individualsâ€™ reputations and privacy.',\n",
       "    'subject_at_risk': 'ai_subject'},\n",
       "   {'reference_risk': 'Facilitates illegal activities by distributing explicit deepfakes',\n",
       "    'source': 'aiid_risks',\n",
       "    'reasoning': 'Explicit deepfakes can be illegal and highly damaging, risking severe legal consequences for marketing agencies.',\n",
       "    'subject_at_risk': 'institution'},\n",
       "   {'reference_risk': 'Infringes intellectual property rights by misusing image generation technology',\n",
       "    'source': 'aiid_risks',\n",
       "    'reasoning': 'Infringing on intellectual property rights can lead to legal disputes and financial losses.',\n",
       "    'subject_at_risk': 'institution'},\n",
       "   {'reference_risk': 'Harms artists economic interests by unauthorized use of their work',\n",
       "    'source': 'aiid_risks',\n",
       "    'reasoning': \"Using an artist's work without authorization can damage their economic interests and lead to legal repercussions.\",\n",
       "    'subject_at_risk': 'ai_subject'}]},\n",
       " {'cardID': '231',\n",
       "  'use': 'Domain-- Education and vocational training, Purpose-- Creating educational content, Capability-- Generating instructional videos from text',\n",
       "  'risks': [{'reference_risk': 'Cannot render legible text',\n",
       "    'source': 'model_risks',\n",
       "    'reasoning': 'The model may fail to produce clear instructional content if the text is not legible.',\n",
       "    'subject_at_risk': 'Students'},\n",
       "   {'reference_risk': 'Underperforms with non-English prompts',\n",
       "    'source': 'model_risks',\n",
       "    'reasoning': 'Limited to English input could reduce effectiveness in a multilingual educational setting.',\n",
       "    'subject_at_risk': 'Students'},\n",
       "   {'reference_risk': 'Generates nonfactual or untrue representations of people or events',\n",
       "    'source': 'model_risks',\n",
       "    'reasoning': 'Educational content must be accurate and truthful; otherwise, it misleads students.',\n",
       "    'subject_at_risk': 'Students'},\n",
       "   {'reference_risk': 'Creates hostile or alienating environments for people',\n",
       "    'source': 'model_risks',\n",
       "    'reasoning': 'Inappropriate representations may make certain groups feel excluded or targeted.',\n",
       "    'subject_at_risk': 'Students'},\n",
       "   {'reference_risk': 'Propagates historical or current stereotypes',\n",
       "    'source': 'model_risks',\n",
       "    'reasoning': 'Educational content needs to be unbiased and inclusive.',\n",
       "    'subject_at_risk': 'Students'},\n",
       "   {'reference_risk': 'Fails to produce accurate or truthful depictions of people or events',\n",
       "    'source': 'model_risks',\n",
       "    'reasoning': 'Inaccurate video content can misinform students.',\n",
       "    'subject_at_risk': 'Students'},\n",
       "   {'reference_risk': 'Reinforces or exacerbates social biases',\n",
       "    'source': 'model_risks',\n",
       "    'reasoning': 'Educational content should not perpetuate societal biases.',\n",
       "    'subject_at_risk': 'Students'},\n",
       "   {'reference_risk': 'Underrepresents communities and cultures using non-English languages',\n",
       "    'source': 'model_risks',\n",
       "    'reasoning': 'Educational content should be inclusive of different cultures and languages.',\n",
       "    'subject_at_risk': 'Students'},\n",
       "   {'reference_risk': 'Fails to generate faces and people properly',\n",
       "    'source': 'model_risks',\n",
       "    'reasoning': 'Accurate rendering of human figures is important for instructional videos.',\n",
       "    'subject_at_risk': 'Students'},\n",
       "   {'reference_risk': 'Biases towards painting images over realistic images',\n",
       "    'source': 'model_risks',\n",
       "    'reasoning': 'Educational content should be realistic to be effective.',\n",
       "    'subject_at_risk': 'Students'},\n",
       "   {'reference_risk': 'Underperforms with non-English captions',\n",
       "    'source': 'model_risks',\n",
       "    'reasoning': 'Limitations in multilingual support can hinder educational goals in diverse settings.',\n",
       "    'subject_at_risk': 'Students'},\n",
       "   {'reference_risk': 'Amplifies societal biases',\n",
       "    'source': 'model_risks',\n",
       "    'reasoning': 'Educational content should aim to reduce societal biases, not amplify them.',\n",
       "    'subject_at_risk': 'Students'},\n",
       "   {'reference_risk': 'Produces explicit content that can be harmful or inappropriate',\n",
       "    'source': 'aiid_risks',\n",
       "    'reasoning': 'Educational content should be age-appropriate and safe for students.',\n",
       "    'subject_at_risk': 'Students'},\n",
       "   {'reference_risk': 'Violates privacy by exposing private medical records without consent',\n",
       "    'source': 'aiid_risks',\n",
       "    'reasoning': 'Educational content must respect privacy and data protection laws.',\n",
       "    'subject_at_risk': 'Institution'},\n",
       "   {'reference_risk': 'Generates offensive content harming reputations',\n",
       "    'source': 'aiid_risks',\n",
       "    'reasoning': \"Educational content should be respectful and not harm anyone's reputation.\",\n",
       "    'subject_at_risk': 'Students'}]},\n",
       " {'cardID': '231',\n",
       "  'use': 'Domain-- Well-being, Purpose-- Creating guided meditation videos, Capability-- Generating calming visuals from text',\n",
       "  'risks': [{'reference_risk': 'Cannot render legible text',\n",
       "    'source': 'model_risks',\n",
       "    'reasoning': 'The model underperforms in text rendering which could be crucial for creating effective guided meditation videos that may require subtitles or overlay text.',\n",
       "    'subject_at_risk': 'ai_subject'},\n",
       "   {'reference_risk': 'Biases towards white and western norms',\n",
       "    'source': 'model_risks',\n",
       "    'reasoning': \"The model's bias might result in culturally insensitive or non-inclusive meditation visuals, affecting user experience.\",\n",
       "    'subject_at_risk': 'ai_subject'},\n",
       "   {'reference_risk': 'Underperforms with non-English prompts',\n",
       "    'source': 'model_risks',\n",
       "    'reasoning': 'Given the global audience for wellness and relaxation, underperforming with non-English prompts could limit accessibility.',\n",
       "    'subject_at_risk': 'ai_subject'},\n",
       "   {'reference_risk': 'Fails to achieve perfect photorealism',\n",
       "    'source': 'model_risks',\n",
       "    'reasoning': 'Imperfect visuals could detract from the calming and immersive experience intended for relaxation and meditation.',\n",
       "    'subject_at_risk': 'ai_subject'},\n",
       "   {'reference_risk': 'Generates nonfactual or untrue representations of people or events',\n",
       "    'source': 'model_risks',\n",
       "    'reasoning': 'Nonfactual representations could mislead users and affect the authenticity and trust in the guided meditation content.',\n",
       "    'subject_at_risk': 'ai_subject'},\n",
       "   {'reference_risk': 'Generate content that is cruel to individuals',\n",
       "    'source': 'model_risks',\n",
       "    'reasoning': 'Cruel content could inadvertently cause psychological harm rather than aid in relaxation.',\n",
       "    'subject_at_risk': 'ai_subject'},\n",
       "   {'reference_risk': 'Produces less accurate outputs from non-English prompts',\n",
       "    'source': 'model_risks',\n",
       "    'reasoning': 'Inaccurate outputs for non-English prompts can limit the inclusivity and effectiveness of the meditation content.',\n",
       "    'subject_at_risk': 'ai_subject'},\n",
       "   {'reference_risk': 'Generates visuals that might be predictably upsetting, distressing or inappropriate',\n",
       "    'source': 'model_risks',\n",
       "    'reasoning': 'Upsetting or distressing visuals would be counterproductive for a tool intended to promote well-being and relaxation.',\n",
       "    'subject_at_risk': 'ai_subject'},\n",
       "   {'reference_risk': 'Displays emerging flashing lights due to training on dance videos',\n",
       "    'source': 'model_risks',\n",
       "    'reasoning': 'Flashing lights could be harmful, especially to individuals prone to epilepsy or susceptible to visual triggers.',\n",
       "    'subject_at_risk': 'ai_subject'},\n",
       "   {'reference_risk': 'Sets white and western cultures as the default',\n",
       "    'source': 'model_risks',\n",
       "    'reasoning': 'Setting a default to white and western norms could alienate users from diverse cultural backgrounds.',\n",
       "    'subject_at_risk': 'ai_subject'}]},\n",
       " {'cardID': '1490',\n",
       "  'use': 'Domain-- Social Media, Purpose-- Creating engaging social media posts, Capability-- Generating GIFs from user content',\n",
       "  'risks': [{'reference_risk': 'Contains adult material in training data',\n",
       "    'source': 'model_risks',\n",
       "    'reasoning': 'This can result in the unintentional generation of inappropriate or explicit content, which is unsuitable for general social media use.',\n",
       "    'subject_at_risk': 'ai_subject'},\n",
       "   {'reference_risk': 'Underperforms with non-English prompts',\n",
       "    'source': 'model_risks',\n",
       "    'reasoning': 'The prevalence of non-English users on social media could lead to an exclusionary user experience for these individuals.',\n",
       "    'subject_at_risk': 'ai_user'},\n",
       "   {'reference_risk': 'Generates demeaning, dehumanizing, or harmful representations of people or their environments, cultures, religions',\n",
       "    'source': 'model_risks',\n",
       "    'reasoning': 'Such content can be harmful to both influencers and followers, as well as damaging to diverse cultural representations on social media.',\n",
       "    'subject_at_risk': 'ai_subject'},\n",
       "   {'reference_risk': 'Generates non-factual or untrue representations of people or events',\n",
       "    'source': 'model_risks',\n",
       "    'reasoning': 'This can propagate misinformation, leading to potential harm to the reputation of influencers and misleading followers.',\n",
       "    'subject_at_risk': 'ai_subject'},\n",
       "   {'reference_risk': 'Spreads misinformation and disinformation',\n",
       "    'source': 'model_risks',\n",
       "    'reasoning': 'The model might generate misleading GIFs, affecting public perception and the credibility of social media influencers.',\n",
       "    'subject_at_risk': 'ai_subject'},\n",
       "   {'reference_risk': 'Creates hostile or alienating environments for people',\n",
       "    'source': 'model_risks',\n",
       "    'reasoning': 'Offensive or harmful content could make social media platforms less welcoming.',\n",
       "    'subject_at_risk': 'ai_subject'},\n",
       "   {'reference_risk': 'Generates representations of egregious violence and gore',\n",
       "    'source': 'model_risks',\n",
       "    'reasoning': 'Such content is unsuitable for general social media use and can distress followers.',\n",
       "    'subject_at_risk': 'ai_subject'},\n",
       "   {'reference_risk': 'Generates sexual content without consent',\n",
       "    'source': 'model_risks',\n",
       "    'reasoning': 'Social media influencers risk sharing content that is inappropriate and without the consent of viewers.',\n",
       "    'subject_at_risk': 'ai_subject'},\n",
       "   {'reference_risk': 'Impersonates individuals without their consent',\n",
       "    'source': 'model_risks',\n",
       "    'reasoning': 'This can lead to ethical and legal issues in social media use.',\n",
       "    'subject_at_risk': 'ai_user'},\n",
       "   {'reference_risk': 'Fails to generate realistic images due to focus on anime-style content',\n",
       "    'source': 'model_risks',\n",
       "    'reasoning': \"This limits the model's applicability for influencers looking for realistic GIFs.\",\n",
       "    'subject_at_risk': 'ai_user'},\n",
       "   {'reference_risk': 'Generates demeaning, dehumanizing, or otherwise harmful representations of people or their environments, cultures, religions',\n",
       "    'source': 'model_risks',\n",
       "    'reasoning': \"Such content can damage the influencer's relationship with followers and their public image.\",\n",
       "    'subject_at_risk': 'ai_user'}]},\n",
       " {'cardID': '1490',\n",
       "  'use': 'Domain-- Marketing and Advertising, Purpose-- Creating engaging promotional content, Capability-- Generating GIFs from marketing text',\n",
       "  'risks': [{'reference_risk': 'Cannot render legible text',\n",
       "    'source': 'model_risks',\n",
       "    'reasoning': 'The AI model might fail to create legible text in generated GIFs, reducing the effectiveness of promotional content',\n",
       "    'subject_at_risk': 'ai_user'},\n",
       "   {'reference_risk': 'Underperforms with natural language descriptions due to focus on anime-specific terminologies',\n",
       "    'source': 'model_risks',\n",
       "    'reasoning': 'The model might not accurately interpret marketing text prompts due to its training focus, affecting the quality of the output GIFs',\n",
       "    'subject_at_risk': 'ai_user'},\n",
       "   {'reference_risk': 'Contains adult material in training data',\n",
       "    'source': 'model_risks',\n",
       "    'reasoning': 'Generated GIFs might unintentionally contain inappropriate content, which can harm the reputation of the advertising agency and offend potential customers',\n",
       "    'subject_at_risk': 'ai_subject'},\n",
       "   {'reference_risk': 'Underperforms with non-English prompts',\n",
       "    'source': 'model_risks',\n",
       "    'reasoning': \"Marketing campaigns aimed at non-English speaking audiences could be less effective due to the model's limitations\",\n",
       "    'subject_at_risk': 'ai_user'},\n",
       "   {'reference_risk': 'Fails to achieve perfect photorealism',\n",
       "    'source': 'model_risks',\n",
       "    'reasoning': 'The generated GIFs may not appear realistic, which could diminish their appeal in marketing campaigns',\n",
       "    'subject_at_risk': 'ai_subject'},\n",
       "   {'reference_risk': 'Generates demeaning, dehumanizing or harmful representations of people or their environments, cultures, religions',\n",
       "    'source': 'model_risks',\n",
       "    'reasoning': 'Such representations could offend potential customers and damage the reputation of the advertising agency',\n",
       "    'subject_at_risk': 'ai_subject'},\n",
       "   {'reference_risk': 'Spreads mis and disinformation',\n",
       "    'source': 'model_risks',\n",
       "    'reasoning': 'Sharing inaccurate GIFs in marketing campaigns could mislead potential customers and harm the credibility of the agency',\n",
       "    'subject_at_risk': 'ai_subject'},\n",
       "   {'reference_risk': 'Exhibits a bias towards a specific art style due to fine-tuning on similar images',\n",
       "    'source': 'model_risks',\n",
       "    'reasoning': \"The model might generate GIFs that aren't versatile enough for different marketing themes, limiting creative expression\",\n",
       "    'subject_at_risk': 'ai_user'},\n",
       "   {'reference_risk': 'Underperforms on tasks involving compositionality',\n",
       "    'source': 'model_risks',\n",
       "    'reasoning': 'The model may struggle to generate coherent and complex GIFs required for elaborate marketing messages',\n",
       "    'subject_at_risk': 'ai_user'},\n",
       "   {'reference_risk': 'Generates sexual content without consent',\n",
       "    'source': 'model_risks',\n",
       "    'reasoning': 'Inappropriate content could damage the reputation of the advertising agency and offend the audience',\n",
       "    'subject_at_risk': 'ai_subject'},\n",
       "   {'reference_risk': 'Fails to generate faces and people properly',\n",
       "    'source': 'model_risks',\n",
       "    'reasoning': 'Poorly rendered faces or people in GIFs could reduce the quality and appeal of marketing material',\n",
       "    'subject_at_risk': 'ai_user'},\n",
       "   {'reference_risk': 'Creates hostile or alienating environments by generating disturbing or offensive images',\n",
       "    'source': 'aiid_risks',\n",
       "    'reasoning': 'Offensive or disturbing GIFs in a marketing context could alienate potential customers and harm the agencyâ€™s reputation',\n",
       "    'subject_at_risk': 'institution'},\n",
       "   {'reference_risk': 'Promotes or propagates discriminatory content or harmful stereotypes',\n",
       "    'source': 'model_risks',\n",
       "    'reasoning': 'Incorporating discriminatory or stereotypical content in marketing GIFs could offend potential customers and damage the brand image',\n",
       "    'subject_at_risk': 'ai_subject'},\n",
       "   {'reference_risk': 'Undermines public trust in AI by demonstrating misuse of AI technology',\n",
       "    'source': 'aiid_risks',\n",
       "    'reasoning': 'Misuse of the AI model in marketing could erode trust in both the technology and the advertising agency',\n",
       "    'subject_at_risk': 'institution'},\n",
       "   {'reference_risk': 'Violates intellectual property rights by generating code without proper attribution',\n",
       "    'source': 'aiid_risks',\n",
       "    'reasoning': 'Unauthorized use of content in GIFs could lead to legal repercussions and damage the agencyâ€™s reputation',\n",
       "    'subject_at_risk': 'institution'},\n",
       "   {'reference_risk': 'Undermines trust in legitimate news sources by spreading propaganda',\n",
       "    'source': 'aiid_risks',\n",
       "    'reasoning': 'Using the model to generate misleading promotional content could reduce trust in authentic marketing messages',\n",
       "    'subject_at_risk': 'institution'}]},\n",
       " {'cardID': '1490',\n",
       "  'use': 'Domain-- Education and vocational training, Purpose-- Creating educational animations, Capability-- Generating GIFs from lesson content',\n",
       "  'risks': [{'reference_risk': 'Cannot render legible text',\n",
       "    'source': 'model_risks',\n",
       "    'reasoning': 'If the generated GIFs include text that is illegible, it could hinder educational effectiveness.',\n",
       "    'subject_at_risk': 'ai_subject'},\n",
       "   {'reference_risk': 'Underperforms with non-English prompts',\n",
       "    'source': 'model_risks',\n",
       "    'reasoning': 'If the model underperforms with non-English prompts, it may fail to generate useful content for students speaking other languages.',\n",
       "    'subject_at_risk': 'ai_subject'},\n",
       "   {'reference_risk': 'Generates nonfactual or untrue representations of people or events',\n",
       "    'source': 'model_risks',\n",
       "    'reasoning': 'Generating nonfactual representations can misinform students and undermine educational goals.',\n",
       "    'subject_at_risk': 'ai_subject'},\n",
       "   {'reference_risk': 'Spreads mis and disinformation',\n",
       "    'source': 'model_risks',\n",
       "    'reasoning': \"Disseminating misinformation in educational materials can harm students' learning and trust in the content.\",\n",
       "    'subject_at_risk': 'ai_subject'},\n",
       "   {'reference_risk': 'Promotes hate speech by generating and posting racist, misogynistic, and antisemitic content',\n",
       "    'source': 'aiid_risks',\n",
       "    'reasoning': 'Hate speech in educational content can create a hostile and unsafe learning environment.',\n",
       "    'subject_at_risk': 'ai_subject'},\n",
       "   {'reference_risk': 'Harms reputations by spreading altered and misleading media',\n",
       "    'source': 'aiid_risks',\n",
       "    'reasoning': 'Spreading misleading media can damage the reputation of the educational institution and teachers involved.',\n",
       "    'subject_at_risk': 'institution'},\n",
       "   {'reference_risk': 'Violates human rights by propagating discriminatory and offensive language',\n",
       "    'source': 'aiid_risks',\n",
       "    'reasoning': 'Discriminatory content can violate human rights and harm the well-being of students.',\n",
       "    'subject_at_risk': 'ai_subject'},\n",
       "   {'reference_risk': 'Reduces learning outcomes by allowing students to bypass the educational process',\n",
       "    'source': 'aiid_risks',\n",
       "    'reasoning': 'If the tool enables students to shortcut learning, it can reduce the overall effectiveness of education.',\n",
       "    'subject_at_risk': 'ai_subject'},\n",
       "   {'reference_risk': 'Generates sexual content without consent of the people who might see it',\n",
       "    'source': 'model_risks',\n",
       "    'reasoning': 'Exposure to inappropriate content can be harmful to students and is unsuitable for educational settings.',\n",
       "    'subject_at_risk': 'ai_subject'}]},\n",
       " {'cardID': '1490',\n",
       "  'use': 'Domain-- Well-being, Purpose-- Creating motivational content, Capability-- Generating GIFs from wellness quotes',\n",
       "  'risks': [{'reference_risk': 'Generates demeaning dehumanizing or otherwise harmful representations of people or their environments cultures religions',\n",
       "    'source': 'model_risks',\n",
       "    'reasoning': 'This pertains to the model generating content that might be harmful, which is relevant since motivational content should be positive.',\n",
       "    'subject_at_risk': 'Clients'},\n",
       "   {'reference_risk': 'Generates nonfactual or untrue representations of people or events',\n",
       "    'source': 'model_risks',\n",
       "    'reasoning': 'Nonfactual representations can mislead clients seeking motivational content.',\n",
       "    'subject_at_risk': 'Clients'},\n",
       "   {'reference_risk': 'Generates demeaning dehumanizing or harmful representations of people or their environments cultures religions',\n",
       "    'source': 'model_risks',\n",
       "    'reasoning': \"Motivational content that demeans or dehumanizes people can harm clients' well-being.\",\n",
       "    'subject_at_risk': 'Clients'},\n",
       "   {'reference_risk': 'Exhibits a bias towards a specific art style due to finetuning on similar images',\n",
       "    'source': 'model_risks',\n",
       "    'reasoning': \"Bias towards a specific art style might limit the model's effectiveness in generating diverse, inclusive motivational content.\",\n",
       "    'subject_at_risk': 'Clients'},\n",
       "   {'reference_risk': 'Generates representations of egregious violence and gore',\n",
       "    'source': 'model_risks',\n",
       "    'reasoning': 'Content featuring violence and gore is inappropriate and harmful for motivational purposes.',\n",
       "    'subject_at_risk': 'Clients'},\n",
       "   {'reference_risk': 'Propagates historical or current stereotypes',\n",
       "    'source': 'model_risks',\n",
       "    'reasoning': 'Stereotypes can negatively impact the inclusivity and positivity of motivational content.',\n",
       "    'subject_at_risk': 'Clients'},\n",
       "   {'reference_risk': 'Reinforces or exacerbates social biases',\n",
       "    'source': 'model_risks',\n",
       "    'reasoning': 'Social biases in content could harm the target audience psychologically and socially.',\n",
       "    'subject_at_risk': 'Clients'},\n",
       "   {'reference_risk': 'Creates hostile or alienating environments for people',\n",
       "    'source': 'model_risks',\n",
       "    'reasoning': 'Motivational content should not create hostile or alienating environments.',\n",
       "    'subject_at_risk': 'Clients'},\n",
       "   {'reference_risk': 'Promotes or propagates discriminatory content or harmful stereotypes',\n",
       "    'source': 'model_risks',\n",
       "    'reasoning': 'Discriminatory content in motivational material can harm clients and undermine the purpose.',\n",
       "    'subject_at_risk': 'Clients'},\n",
       "   {'reference_risk': 'Memorizes images that are duplicated in the training data',\n",
       "    'source': 'model_risks',\n",
       "    'reasoning': \"Memorization might lead to repetitive, uninspiring content that does not meet clients' needs.\",\n",
       "    'subject_at_risk': 'Clients'},\n",
       "   {'reference_risk': 'Generates images that people find disturbing distressing or offensive',\n",
       "    'source': 'model_risks',\n",
       "    'reasoning': 'Such images are counterproductive for motivational content aimed at well-being.',\n",
       "    'subject_at_risk': 'Clients'}]}]"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "FULL_RES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "###############################\n",
    "# save result\n",
    "with open(results_file, \"w\") as json_file:\n",
    "    json.dump(FULL_RES, json_file, indent=4)  # 4 spaces of indentation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sort risks according to uses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>cardID</th>\n",
       "      <th>risks.reference_risk</th>\n",
       "      <th>risks.source</th>\n",
       "      <th>count</th>\n",
       "      <th>uses</th>\n",
       "      <th>use_capability</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>44</td>\n",
       "      <td>Produces low diversity and hallucinated outputs</td>\n",
       "      <td>model_risks</td>\n",
       "      <td>4</td>\n",
       "      <td>[Domain-- Recommender Systems and Personalizat...</td>\n",
       "      <td>[Analyzing user preferences and suggesting ite...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>44</td>\n",
       "      <td>Contains biased training data from the internet</td>\n",
       "      <td>model_risks</td>\n",
       "      <td>3</td>\n",
       "      <td>[Domain-- Recommender Systems and Personalizat...</td>\n",
       "      <td>[Analyzing user preferences and suggesting ite...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>44</td>\n",
       "      <td>Exhibits biases</td>\n",
       "      <td>model_risks</td>\n",
       "      <td>3</td>\n",
       "      <td>[Domain-- Recommender Systems and Personalizat...</td>\n",
       "      <td>[Analyzing user preferences and suggesting ite...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>44</td>\n",
       "      <td>Facilitates misinformation spreading false kno...</td>\n",
       "      <td>aiid_risks</td>\n",
       "      <td>3</td>\n",
       "      <td>[Domain-- Recommender Systems and Personalizat...</td>\n",
       "      <td>[Analyzing user preferences and suggesting ite...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>44</td>\n",
       "      <td>Generates factual inaccuracies</td>\n",
       "      <td>model_risks</td>\n",
       "      <td>3</td>\n",
       "      <td>[Domain-- Marketing and Advertising, Purpose--...</td>\n",
       "      <td>[Generating tailored messages from user data, ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    cardID                               risks.reference_risk risks.source  \\\n",
       "24      44    Produces low diversity and hallucinated outputs  model_risks   \n",
       "0       44    Contains biased training data from the internet  model_risks   \n",
       "3       44                                    Exhibits biases  model_risks   \n",
       "6       44  Facilitates misinformation spreading false kno...   aiid_risks   \n",
       "8       44                     Generates factual inaccuracies  model_risks   \n",
       "\n",
       "    count                                               uses  \\\n",
       "24      4  [Domain-- Recommender Systems and Personalizat...   \n",
       "0       3  [Domain-- Recommender Systems and Personalizat...   \n",
       "3       3  [Domain-- Recommender Systems and Personalizat...   \n",
       "6       3  [Domain-- Recommender Systems and Personalizat...   \n",
       "8       3  [Domain-- Marketing and Advertising, Purpose--...   \n",
       "\n",
       "                                       use_capability  \n",
       "24  [Analyzing user preferences and suggesting ite...  \n",
       "0   [Analyzing user preferences and suggesting ite...  \n",
       "3   [Analyzing user preferences and suggesting ite...  \n",
       "6   [Analyzing user preferences and suggesting ite...  \n",
       "8   [Generating tailored messages from user data, ...  "
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mapped_risks = pd.read_json(results_file)\n",
    "\n",
    "# Normalize the JSON mapped_risks to create a flat DataFrame\n",
    "df = pd.json_normalize(mapped_risks.explode('risks').to_dict(orient='records'))\n",
    "\n",
    "# Define a function to extract the capability from the use\n",
    "def extract_capability(use):\n",
    "    # Extract the capability part from the structured use string\n",
    "    capability_part = use.split('Capability-- ')[1].strip() if 'Capability-- ' in use else None\n",
    "    return capability_part\n",
    "\n",
    "# Group by 'cardID' and 'risks.reference_risk' and aggregate the uses\n",
    "risk_counts = df.groupby(['cardID', 'risks.reference_risk', 'risks.source']).agg(\n",
    "    count=('use', 'nunique'),  # Count the number of unique uses\n",
    "    uses=('use', lambda x: list(x.unique())),  # List of unique uses\n",
    "    use_capability=('use', lambda x: list(x.apply(extract_capability).unique()))  # List of unique capabilities\n",
    ").reset_index()\n",
    "\n",
    "# Sort the counts in descending order for each cardID\n",
    "risk_counts_sorted = risk_counts.sort_values(by=['cardID', 'count'], ascending=[True, False])\n",
    "\n",
    "# Save the result to a CSV file\n",
    "output_risk_file = 'user_study/final_study/user_study_reference_risk_counts_sorted.csv'\n",
    "risk_counts_sorted.to_csv(output_file, index=False)\n",
    "# Display the result\n",
    "risk_counts_sorted.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Mitigation mapping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "MESSAGES = [ { 'role': 'system', 'content': \"\"\"\n",
    "Consider the following definitions: \n",
    "    1) An AI incident is an event, circumstance or series of events where the development, use or malfunction of one or more AI systems directly or indirectly leads to any of the following harms: (a) injury or harm to the health of a person or groups of people; (b) disruption of the management and operation of critical infrastructure; (c) violations to human rights or a breach of obligations under the applicable law intended to protect fundamental, labour and intellectual property rights; (d) harm to property, communities or the environment.' The harm can be physical, psychological, reputational, economic/financial (including harm to property), environmental, public interest (e.g., protection of critical infrastructure and democratic institutions), human rights and fundamental rights. \n",
    "    2) An AI risk is expressed as likelihood that harm or damage will occur. Risk is a function of both the probability of an event occurring and the severity of the consequences that would result. Risk is usually expressed in terms of risk sources, potential events, their consequences and their likelihood.  \"\"\" },\n",
    "\n",
    "{ 'role': 'user', 'content': \"\"\"You are provided in input with cardID, model description, a potential use of the model and a list of risks :\n",
    "cardID: \"{}\", model_description: \"{}\", model_task: \"{}\", model_risks: \"{}\", aiid_risks: \"{}\", mitigations: \"{}\".\n",
    "\n",
    "Tasks:\n",
    "\n",
    "(1) The main purpose of this task is to map each unique risk to the mitigations provided. Output the risk ONLY AFTER MAPPING IT. If some risks are redundant and similar to each other, skip the duplicates and map ONLY UNIQUE risks. If some risks do not pertain to the model description, skip those. DO NOT INVENT ANY NEW RISKS. \n",
    " Guidelines:\n",
    " 1. Understand Model Description, Model Task: Thoroughly read and understand the specific context of the AI model being described, the task it is intended for.\n",
    " 2. Identify Unique Risks: There are two lists of risks. Identify unique risks from both lists that are relevant to the described model; skip those that are not. Remember the source of the risk. For the model_risks, check if it is relevant to the model description and model_task. If it is not, skip those. For the aiid_risks, check if it is relevant to the model_task. Skip those, if it is not relevant.\n",
    " 3. Map Relevant Risks to Mitigations: For each of the identified risk, map the appropriate mitigation strategy given. Note that each mitigation can map to more than one risk.\n",
    " \n",
    " Examples: \n",
    " 1. Reference Risk: Violates privacy rights.\n",
    "    Mitigation mapped: Limit data collection to essential information only.\n",
    " \n",
    " 2. Reference Risk: Generates offensive content harming reputations.\n",
    "    Mitigation mapped: Probe these aspects on your use-cases to evaluate risks.\n",
    " \n",
    "Output Format: Ensure your output strictly follows this JSON structure. Ouput only relevant risks. No need to output skipped risks.\n",
    "\n",
    "{{\n",
    "    \"cardID\": \"<Card ID>\",\n",
    "    \"use\": \"<use>\"\n",
    "    \"risks\": \n",
    "    {{\n",
    "        [\n",
    "            {{\n",
    "                \"reference_risk\": \"Reference risk 1 from list\",\n",
    "                \"source\": \"model_risks or aiid_risks\",\n",
    "                \"reasoning\": \"reasoning\",\n",
    "                \"subject_at_risk\": \"<ai_user> or <ai_subject> or <institution>\"\n",
    "            }},\n",
    "            {{\n",
    "                \"reference_risk\": \"Reference risk 2 from list\",\n",
    "                \"source\": \"model_risks or aiid_risks\",\n",
    "                \"reasoning\": \"reasoning\",\n",
    "                \"subject_at_risk\": \"<ai_user> or <ai_subject> or <institution>\"\n",
    "            }},\n",
    "            ...\n",
    "        ]\n",
    "    }},\n",
    "}}\n",
    "\n",
    "\n",
    "Important Notes: Do not report your reasoning steps or any preamble like 'Here is the output', '```json ...```', ONLY the JSON result. In scenarios where there are no sentences mentioned, provide an empty JSON array for those sections.\n",
    "\n",
    "*** Double Check your output that it contains only the requested JSON and nothing else. *** \"\"\"\n",
    "\n",
    "} ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def format_prompt(MESSAGES, cardID, desc, task, model_risks, aiid_risks, mitigations): \n",
    "    messages = deepcopy(MESSAGES) \n",
    "    messages[1]['content'] = messages[1]['content'].format(cardID, desc, task, model_risks, aiid_risks, mitigations) \n",
    "    return messages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def batch_data(data=data):\n",
    "    tasks = []\n",
    "    for i, row in data.iterrows():\n",
    "        print (i)\n",
    "    \n",
    "        messages = format_prompt(MESSAGES, cardID=i, desc=row[\"test_description\"], task=risk_cards[\"pipeline_tag\"][i], model_risks=row[\"matched_risks\"], aiid_risks=row[\"matched_risks_aiid\"], mitigations=row[\"matched_mitigations\"])\n",
    "        task = {\n",
    "        \"custom_id\": f\"task-{int(i)}\",\n",
    "        \"method\": \"POST\",\n",
    "        \"url\": \"/v1/chat/completions\",\n",
    "        \"body\": {\n",
    "            # This is what you would have in your Chat Completions API call\n",
    "            \"model\": \"gpt-4o\",\n",
    "            \"temperature\": 0,\n",
    "            \"response_format\": { \n",
    "                \"type\": \"json_object\"\n",
    "            },\n",
    "            \"messages\": messages,\n",
    "            }\n",
    "        }\n",
    "    \n",
    "        tasks.append(task)\n",
    "    return tasks\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_name = \"data/new_data/results/user_study_risks.jsonl\"\n",
    "\n",
    "with open(file_name, 'w') as file:\n",
    "    for obj in responses:\n",
    "        file.write(json.dumps(obj) + '\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_mit_file_name = \"data/new_data/results/user_study_mitigations.jsonl\"\n",
    "results_mit_file = \"user_study/final_study/user_study_mitigations_v2.json\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('data/new_data/results/user_study_mitigations.jsonl',\n",
       " 'user_study/final_study/user_study_mitigations_v2.json')"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results_mit_file_name, results_mit_file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading data from saved file\n",
    "results = []\n",
    "with open(results_mit_file_name, 'r') as file:\n",
    "    for line in file:\n",
    "        # Parsing the JSON string into a dict and appending to the list of results\n",
    "        json_object = json.loads(line.strip())\n",
    "        results.append(json_object)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for res in results:\n",
    "    print (res)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "FULL_RES = []\n",
    "cnt_errors = []\n",
    "\n",
    "# Reading only the first results\n",
    "for res in results:\n",
    "    try:\n",
    "        res = ast.literal_eval(res)\n",
    "        # print (index)\n",
    "        # res[\"Incident ID\"] = int(index)\n",
    "        FULL_RES.append(res)\n",
    "    except Exception as e:\n",
    "        print (e)\n",
    "        # print (result)\n",
    "        cnt_errors.append(res)\n",
    "        continue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "cnt_errors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "FULL_RES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "###############################\n",
    "# save result\n",
    "with open(results_mit_file, \"w\") as json_file:\n",
    "    json.dump(FULL_RES, json_file, indent=4)  # 4 spaces of indentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "\"['risks.source', 'count', 'use_capability'] not in index\"",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[19], line 17\u001b[0m\n\u001b[1;32m     14\u001b[0m mitigations_df \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mjson_normalize(mitigations_data, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mrisks\u001b[39m\u001b[38;5;124m'\u001b[39m, [\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcardID\u001b[39m\u001b[38;5;124m'\u001b[39m])\n\u001b[1;32m     16\u001b[0m \u001b[38;5;66;03m# Create a lookup DataFrame for mitigations based on the reference risk\u001b[39;00m\n\u001b[0;32m---> 17\u001b[0m mitigations_lookup_df \u001b[38;5;241m=\u001b[39m \u001b[43mmitigations_df\u001b[49m\u001b[43m[\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mreference_risk\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mcardID\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mrisks.source\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mcount\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43muse_capability\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m]\u001b[49m\n\u001b[1;32m     19\u001b[0m \u001b[38;5;66;03m# Filter the mitigations DataFrame based on the ordered reference risks\u001b[39;00m\n\u001b[1;32m     20\u001b[0m filtered_mitigations \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mmerge(\n\u001b[1;32m     21\u001b[0m     pd\u001b[38;5;241m.\u001b[39mDataFrame({\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mreference_risk\u001b[39m\u001b[38;5;124m'\u001b[39m: ordered_reference_risks}),\n\u001b[1;32m     22\u001b[0m     mitigations_lookup_df,\n\u001b[1;32m     23\u001b[0m     on\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mreference_risk\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[1;32m     24\u001b[0m     how\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mleft\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m     25\u001b[0m )\n",
      "File \u001b[0;32m/10TBdrive/pooja/miniconda3/envs/ai-mitigations/lib/python3.8/site-packages/pandas/core/frame.py:3767\u001b[0m, in \u001b[0;36mDataFrame.__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   3765\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m is_iterator(key):\n\u001b[1;32m   3766\u001b[0m         key \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(key)\n\u001b[0;32m-> 3767\u001b[0m     indexer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcolumns\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_get_indexer_strict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcolumns\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m[\u001b[38;5;241m1\u001b[39m]\n\u001b[1;32m   3769\u001b[0m \u001b[38;5;66;03m# take() does not accept boolean indexers\u001b[39;00m\n\u001b[1;32m   3770\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mgetattr\u001b[39m(indexer, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdtype\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m) \u001b[38;5;241m==\u001b[39m \u001b[38;5;28mbool\u001b[39m:\n",
      "File \u001b[0;32m/10TBdrive/pooja/miniconda3/envs/ai-mitigations/lib/python3.8/site-packages/pandas/core/indexes/base.py:5877\u001b[0m, in \u001b[0;36mIndex._get_indexer_strict\u001b[0;34m(self, key, axis_name)\u001b[0m\n\u001b[1;32m   5874\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   5875\u001b[0m     keyarr, indexer, new_indexer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reindex_non_unique(keyarr)\n\u001b[0;32m-> 5877\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_raise_if_missing\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkeyarr\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mindexer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis_name\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   5879\u001b[0m keyarr \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtake(indexer)\n\u001b[1;32m   5880\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(key, Index):\n\u001b[1;32m   5881\u001b[0m     \u001b[38;5;66;03m# GH 42790 - Preserve name from an Index\u001b[39;00m\n",
      "File \u001b[0;32m/10TBdrive/pooja/miniconda3/envs/ai-mitigations/lib/python3.8/site-packages/pandas/core/indexes/base.py:5941\u001b[0m, in \u001b[0;36mIndex._raise_if_missing\u001b[0;34m(self, key, indexer, axis_name)\u001b[0m\n\u001b[1;32m   5938\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNone of [\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mkey\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m] are in the [\u001b[39m\u001b[38;5;132;01m{\u001b[39;00maxis_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m]\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m   5940\u001b[0m not_found \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(ensure_index(key)[missing_mask\u001b[38;5;241m.\u001b[39mnonzero()[\u001b[38;5;241m0\u001b[39m]]\u001b[38;5;241m.\u001b[39munique())\n\u001b[0;32m-> 5941\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mnot_found\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m not in index\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[0;31mKeyError\u001b[0m: \"['risks.source', 'count', 'use_capability'] not in index\""
     ]
    }
   ],
   "source": [
    "filtered_mit_file = \"user_study/final_study/user_study_filtered_mitigations_v2.json\"\n",
    "output_risk_file = \"user_study/final_study/user_study_reference_risk_counts_sorted.csv\"\n",
    "\n",
    "# Load the original sorted risk and mitigations JSON files\n",
    "df = pd.read_csv(output_risk_file)\n",
    "\n",
    "with open(results_mit_file, 'r') as file:\n",
    "    mitigations_data = json.load(file)\n",
    "\n",
    "# Extract risks in the order they appear\n",
    "ordered_reference_risks = df['risks.reference_risk'].tolist()\n",
    "\n",
    "# Normalize JSON data into a DataFrame\n",
    "mitigations_df = pd.json_normalize(mitigations_data, 'risks', ['cardID'])\n",
    "\n",
    "# Create a lookup DataFrame for mitigations based on the reference risk\n",
    "mitigations_lookup_df = mitigations_df[['reference_risk', 'cardID', 'risks.source', 'count', 'use_capability']]\n",
    "\n",
    "# Filter the mitigations DataFrame based on the ordered reference risks\n",
    "filtered_mitigations = pd.merge(\n",
    "    pd.DataFrame({'reference_risk': ordered_reference_risks}),\n",
    "    mitigations_lookup_df,\n",
    "    on='reference_risk',\n",
    "    how='left'\n",
    ")\n",
    "\n",
    "# Group by cardID and aggregate risks into lists, maintaining order\n",
    "filtered_mitigations = filtered_mitigations.groupby('cardID').apply(\n",
    "    lambda x: x[['reference_risk', 'source', 'count', 'uses']].to_dict(orient='records')\n",
    ").reset_index(name='risks')\n",
    "\n",
    "# Convert the DataFrame to the desired JSON format\n",
    "filtered_mitigations_json = filtered_mitigations.to_dict(orient='records')\n",
    "\n",
    "# # Filter the mitigations data based on the reference risks\n",
    "# filtered_mitigations = []\n",
    "# for card in mitigations_data:\n",
    "#     filtered_risks = []\n",
    "#     for risk in card['risks']:\n",
    "#         if risk['reference_risk'] in reference_risks:\n",
    "#             filtered_risks.append(risk)\n",
    "#     if filtered_risks:\n",
    "#         filtered_mitigations.append({\n",
    "#             'cardID': card['cardID'],\n",
    "#             'risks': filtered_risks\n",
    "#         })\n",
    "\n",
    "# Save the filtered mitigations data to a new JSON file\n",
    "with open(filtered_mit_file, 'w') as outfile:\n",
    "    json.dump(filtered_mitigations, outfile, indent=4)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "ordered_risks = {}\n",
    "for _, row in risk_counts_sorted.iterrows():\n",
    "    if row['cardID'] not in ordered_risks:\n",
    "        ordered_risks[row['cardID']] = []\n",
    "    ordered_risks[row['cardID']].append(row['risks.reference_risk'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "filtered_mit_file = \"user_study/final_study/user_study_filtered_mitigations_v2_.json\"\n",
    "# output_risk_file = \"user_study/final_study/user_study_reference_risk_counts_sorted.csv\"\n",
    "\n",
    "with open(results_mit_file, 'r') as file:\n",
    "    mitigations_data = json.load(file)\n",
    "\n",
    "\n",
    "# Extract the ordered reference_risks by cardID\n",
    "ordered_risks = {}\n",
    "for _, row in risk_counts_sorted.iterrows():\n",
    "    if row['cardID'] not in ordered_risks:\n",
    "        ordered_risks[row['cardID']] = []\n",
    "    ordered_risks[row['cardID']].append(row['risks.reference_risk'])\n",
    "\n",
    "# Filter and reorder the mitigations data based on the reference risks\n",
    "filtered_mitigations = []\n",
    "for card in mitigations_data:\n",
    "    card_id = card['cardID']\n",
    "    if card_id in ordered_risks:\n",
    "        filtered_risks = []\n",
    "        # Reorder the risks according to the ordered_risks list\n",
    "        for reference_risk in ordered_risks[card_id]:\n",
    "            for risk in card['risks']:\n",
    "                if risk['reference_risk'] == reference_risk:\n",
    "                    filtered_risks.append(risk)\n",
    "        if filtered_risks:\n",
    "            filtered_mitigations.append({\n",
    "                'cardID': card['cardID'],\n",
    "                'risks': filtered_risks\n",
    "            })\n",
    "\n",
    "# Save the filtered and ordered mitigations data to a new JSON file\n",
    "with open(filtered_mit_file, 'w') as outfile:\n",
    "    json.dump(filtered_mitigations, outfile, indent=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Map risks and mitigations and sort according to uses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>cardID</th>\n",
       "      <th>risks.reference_risk</th>\n",
       "      <th>risks.source</th>\n",
       "      <th>count</th>\n",
       "      <th>uses</th>\n",
       "      <th>use_capability</th>\n",
       "      <th>risks.mapped_mitigations</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>1490</td>\n",
       "      <td>Underperforms with non-English prompts</td>\n",
       "      <td>model_risks</td>\n",
       "      <td>3</td>\n",
       "      <td>[Domain-- Social Media, Purpose-- Creating eng...</td>\n",
       "      <td>[Generating GIFs from user content, Generating...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1490</td>\n",
       "      <td>Cannot render legible text</td>\n",
       "      <td>model_risks</td>\n",
       "      <td>2</td>\n",
       "      <td>[Domain-- Marketing and Advertising, Purpose--...</td>\n",
       "      <td>[Generating GIFs from marketing text, Generati...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1490</td>\n",
       "      <td>Contains adult material in training data</td>\n",
       "      <td>model_risks</td>\n",
       "      <td>2</td>\n",
       "      <td>[Domain-- Social Media, Purpose-- Creating eng...</td>\n",
       "      <td>[Generating GIFs from user content, Generating...</td>\n",
       "      <td>[Promote safe and appropriate content generati...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1490</td>\n",
       "      <td>Creates hostile or alienating environments for...</td>\n",
       "      <td>model_risks</td>\n",
       "      <td>2</td>\n",
       "      <td>[Domain-- Social Media, Purpose-- Creating eng...</td>\n",
       "      <td>[Generating GIFs from user content, Generating...</td>\n",
       "      <td>[Use Safety Checker to filter harmful concepts]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>1490</td>\n",
       "      <td>Generates nonfactual or untrue representations...</td>\n",
       "      <td>model_risks</td>\n",
       "      <td>2</td>\n",
       "      <td>[Domain-- Education and vocational training, P...</td>\n",
       "      <td>[Generating GIFs from lesson content, Generati...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   cardID                               risks.reference_risk risks.source  \\\n",
       "34   1490             Underperforms with non-English prompts  model_risks   \n",
       "0    1490                         Cannot render legible text  model_risks   \n",
       "1    1490           Contains adult material in training data  model_risks   \n",
       "3    1490  Creates hostile or alienating environments for...  model_risks   \n",
       "16   1490  Generates nonfactual or untrue representations...  model_risks   \n",
       "\n",
       "    count                                               uses  \\\n",
       "34      3  [Domain-- Social Media, Purpose-- Creating eng...   \n",
       "0       2  [Domain-- Marketing and Advertising, Purpose--...   \n",
       "1       2  [Domain-- Social Media, Purpose-- Creating eng...   \n",
       "3       2  [Domain-- Social Media, Purpose-- Creating eng...   \n",
       "16      2  [Domain-- Education and vocational training, P...   \n",
       "\n",
       "                                       use_capability  \\\n",
       "34  [Generating GIFs from user content, Generating...   \n",
       "0   [Generating GIFs from marketing text, Generati...   \n",
       "1   [Generating GIFs from user content, Generating...   \n",
       "3   [Generating GIFs from user content, Generating...   \n",
       "16  [Generating GIFs from lesson content, Generati...   \n",
       "\n",
       "                             risks.mapped_mitigations  \n",
       "34                                                NaN  \n",
       "0                                                 NaN  \n",
       "1   [Promote safe and appropriate content generati...  \n",
       "3     [Use Safety Checker to filter harmful concepts]  \n",
       "16                                                NaN  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results_file = \"user_study/final_study/user_study_risks_v2.json\"\n",
    "results_mit_file = \"user_study/final_study/user_study_mitigations_v2.json\"\n",
    "output_risk_file = \"user_study/final_study/user_study_reference_risk_counts_sorted_.csv\"\n",
    "\n",
    "# Load the risks and mitigations JSON files\n",
    "with open(results_file, 'r') as file:\n",
    "    risk_data = json.load(file)\n",
    "\n",
    "with open(results_mit_file, 'r') as file:\n",
    "    mitigations_data = json.load(file)\n",
    "\n",
    "# Extract reference risks from the original JSON file\n",
    "reference_risks = set()\n",
    "for item in risk_data:\n",
    "    for risk in item.get('risks', []):\n",
    "        reference_risks.add(risk['reference_risk'])\n",
    "\n",
    "# Filter the mitigations data based on the reference risks\n",
    "filtered_mitigations = []\n",
    "for card in mitigations_data:\n",
    "    filtered_risks = []\n",
    "    for risk in card['risks']:\n",
    "        if risk['reference_risk'] in reference_risks:\n",
    "            filtered_risks.append(risk)\n",
    "    if filtered_risks:\n",
    "        filtered_mitigations.append({\n",
    "            'cardID': card['cardID'],\n",
    "            'risks': filtered_risks\n",
    "        })\n",
    "\n",
    "# Save the filtered mitigations data to a temporary JSON file\n",
    "temp_filtered_mitigations_file = 'user_study/final_study/temp_filtered_mitigations.json'\n",
    "with open(temp_filtered_mitigations_file, 'w') as outfile:\n",
    "    json.dump(filtered_mitigations, outfile, indent=4)\n",
    "\n",
    "# Load the filtered mitigations into a DataFrame\n",
    "mitigations_df = pd.read_json(temp_filtered_mitigations_file)\n",
    "\n",
    "# Normalize the JSON mapped_risks to create a flat DataFrame\n",
    "df_risks = pd.json_normalize(pd.DataFrame(risk_data).explode('risks').to_dict(orient='records'))\n",
    "df_mitigations = pd.json_normalize(pd.DataFrame(filtered_mitigations).explode('risks').to_dict(orient='records'))\n",
    "\n",
    "# Define a function to extract the capability from the use\n",
    "def extract_capability(use):\n",
    "    capability_part = use.split('Capability-- ')[1].strip() if 'Capability-- ' in use else None\n",
    "    return capability_part\n",
    "\n",
    "# Group by 'cardID' and 'risks.reference_risk' and aggregate the uses\n",
    "risk_counts = df_risks.groupby(['cardID', 'risks.reference_risk', 'risks.source']).agg(\n",
    "    count=('use', 'nunique'),  # Count the number of unique uses\n",
    "    uses=('use', lambda x: list(x.unique())),  # List of unique uses\n",
    "    use_capability=('use', lambda x: list(x.apply(extract_capability).unique()))  # List of unique capabilities\n",
    ").reset_index()\n",
    "\n",
    "# Merge the mitigations with the risk counts\n",
    "merged_data = pd.merge(risk_counts, df_mitigations[['cardID', 'risks.reference_risk', 'risks.mapped_mitigations']],\n",
    "                       on=['cardID', 'risks.reference_risk'], how='left')\n",
    "\n",
    "# Sort the counts in descending order for each cardID\n",
    "merged_data_sorted = merged_data.sort_values(by=['cardID', 'count'], ascending=[True, False])\n",
    "\n",
    "# Save the result to a CSV file\n",
    "merged_data_sorted.to_csv(output_risk_file, index=False)\n",
    "\n",
    "# Display the result\n",
    "merged_data_sorted.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>cardID</th>\n",
       "      <th>risks.reference_risk</th>\n",
       "      <th>risks.source</th>\n",
       "      <th>count</th>\n",
       "      <th>uses</th>\n",
       "      <th>use_capability</th>\n",
       "      <th>risks.mapped_mitigations</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>1490</td>\n",
       "      <td>Underperforms with non-English prompts</td>\n",
       "      <td>model_risks</td>\n",
       "      <td>3</td>\n",
       "      <td>[Domain-- Social Media, Purpose-- Creating eng...</td>\n",
       "      <td>[Generating GIFs from user content, Generating...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1490</td>\n",
       "      <td>Cannot render legible text</td>\n",
       "      <td>model_risks</td>\n",
       "      <td>2</td>\n",
       "      <td>[Domain-- Marketing and Advertising, Purpose--...</td>\n",
       "      <td>[Generating GIFs from marketing text, Generati...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1490</td>\n",
       "      <td>Contains adult material in training data</td>\n",
       "      <td>model_risks</td>\n",
       "      <td>2</td>\n",
       "      <td>[Domain-- Social Media, Purpose-- Creating eng...</td>\n",
       "      <td>[Generating GIFs from user content, Generating...</td>\n",
       "      <td>[Promote safe and appropriate content generati...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1490</td>\n",
       "      <td>Creates hostile or alienating environments for...</td>\n",
       "      <td>model_risks</td>\n",
       "      <td>2</td>\n",
       "      <td>[Domain-- Social Media, Purpose-- Creating eng...</td>\n",
       "      <td>[Generating GIFs from user content, Generating...</td>\n",
       "      <td>[Use Safety Checker to filter harmful concepts]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>1490</td>\n",
       "      <td>Generates nonfactual or untrue representations...</td>\n",
       "      <td>model_risks</td>\n",
       "      <td>2</td>\n",
       "      <td>[Domain-- Education and vocational training, P...</td>\n",
       "      <td>[Generating GIFs from lesson content, Generati...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>177</th>\n",
       "      <td>93</td>\n",
       "      <td>Small models may be more susceptible to halluc...</td>\n",
       "      <td>model_risks</td>\n",
       "      <td>1</td>\n",
       "      <td>[Domain-- Health and Healthcare, Purpose-- Ass...</td>\n",
       "      <td>[Analyzing patient data and suggesting conditi...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>178</th>\n",
       "      <td>93</td>\n",
       "      <td>Undermines trust in AI systems by mishandling ...</td>\n",
       "      <td>aiid_risks</td>\n",
       "      <td>1</td>\n",
       "      <td>[Domain-- Recommender Systems and Personalizat...</td>\n",
       "      <td>[Analyzing preferences for suggestions]</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>179</th>\n",
       "      <td>93</td>\n",
       "      <td>Underperforms in non-English languages</td>\n",
       "      <td>model_risks</td>\n",
       "      <td>1</td>\n",
       "      <td>[Domain-- Recommender Systems and Personalizat...</td>\n",
       "      <td>[Analyzing preferences for suggestions]</td>\n",
       "      <td>[Avoid using models unsuitable for your applic...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>180</th>\n",
       "      <td>93</td>\n",
       "      <td>Used maliciously for generating disinformation...</td>\n",
       "      <td>model_risks</td>\n",
       "      <td>1</td>\n",
       "      <td>[Domain-- Recommender Systems and Personalizat...</td>\n",
       "      <td>[Analyzing preferences for suggestions]</td>\n",
       "      <td>[Hope for better regulations and standards fro...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>181</th>\n",
       "      <td>93</td>\n",
       "      <td>Violates privacy by exposing private medical r...</td>\n",
       "      <td>aiid_risks</td>\n",
       "      <td>1</td>\n",
       "      <td>[Domain-- Health and Healthcare, Purpose-- Ass...</td>\n",
       "      <td>[Analyzing patient data and suggesting conditi...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>182 rows Ã— 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    cardID                               risks.reference_risk risks.source  \\\n",
       "34    1490             Underperforms with non-English prompts  model_risks   \n",
       "0     1490                         Cannot render legible text  model_risks   \n",
       "1     1490           Contains adult material in training data  model_risks   \n",
       "3     1490  Creates hostile or alienating environments for...  model_risks   \n",
       "16    1490  Generates nonfactual or untrue representations...  model_risks   \n",
       "..     ...                                                ...          ...   \n",
       "177     93  Small models may be more susceptible to halluc...  model_risks   \n",
       "178     93  Undermines trust in AI systems by mishandling ...   aiid_risks   \n",
       "179     93             Underperforms in non-English languages  model_risks   \n",
       "180     93  Used maliciously for generating disinformation...  model_risks   \n",
       "181     93  Violates privacy by exposing private medical r...   aiid_risks   \n",
       "\n",
       "     count                                               uses  \\\n",
       "34       3  [Domain-- Social Media, Purpose-- Creating eng...   \n",
       "0        2  [Domain-- Marketing and Advertising, Purpose--...   \n",
       "1        2  [Domain-- Social Media, Purpose-- Creating eng...   \n",
       "3        2  [Domain-- Social Media, Purpose-- Creating eng...   \n",
       "16       2  [Domain-- Education and vocational training, P...   \n",
       "..     ...                                                ...   \n",
       "177      1  [Domain-- Health and Healthcare, Purpose-- Ass...   \n",
       "178      1  [Domain-- Recommender Systems and Personalizat...   \n",
       "179      1  [Domain-- Recommender Systems and Personalizat...   \n",
       "180      1  [Domain-- Recommender Systems and Personalizat...   \n",
       "181      1  [Domain-- Health and Healthcare, Purpose-- Ass...   \n",
       "\n",
       "                                        use_capability  \\\n",
       "34   [Generating GIFs from user content, Generating...   \n",
       "0    [Generating GIFs from marketing text, Generati...   \n",
       "1    [Generating GIFs from user content, Generating...   \n",
       "3    [Generating GIFs from user content, Generating...   \n",
       "16   [Generating GIFs from lesson content, Generati...   \n",
       "..                                                 ...   \n",
       "177  [Analyzing patient data and suggesting conditi...   \n",
       "178            [Analyzing preferences for suggestions]   \n",
       "179            [Analyzing preferences for suggestions]   \n",
       "180            [Analyzing preferences for suggestions]   \n",
       "181  [Analyzing patient data and suggesting conditi...   \n",
       "\n",
       "                              risks.mapped_mitigations  \n",
       "34                                                 NaN  \n",
       "0                                                  NaN  \n",
       "1    [Promote safe and appropriate content generati...  \n",
       "3      [Use Safety Checker to filter harmful concepts]  \n",
       "16                                                 NaN  \n",
       "..                                                 ...  \n",
       "177                                                NaN  \n",
       "178                                                NaN  \n",
       "179  [Avoid using models unsuitable for your applic...  \n",
       "180  [Hope for better regulations and standards fro...  \n",
       "181                                                NaN  \n",
       "\n",
       "[182 rows x 7 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "merged_data_sorted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ai-mitigations",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
